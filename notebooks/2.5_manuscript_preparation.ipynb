{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.5: ìƒ˜í”Œ ë…¼ë¬¸ ì¤€ë¹„í•˜ê¸°\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. AI ë¦¬ë·°ë¥¼ ìœ„í•œ **ë…¼ë¬¸ ì›ê³  ì¤€ë¹„** ë°©ë²• ì´í•´\n",
    "2. ë³¸ì¸ ë…¼ë¬¸ì´ ì—†ëŠ” ê²½ìš° **ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±**\n",
    "3. ë…¼ë¬¸ì„ **Markdown í˜•ì‹**ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "---\n",
    "\n",
    "## ë…¼ë¬¸ ì¤€ë¹„ ì˜µì…˜\n",
    "\n",
    "| ì˜µì…˜ | ì„¤ëª… | ê¶Œì¥ ëŒ€ìƒ |\n",
    "|------|------|----------|\n",
    "| **A. ë³¸ì¸ ë…¼ë¬¸** | ì§ì ‘ ì‘ì„±í•œ ì´ˆê³  ì‚¬ìš© | ë…¼ë¬¸ ì‘ì„± ì¤‘ì¸ ë¶„ |\n",
    "| **B. AI ìƒì„±** | ê´€ì‹¬ ì£¼ì œë¡œ ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„± | ë³¸ì¸ ë…¼ë¬¸ì´ ì—†ëŠ” ë¶„ |\n",
    "| **C. ê¸°ì¡´ ìƒ˜í”Œ** | ì œê³µëœ ìƒ˜í”Œ ë…¼ë¬¸ ì‚¬ìš© | ë¹ ë¥´ê²Œ ì§„í–‰í•˜ê³  ì‹¶ì€ ë¶„ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: API Key ë¡œë”© ë° ì˜ì¡´ì„± ì„¤ì¹˜\nimport os\n\n# Colabì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\nif IN_COLAB:\n    %pip install langchain-google-genai pdfplumber python-docx -q\n    print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n\nif IN_COLAB:\n    try:\n        from google.colab import userdata\n        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n    except:\n        GEMINI_API_KEY = None\nelse:\n    from dotenv import load_dotenv\n    load_dotenv(override=True)\n    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n\nif GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n    print(\"âœ… Gemini API Key ë¡œë“œ ì™„ë£Œ\")\nelse:\n    print(\"âŒ Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n    print(\"   ë°œê¸‰: https://aistudio.google.com/apikey\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: API Key ë¡œë”©\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        GEMINI_API_KEY = None\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(override=True)\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n",
    "    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
    "    print(\"âœ… Gemini API Key ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n",
    "    print(\"   ë°œê¸‰: https://aistudio.google.com/apikey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: ì˜µì…˜ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: ê¸°ì¡´ ë…¼ë¬¸ íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "\n",
    "# ì§€ì› í˜•ì‹\n",
    "SUPPORTED_EXT = ['.md', '.txt', '.pdf', '.docx']\n",
    "\n",
    "# ê¸°ì¡´ íŒŒì¼ í™•ì¸\n",
    "existing_files = [f for f in os.listdir(INPUT_DIR) \n",
    "                  if os.path.splitext(f)[1].lower() in SUPPORTED_EXT]\n",
    "\n",
    "print(f\"ğŸ“ input í´ë” í™•ì¸: {INPUT_DIR}\")\n",
    "print(f\"\\nğŸ“„ ë°œê²¬ëœ ë…¼ë¬¸ íŒŒì¼ ({len(existing_files)}ê°œ):\")\n",
    "\n",
    "if existing_files:\n",
    "    for f in existing_files:\n",
    "        size = os.path.getsize(os.path.join(INPUT_DIR, f)) / 1024\n",
    "        print(f\"   - {f} ({size:.1f} KB)\")\n",
    "    print(\"\\nâœ… ê¸°ì¡´ íŒŒì¼ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ì•„ë˜ì—ì„œ ìƒˆ ë…¼ë¬¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"   (ì—†ìŒ)\")\n",
    "    print(\"\\nâš ï¸ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ A: ë³¸ì¸ ë…¼ë¬¸ ë³€í™˜\n",
    "\n",
    "PDFë‚˜ Word íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: ìƒì„±ëœ ë…¼ë¬¸ ì €ì¥\nimport re\n\nif 'generated_paper' in dir() and generated_paper:\n    # my_manuscript.mdë¡œ ì €ì¥ (ë…¸íŠ¸ë¶ 3, 4ì—ì„œ 1ìˆœìœ„ë¡œ ì‚¬ìš©)\n    my_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n    \n    with open(my_path, 'w', encoding='utf-8') as f:\n        f.write(generated_paper)\n    \n    print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {my_path}\")\n    print(f\"   íŒŒì¼ í¬ê¸°: {len(generated_paper)} ë¬¸ì\")\n    \n    # ì£¼ì œë³„ ë°±ì—… íŒŒì¼ë„ ì €ì¥\n    safe_topic = re.sub(r'[^\\w\\sê°€-í£]', '', RESEARCH_TOPIC)[:30]\n    safe_topic = safe_topic.replace(' ', '_')\n    backup_path = os.path.join(INPUT_DIR, f\"manuscript_{safe_topic}.md\")\n    \n    with open(backup_path, 'w', encoding='utf-8') as f:\n        f.write(generated_paper)\n    print(f\"   + ë°±ì—…: {backup_path}\")\n    \n    print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\")\n    print(\"   (my_manuscript.md â†’ 1ìˆœìœ„)\")\nelse:\n    print(\"âŒ Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ B: AIë¡œ ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±\n",
    "\n",
    "ê´€ì‹¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ AIê°€ ìƒ˜í”Œ ë…¼ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: ìµœì¢… í™•ì¸\nprint(\"=\"*60)\nprint(\"ğŸ“‹ ë…¼ë¬¸ ì¤€ë¹„ ìƒíƒœ\")\nprint(\"=\"*60)\n\n# ìš°ì„ ìˆœìœ„ í™•ì¸\nmy_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\nsample_path = os.path.join(INPUT_DIR, \"sample_manuscript.md\")\n\nprint(\"\\nğŸ“„ ë…¼ë¬¸ ë¡œë”© ìš°ì„ ìˆœìœ„:\")\nif os.path.exists(my_path):\n    size = os.path.getsize(my_path) / 1024\n    print(f\"   1ìˆœìœ„: âœ… my_manuscript.md ({size:.1f} KB) â† ì‚¬ìš©ë¨\")\nelse:\n    print(f\"   1ìˆœìœ„: âŒ my_manuscript.md (ì—†ìŒ)\")\n\nif os.path.exists(sample_path):\n    size = os.path.getsize(sample_path) / 1024\n    if os.path.exists(my_path):\n        print(f\"   2ìˆœìœ„: âœ… sample_manuscript.md ({size:.1f} KB)\")\n    else:\n        print(f\"   2ìˆœìœ„: âœ… sample_manuscript.md ({size:.1f} KB) â† ì‚¬ìš©ë¨\")\nelse:\n    print(f\"   2ìˆœìœ„: âŒ sample_manuscript.md (ì—†ìŒ)\")\n\n# ëª¨ë“  ë…¼ë¬¸ íŒŒì¼ í™•ì¸\nall_papers = [f for f in os.listdir(INPUT_DIR) \n              if os.path.splitext(f)[1].lower() in SUPPORTED_EXT]\n\nif all_papers:\n    print(f\"\\nğŸ“ input í´ë” ë‚´ ëª¨ë“  ë…¼ë¬¸ ({len(all_papers)}ê°œ):\")\n    for f in all_papers:\n        filepath = os.path.join(INPUT_DIR, f)\n        size = os.path.getsize(filepath) / 1024\n        print(f\"   - {f} ({size:.1f} KB)\")\n    \n    print(\"\\nğŸ‰ ë‹¤ìŒ ë‹¨ê³„: ë…¸íŠ¸ë¶ 3 ë˜ëŠ” 4ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!\")\nelse:\n    print(\"\\nâŒ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n    print(\"   ìœ„ì˜ ì˜µì…˜ A ë˜ëŠ” Bë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: AI ë…¼ë¬¸ ìƒì„±\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "if not RESEARCH_TOPIC:\n",
    "    print(\"âŒ Cell 5ì—ì„œ RESEARCH_TOPICì„ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ '{RESEARCH_TOPIC}' ì£¼ì œë¡œ ë…¼ë¬¸ ìƒì„± ì¤‘...\")\n",
    "    print(\"   (1-2ë¶„ ì†Œìš”)\")\n",
    "    \n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ {RESEARCH_FIELD} ë¶„ì•¼ì˜ ì—°êµ¬ìì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ì£¼ì œë¡œ í•™ìˆ  ë…¼ë¬¸ ì´ˆê³ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "**ì£¼ì œ**: {RESEARCH_TOPIC}\n",
    "**ì–¸ì–´**: {PAPER_LANGUAGE}\n",
    "**ë¶„ëŸ‰**: ì•½ 3000-4000 ë‹¨ì–´\n",
    "\n",
    "## ë…¼ë¬¸ êµ¬ì¡°\n",
    "\n",
    "ë‹¤ìŒ ì„¹ì…˜ì„ í¬í•¨í•˜ì„¸ìš”:\n",
    "\n",
    "1. **ì œëª©** - êµ¬ì²´ì ì´ê³  í•™ìˆ ì ì¸ ì œëª©\n",
    "2. **ì´ˆë¡ (Abstract)** - 200-300 ë‹¨ì–´, ë°°ê²½/ëª©ì /ë°©ë²•/ê²°ê³¼/ê²°ë¡ \n",
    "3. **ì„œë¡  (Introduction)** - ì—°êµ¬ ë°°ê²½, ì„ í–‰ì—°êµ¬, ì—°êµ¬ ì§ˆë¬¸/ê°€ì„¤\n",
    "4. **ë°©ë²• (Methods)** - ì°¸ê°€ì, ì¸¡ì •ë„êµ¬, ì ˆì°¨, ë¶„ì„ë°©ë²•\n",
    "5. **ê²°ê³¼ (Results)** - ê°€ìƒì˜ í†µê³„ ê²°ê³¼ í¬í•¨ (ì˜ˆ: t=2.45, p<.05)\n",
    "6. **ë…¼ì˜ (Discussion)** - ê²°ê³¼ í•´ì„, í•œê³„ì , í–¥í›„ ì—°êµ¬ ë°©í–¥\n",
    "7. **ì°¸ê³ ë¬¸í—Œ (References)** - APA í˜•ì‹ìœ¼ë¡œ 5-10ê°œ\n",
    "\n",
    "## ìš”êµ¬ì‚¬í•­\n",
    "- í•™ìˆ ì  í†¤ ìœ ì§€\n",
    "- êµ¬ì²´ì ì¸ ê°€ìƒ ë°ì´í„° í¬í•¨ (N, í‰ê· , í‘œì¤€í¸ì°¨, í†µê³„ì¹˜)\n",
    "- Markdown í˜•ì‹ ì‚¬ìš© (# ì œëª©, ## ì„¹ì…˜, **ê°•ì¡°** ë“±)\n",
    "- ì‹¤ì œ ì—°êµ¬ì²˜ëŸ¼ ë³´ì´ë„ë¡ ë””í…Œì¼í•˜ê²Œ ì‘ì„±\n",
    "\n",
    "ë…¼ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”:\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    generated_paper = response.content\n",
    "    \n",
    "    print(f\"\\nâœ… ë…¼ë¬¸ ìƒì„± ì™„ë£Œ! ({len(generated_paper)} ë¬¸ì)\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“„ ìƒì„±ëœ ë…¼ë¬¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 1000ì):\")\n",
    "    print(\"=\"*60)\n",
    "    print(generated_paper[:1000])\n",
    "    print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ìƒì„±ëœ ë…¼ë¬¸ ì €ì¥\n",
    "import re\n",
    "\n",
    "if 'generated_paper' in dir() and generated_paper:\n",
    "    # íŒŒì¼ëª… ìƒì„± (ì£¼ì œì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°)\n",
    "    safe_topic = re.sub(r'[^\\w\\sê°€-í£]', '', RESEARCH_TOPIC)[:30]\n",
    "    safe_topic = safe_topic.replace(' ', '_')\n",
    "    \n",
    "    filename = f\"sample_manuscript_{safe_topic}.md\"\n",
    "    filepath = os.path.join(INPUT_DIR, filename)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(generated_paper)\n",
    "    \n",
    "    print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filepath}\")\n",
    "    print(f\"   íŒŒì¼ í¬ê¸°: {len(generated_paper)} ë¬¸ì\")\n",
    "    \n",
    "    # sample_manuscript.mdë¡œë„ ë³µì‚¬ (ê¸°ë³¸ ìƒ˜í”Œë¡œ ì‚¬ìš©)\n",
    "    default_path = os.path.join(INPUT_DIR, \"sample_manuscript.md\")\n",
    "    with open(default_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(generated_paper)\n",
    "    print(f\"   + sample_manuscript.md ì—…ë°ì´íŠ¸\")\n",
    "    \n",
    "    print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"âŒ Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ C: ê¸°ì¡´ ìƒ˜í”Œ ë…¼ë¬¸ ì‚¬ìš©\n",
    "\n",
    "ì´ë¯¸ `sample_manuscript.md`ê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: ê¸°ì¡´ ìƒ˜í”Œ ë…¼ë¬¸ í™•ì¸\n",
    "sample_path = os.path.join(INPUT_DIR, \"sample_manuscript.md\")\n",
    "\n",
    "if os.path.exists(sample_path):\n",
    "    with open(sample_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # ì œëª© ì¶”ì¶œ ì‹œë„\n",
    "    lines = content.split('\\n')\n",
    "    title = \"(ì œëª© ì—†ìŒ)\"\n",
    "    for line in lines[:10]:\n",
    "        if line.startswith('# '):\n",
    "            title = line[2:].strip()\n",
    "            break\n",
    "    \n",
    "    print(\"âœ… ìƒ˜í”Œ ë…¼ë¬¸ì´ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"\\nğŸ“„ íŒŒì¼: {sample_path}\")\n",
    "    print(f\"ğŸ“ ì œëª©: {title}\")\n",
    "    print(f\"ğŸ“Š ë¶„ëŸ‰: {len(content)} ë¬¸ì\")\n",
    "    print(\"\\nâ†’ ë…¸íŠ¸ë¶ 3, 4ë¥¼ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âš ï¸ sample_manuscript.mdê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ì˜µì…˜ A ë˜ëŠ” Bë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ì„ ì¤€ë¹„í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬\n",
    "\n",
    "### ì¤€ë¹„ëœ ë…¼ë¬¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: ìµœì¢… í™•ì¸\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“‹ ë…¼ë¬¸ ì¤€ë¹„ ìƒíƒœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ëª¨ë“  ë…¼ë¬¸ íŒŒì¼ í™•ì¸\n",
    "all_papers = [f for f in os.listdir(INPUT_DIR) \n",
    "              if os.path.splitext(f)[1].lower() in SUPPORTED_EXT]\n",
    "\n",
    "if all_papers:\n",
    "    print(f\"\\nâœ… ì‚¬ìš© ê°€ëŠ¥í•œ ë…¼ë¬¸ ({len(all_papers)}ê°œ):\")\n",
    "    for f in all_papers:\n",
    "        filepath = os.path.join(INPUT_DIR, f)\n",
    "        size = os.path.getsize(filepath) / 1024\n",
    "        marker = \"â­\" if f == \"sample_manuscript.md\" else \"  \"\n",
    "        print(f\"   {marker} {f} ({size:.1f} KB)\")\n",
    "    \n",
    "    print(\"\\nâ­ = ê¸°ë³¸ ìƒ˜í”Œ (ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ìë™ ì‚¬ìš©)\")\n",
    "    print(\"\\nğŸ‰ ë‹¤ìŒ ë‹¨ê³„: ë…¸íŠ¸ë¶ 3 ë˜ëŠ” 4ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ìœ„ì˜ ì˜µì…˜ A, B, C ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "| ë…¸íŠ¸ë¶ | ë‚´ìš© | í•„ìš”í•œ íŒŒì¼ |\n",
    "|--------|------|-------------|\n",
    "| **3. AI Paper Review Agent** | agentic-paper-reviewë¡œ ë¦¬ë·° ë°›ê¸° | `input/sample_manuscript.md` |\n",
    "| **4. Transparent Peer Review** | Few-shot vs Agentic ë¹„êµ | `input/sample_manuscript.md` + ë…¸íŠ¸ë¶ 3 ê²°ê³¼ |\n",
    "\n",
    "### ë³¸ì¸ ë…¼ë¬¸ ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "ë…¸íŠ¸ë¶ 3, 4ì—ì„œ `MY_PAPER_PATH`ë¥¼ ì„¤ì •í•˜ë©´ ë³¸ì¸ ë…¼ë¬¸ìœ¼ë¡œ ì‹¤ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "MY_PAPER_PATH = \"input/ë‚´ë…¼ë¬¸.md\"  # ë˜ëŠ” .pdf, .docx\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}