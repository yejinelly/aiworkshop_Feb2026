{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.5: ìƒ˜í”Œ ë…¼ë¬¸ ì¤€ë¹„í•˜ê¸°\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. AI ë¦¬ë·°ë¥¼ ìœ„í•œ **ë…¼ë¬¸ ì›ê³  ì¤€ë¹„** ë°©ë²• ì´í•´\n",
    "2. ë³¸ì¸ ë…¼ë¬¸ ìƒíƒœì— ë§ëŠ” **ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±**\n",
    "3. ê° ì„¹ì…˜ë³„ ë‚´ìš©ì„ ì§€ì •í•˜ì—¬ **ë§ì¶¤í˜• ë…¼ë¬¸** ì‘ì„±\n",
    "\n",
    "---\n",
    "\n",
    "## ë…¼ë¬¸ ì¤€ë¹„ ì˜µì…˜\n",
    "\n",
    "| ì˜µì…˜ | í˜„ì¬ ìƒíƒœ | ìƒì„± ë‚´ìš© |\n",
    "|------|----------|----------|\n",
    "| **A. ë³¸ì¸ ë…¼ë¬¸** | ì™„ì„±ëœ ì´ˆê³  ìˆìŒ | ë³€í™˜ë§Œ (PDF/DOCX â†’ MD) |\n",
    "| **B. Methodë§Œ** | Method/í‘œë§Œ ìˆìŒ | Intro + Results + Discussion ì¶”ê°€ |\n",
    "| **C. ë…¼ë¬¸ ì—†ìŒ** | ì•„ë¬´ê²ƒë„ ì—†ìŒ | ì „ì²´ ë…¼ë¬¸ ìƒì„± (ì˜ì–´) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Colab í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "    os.chdir(WORKSHOP_DIR)\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "except ImportError:\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('notebooks'):\n",
    "        os.chdir('..')\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "# input í´ë” ìƒì„±\n",
    "INPUT_DIR = os.path.join(WORKSHOP_DIR, \"input\")\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")\n",
    "print(f\"ë…¼ë¬¸ ì €ì¥ ìœ„ì¹˜: {INPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: API Key ë¡œë”© ë° ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "import os\n",
    "\n",
    "# Colabì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "if IN_COLAB:\n",
    "    %pip install langchain-google-genai pdfplumber python-docx -q\n",
    "    print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        GEMINI_API_KEY = None\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(override=True)\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n",
    "    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
    "    print(\"âœ… Gemini API Key ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤ (ì˜µì…˜ B, C ì‚¬ìš© ì‹œ)\")\n",
    "    print(\"   ë°œê¸‰: https://aistudio.google.com/apikey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ A: ë³¸ì¸ ë…¼ë¬¸ ë³€í™˜\n",
    "\n",
    "ì´ë¯¸ ì™„ì„±ëœ ë…¼ë¬¸ ì´ˆê³ ê°€ ìˆì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. PDFë‚˜ Word íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: ë³¸ì¸ ë…¼ë¬¸ ë³€í™˜ (PDF/DOCX â†’ Markdown)\n\n# âœï¸ ë³€í™˜í•  íŒŒì¼ ê²½ë¡œ ì…ë ¥\nMY_FILE_PATH = \"\"  # ì˜ˆ: \"input/my_paper.pdf\" ë˜ëŠ” \"input/my_paper.docx\"\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nif not MY_FILE_PATH:\n    print(\"â„¹ï¸ MY_FILE_PATHì— íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n    print()\n    print(\"ì˜ˆì‹œ:\")\n    print('   MY_FILE_PATH = \"input/my_paper.pdf\"')\n    print('   MY_FILE_PATH = \"input/my_paper.docx\"')\n    print('   MY_FILE_PATH = \"/Users/name/Documents/thesis.pdf\"')\nelif not os.path.exists(MY_FILE_PATH):\n    print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MY_FILE_PATH}\")\nelse:\n    ext = os.path.splitext(MY_FILE_PATH)[1].lower()\n    text_content = \"\"\n    \n    if ext == '.pdf':\n        try:\n            import pdfplumber\n            with pdfplumber.open(MY_FILE_PATH) as pdf:\n                for page in pdf.pages:\n                    text_content += page.extract_text() or \"\"\n                    text_content += \"\\n\\n\"\n            print(f\"âœ… PDF ì¶”ì¶œ ì™„ë£Œ: {len(text_content)} ë¬¸ì\")\n        except ImportError:\n            print(\"âš ï¸ pdfplumber í•„ìš”: pip install pdfplumber\")\n            \n    elif ext in ['.docx', '.doc']:\n        try:\n            import docx\n            doc = docx.Document(MY_FILE_PATH)\n            text_content = \"\\n\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n            print(f\"âœ… Word ì¶”ì¶œ ì™„ë£Œ: {len(text_content)} ë¬¸ì\")\n        except ImportError:\n            print(\"âš ï¸ python-docx í•„ìš”: pip install python-docx\")\n            \n    elif ext in ['.md', '.txt']:\n        with open(MY_FILE_PATH, 'r', encoding='utf-8') as f:\n            text_content = f.read()\n        print(f\"âœ… í…ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(text_content)} ë¬¸ì\")\n    else:\n        print(f\"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}\")\n        print(\"   ì§€ì› í˜•ì‹: .pdf, .docx, .doc, .md, .txt\")\n    \n    # my_manuscript.mdë¡œ ì €ì¥\n    if text_content:\n        output_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n        \n        with open(output_path, 'w', encoding='utf-8') as f:\n            f.write(text_content)\n        \n        print(f\"\\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}\")\n        print(f\"\\nğŸ“„ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):\")\n        print(\"=\"*50)\n        print(text_content[:500])\n        print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\")"
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ì˜µì…˜ B: Methodë§Œ ìˆëŠ” ê²½ìš°\n\nMethods ì„¹ì…˜(í‘œ, ë¶„ì„ ê³„íš ë“±)ì€ ìˆì§€ë§Œ ë‹¤ë¥¸ ì„¹ì…˜ì´ ì—†ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  \nê¸°ì¡´ Methodsë¥¼ ë°”íƒ•ìœ¼ë¡œ Introduction, Results, Discussionì„ ìƒì„±í•©ë‹ˆë‹¤.\n\n> ğŸ’¡ **Tip**: Methodsê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ(ê¸°í›„ë¶ˆì•ˆ ì—°êµ¬)ì´ ìë™ ë¡œë“œë©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: ì˜µì…˜ B - Method ì…ë ¥ ë° ì„¹ì…˜ë³„ ë‚´ìš© ì§€ì •\n\n# âœï¸ Method íŒŒì¼ ê²½ë¡œ (ê¶Œì¥) ë˜ëŠ” ì§ì ‘ ë¶™ì—¬ë„£ê¸°\nMY_METHODS_PATH = \"\"  # ì˜ˆ: \"input/my_methods.md\" ë˜ëŠ” \"/Users/name/Documents/methods.docx\"\n\n# ë˜ëŠ” ì§ì ‘ ë¶™ì—¬ë„£ê¸° (íŒŒì¼ì´ ì—†ì„ ë•Œ)\nMY_METHODS = \"\"\"\n\n\"\"\"  # ì—¬ê¸°ì— ê¸°ì¡´ Methods ë‚´ìš©ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”\n\n# âœï¸ ê° ì„¹ì…˜ì— í¬í•¨í•  ë‚´ìš© (í‚¤ì›Œë“œë‚˜ ê°„ë‹¨í•œ ì„¤ëª…, ì„ íƒì‚¬í•­)\nINTRO_CONTENT = \"\"  # ì˜ˆ: \"climate anxiety, regional differences, longitudinal design\"\nRESULTS_CONTENT = \"\"  # ì˜ˆ: \"significant trajectory differences, coastal > urban, income moderation\"\nDISCUSSION_CONTENT = \"\"  # ì˜ˆ: \"targeted interventions, vulnerable populations, seasonal patterns\"\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n# 1ìˆœìœ„: íŒŒì¼ ê²½ë¡œì—ì„œ ë¡œë“œ\nif MY_METHODS_PATH:\n    if os.path.exists(MY_METHODS_PATH):\n        ext = os.path.splitext(MY_METHODS_PATH)[1].lower()\n        \n        if ext == '.pdf':\n            try:\n                import pdfplumber\n                with pdfplumber.open(MY_METHODS_PATH) as pdf:\n                    MY_METHODS = \"\\n\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n                print(f\"âœ… PDFì—ì„œ Method ë¡œë“œ: {MY_METHODS_PATH}\")\n            except ImportError:\n                print(\"âš ï¸ pdfplumber í•„ìš”: pip install pdfplumber\")\n        elif ext in ['.docx', '.doc']:\n            try:\n                import docx\n                doc = docx.Document(MY_METHODS_PATH)\n                MY_METHODS = \"\\n\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n                print(f\"âœ… Wordì—ì„œ Method ë¡œë“œ: {MY_METHODS_PATH}\")\n            except ImportError:\n                print(\"âš ï¸ python-docx í•„ìš”: pip install python-docx\")\n        elif ext in ['.md', '.txt']:\n            with open(MY_METHODS_PATH, 'r', encoding='utf-8') as f:\n                MY_METHODS = f.read()\n            print(f\"âœ… í…ìŠ¤íŠ¸ì—ì„œ Method ë¡œë“œ: {MY_METHODS_PATH}\")\n        else:\n            print(f\"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}\")\n    else:\n        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MY_METHODS_PATH}\")\n\n# 2ìˆœìœ„: ìƒ˜í”Œ Method ìë™ ë¡œë“œ (ë‘˜ ë‹¤ ë¹„ì–´ìˆì„ ë•Œ)\nif not MY_METHODS.strip():\n    SAMPLE_METHOD_PATH = os.path.join(INPUT_DIR, \"sample_method.md\")\n    if os.path.exists(SAMPLE_METHOD_PATH):\n        with open(SAMPLE_METHOD_PATH, 'r', encoding='utf-8') as f:\n            MY_METHODS = f.read()\n        print(\"ğŸ“‚ ìƒ˜í”Œ Method ìë™ ë¡œë“œ: sample_method.md\")\n        print(\"   (ê¸°í›„ë¶ˆì•ˆ ì²­ì†Œë…„ ì¢…ë‹¨ì—°êµ¬)\")\n    else:\n        print(\"âš ï¸ Methodê°€ ì—†ìŠµë‹ˆë‹¤.\")\n        print(\"   MY_METHODS_PATHì— íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ê±°ë‚˜\")\n        print(\"   MY_METHODSì— ì§ì ‘ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\")\n\n# ê²°ê³¼ ì¶œë ¥\nif MY_METHODS.strip():\n    print(f\"\\nğŸ“ Method ì…ë ¥ í™•ì¸:\")\n    print(f\"   - Method ê¸¸ì´: {len(MY_METHODS)} ë¬¸ì\")\n    print(f\"   - Introduction íŒíŠ¸: {INTRO_CONTENT or '(ìë™ ìƒì„±)'}\")\n    print(f\"   - Results íŒíŠ¸: {RESULTS_CONTENT or '(ìë™ ìƒì„±)'}\")\n    print(f\"   - Discussion íŒíŠ¸: {DISCUSSION_CONTENT or '(ìë™ ìƒì„±)'}\")\n    print(\"\\nâœ… ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë…¼ë¬¸ì„ ì™„ì„±í•˜ì„¸ìš”.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: ì˜µì…˜ B - Method ê¸°ë°˜ ë…¼ë¬¸ ì™„ì„± ë° ì €ì¥\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nif 'MY_METHODS' not in dir() or not MY_METHODS.strip():\n    print(\"âŒ ìœ„ ì…€(Cell 4)ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\nelse:\n    print(\"ğŸ”„ Methodë¥¼ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¬¸ ì™„ì„± ì¤‘...\")\n    \n    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n    \n    prompt = f\"\"\"You are a psychology researcher. I have a Methods section already written. \nPlease complete the paper by writing the other sections that match this methodology.\n\n## EXISTING METHODS (use this as the style and content guide)\n{MY_METHODS[:4000]}\n\n---\n\n## CONTENT HINTS FROM USER\n- Introduction should cover: {INTRO_CONTENT or 'relevant background and research gaps based on the methods'}\n- Results should include: {RESULTS_CONTENT or 'statistical findings consistent with the methods'}\n- Discussion should address: {DISCUSSION_CONTENT or 'interpretation, implications, and limitations'}\n\n---\n\n## YOUR TASK\nWrite a complete academic paper in **English** with these sections:\n\n1. **Title** - specific and academic\n2. **Abstract** (200-250 words) - background, purpose, methods, results, conclusion\n3. **Introduction** (800-1000 words)\n   - Research background and importance\n   - Literature review (cite 5-8 hypothetical studies)\n   - Research gap and hypotheses\n4. **Methods** - USE THE PROVIDED METHODS ABOVE (copy it exactly, just format as Markdown)\n5. **Results** (500-700 words)\n   - Statistical findings matching the methods\n   - Include: M, SD, t/F values, p values, effect sizes (d, r, Î·Â²)\n   - Reference to tables/figures\n6. **Discussion** (800-1000 words)\n   - Start with BIG PICTURE (not result listing)\n   - Interpretation with prior literature\n   - Theoretical and practical implications\n   - Limitations and future directions\n7. **References** (APA 7th, 8-12 references)\n\n## Requirements\n- Academic tone throughout\n- Results must be consistent with the provided Methods\n- Use Markdown format (# Title, ## Section, **bold**, etc.)\n- Maintain coherence between all sections\n\nWrite the complete paper:\n\"\"\"\n    \n    response = llm.invoke(prompt)\n    generated_paper = response.content\n    \n    # ìë™ ì €ì¥\n    output_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n    with open(output_path, 'w', encoding='utf-8') as f:\n        f.write(generated_paper)\n    \n    print(f\"\\nâœ… ë…¼ë¬¸ ì™„ì„± ë° ì €ì¥! ({len(generated_paper)} ë¬¸ì)\")\n    print(f\"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}\")\n    print(\"\\n\" + \"=\"*60)\n    print(\"ğŸ“„ ìƒì„±ëœ ë…¼ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\")\n    print(\"=\"*60)\n    print(generated_paper[:1500])\n    print(\"\\n...\")\n    print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ C: ë…¼ë¬¸ì´ ì „í˜€ ì—†ëŠ” ê²½ìš°\n",
    "\n",
    "**ì•„ë¬´ ì´ˆê³ ë„ ì—†ëŠ” ê²½ìš°** ì‚¬ìš©í•©ë‹ˆë‹¤. ê° ì„¹ì…˜ì— í¬í•¨í•  ë‚´ìš©ì„ ê°„ë‹¨íˆ ì…ë ¥í•˜ë©´ ì „ì²´ ë…¼ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "> **Language**: ì˜ì–´ (English)ë¡œ ìƒì„±ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ì˜µì…˜ C - ì„¹ì…˜ë³„ ë‚´ìš© ì§€ì •\n",
    "\n",
    "# âœï¸ ê° ì„¹ì…˜ì— í¬í•¨í•  ë‚´ìš© ì…ë ¥ (í‚¤ì›Œë“œ, ë¬¸ì¥, ë˜ëŠ” ê°„ë‹¨í•œ ì„¤ëª…)\n",
    "\n",
    "# Introductionì— ë“¤ì–´ê°ˆ ë‚´ìš©\n",
    "C_INTRO = \"\"  \n",
    "# ì˜ˆ: \"relationship between social media use and depression in adolescents, \n",
    "#      prior studies show mixed results, need for longitudinal design\"\n",
    "\n",
    "# Methodsì— ë“¤ì–´ê°ˆ ë‚´ìš©\n",
    "C_METHODS = \"\"  \n",
    "# ì˜ˆ: \"N=300 high school students, 6-month longitudinal, PHQ-9, social media use questionnaire,\n",
    "#      multilevel modeling\"\n",
    "\n",
    "# Resultsì— ë“¤ì–´ê°ˆ ë‚´ìš©\n",
    "C_RESULTS = \"\"  \n",
    "# ì˜ˆ: \"significant positive correlation, gender moderation effect, \n",
    "#      passive use more harmful than active use\"\n",
    "\n",
    "# Discussionì— ë“¤ì–´ê°ˆ ë‚´ìš©\n",
    "C_DISCUSSION = \"\"  \n",
    "# ì˜ˆ: \"implications for digital literacy education, parental involvement,\n",
    "#      limitation: self-report measures, future: experimental design\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "has_content = any([C_INTRO, C_METHODS, C_RESULTS, C_DISCUSSION])\n",
    "\n",
    "if has_content:\n",
    "    print(\"ğŸ“ ì„¹ì…˜ë³„ ë‚´ìš© í™•ì¸:\")\n",
    "    print(f\"   - Introduction: {C_INTRO[:80] + '...' if len(C_INTRO) > 80 else C_INTRO or '(ì—†ìŒ)'}\")\n",
    "    print(f\"   - Methods: {C_METHODS[:80] + '...' if len(C_METHODS) > 80 else C_METHODS or '(ì—†ìŒ)'}\")\n",
    "    print(f\"   - Results: {C_RESULTS[:80] + '...' if len(C_RESULTS) > 80 else C_RESULTS or '(ì—†ìŒ)'}\")\n",
    "    print(f\"   - Discussion: {C_DISCUSSION[:80] + '...' if len(C_DISCUSSION) > 80 else C_DISCUSSION or '(ì—†ìŒ)'}\")\n",
    "    print(\"\\nâœ… ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë…¼ë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âš ï¸ ê° ì„¹ì…˜ì— í¬í•¨í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "    print(\"\\nì˜ˆì‹œ:\")\n",
    "    print('C_INTRO = \"social media and adolescent depression, screen time effects\"')\n",
    "    print('C_METHODS = \"N=300 students, 6-month longitudinal, PHQ-9, multilevel modeling\"')\n",
    "    print('C_RESULTS = \"significant correlation r=0.35, gender moderation\"')\n",
    "    print('C_DISCUSSION = \"clinical implications, digital literacy education\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: ì˜µì…˜ C - Full ë…¼ë¬¸ ìƒì„±\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "has_content = any([C_INTRO, C_METHODS, C_RESULTS, C_DISCUSSION])\n",
    "\n",
    "if not has_content:\n",
    "    print(\"âŒ ìœ„ ì…€ì—ì„œ ì„¹ì…˜ë³„ ë‚´ìš©ì„ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"ğŸ”„ ì…ë ¥ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¬¸ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "    \n",
    "    prompt = f\"\"\"You are a psychology researcher. Write a complete academic paper based on the following content specifications.\n",
    "\n",
    "## USER'S CONTENT SPECIFICATIONS\n",
    "\n",
    "**Introduction should cover:**\n",
    "{C_INTRO or 'General psychology research topic - you may choose a relevant topic'}\n",
    "\n",
    "**Methods should include:**\n",
    "{C_METHODS or 'Standard quantitative methodology with appropriate sample and measures'}\n",
    "\n",
    "**Results should show:**\n",
    "{C_RESULTS or 'Significant findings that support the hypotheses'}\n",
    "\n",
    "**Discussion should address:**\n",
    "{C_DISCUSSION or 'Interpretation, implications, limitations, and future directions'}\n",
    "\n",
    "---\n",
    "\n",
    "## YOUR TASK\n",
    "Write a complete academic paper in **English** with these sections:\n",
    "\n",
    "1. **Title** - specific and academic, reflecting the content above\n",
    "\n",
    "2. **Abstract** (200-250 words)\n",
    "   - Background, purpose, methods, results, conclusion\n",
    "\n",
    "3. **Introduction** (800-1000 words)\n",
    "   - Research background and importance\n",
    "   - Literature review with 5-8 hypothetical citations\n",
    "   - Research gap identification\n",
    "   - Clear research questions and hypotheses\n",
    "\n",
    "4. **Methods** (600-800 words)\n",
    "   - Participants: sample size, demographics, recruitment\n",
    "   - Measures: scales with reliability coefficients\n",
    "   - Procedure: data collection process\n",
    "   - Data Analysis: statistical approach\n",
    "\n",
    "5. **Results** (500-700 words)\n",
    "   - Descriptive statistics\n",
    "   - Main analyses with specific statistics (M, SD, t, F, p, d, r, Î·Â²)\n",
    "   - Tables/figures references\n",
    "\n",
    "6. **Discussion** (800-1000 words)\n",
    "   - Start with BIG PICTURE meaning (not result listing!)\n",
    "   - Interpretation in context of prior research\n",
    "   - Theoretical and practical implications\n",
    "   - Limitations\n",
    "   - Future research directions\n",
    "   - Conclusion\n",
    "\n",
    "7. **References** (APA 7th format, 10-15 references)\n",
    "\n",
    "## Requirements\n",
    "- Academic tone throughout\n",
    "- All sections must be coherent and consistent\n",
    "- Use Markdown format (# Title, ## Section, **bold**, etc.)\n",
    "- Include specific hypothetical data that looks realistic\n",
    "\n",
    "Write the complete paper:\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    generated_paper = response.content\n",
    "    \n",
    "    print(f\"\\nâœ… ë…¼ë¬¸ ìƒì„± ì™„ë£Œ! ({len(generated_paper)} ë¬¸ì)\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“„ ìƒì„±ëœ ë…¼ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(\"=\"*60)\n",
    "    print(generated_paper[:1500])\n",
    "    print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: ì˜µì…˜ C - Full ë…¼ë¬¸ ìƒì„± ë° ì €ì¥\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nif 'C_INTRO' not in dir():\n    print(\"âŒ ìœ„ ì…€(Cell 6)ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\nelse:\n    has_content = any([C_INTRO, C_METHODS, C_RESULTS, C_DISCUSSION])\n    \n    if not has_content:\n        print(\"âŒ ìœ„ ì…€ì—ì„œ ì„¹ì…˜ë³„ ë‚´ìš©ì„ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”.\")\n    else:\n        print(\"ğŸ”„ ì…ë ¥ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë…¼ë¬¸ ìƒì„± ì¤‘...\")\n        \n        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n        \n        prompt = f\"\"\"You are a psychology researcher. Write a complete academic paper based on the following content specifications.\n\n## USER'S CONTENT SPECIFICATIONS\n\n**Introduction should cover:**\n{C_INTRO or 'General psychology research topic - you may choose a relevant topic'}\n\n**Methods should include:**\n{C_METHODS or 'Standard quantitative methodology with appropriate sample and measures'}\n\n**Results should show:**\n{C_RESULTS or 'Significant findings that support the hypotheses'}\n\n**Discussion should address:**\n{C_DISCUSSION or 'Interpretation, implications, limitations, and future directions'}\n\n---\n\n## YOUR TASK\nWrite a complete academic paper in **English** with these sections:\n\n1. **Title** - specific and academic, reflecting the content above\n\n2. **Abstract** (200-250 words)\n   - Background, purpose, methods, results, conclusion\n\n3. **Introduction** (800-1000 words)\n   - Research background and importance\n   - Literature review with 5-8 hypothetical citations\n   - Research gap identification\n   - Clear research questions and hypotheses\n\n4. **Methods** (600-800 words)\n   - Participants: sample size, demographics, recruitment\n   - Measures: scales with reliability coefficients\n   - Procedure: data collection process\n   - Data Analysis: statistical approach\n\n5. **Results** (500-700 words)\n   - Descriptive statistics\n   - Main analyses with specific statistics (M, SD, t, F, p, d, r, Î·Â²)\n   - Tables/figures references\n\n6. **Discussion** (800-1000 words)\n   - Start with BIG PICTURE meaning (not result listing!)\n   - Interpretation in context of prior research\n   - Theoretical and practical implications\n   - Limitations\n   - Future research directions\n   - Conclusion\n\n7. **References** (APA 7th format, 10-15 references)\n\n## Requirements\n- Academic tone throughout\n- All sections must be coherent and consistent\n- Use Markdown format (# Title, ## Section, **bold**, etc.)\n- Include specific hypothetical data that looks realistic\n\nWrite the complete paper:\n\"\"\"\n        \n        response = llm.invoke(prompt)\n        generated_paper = response.content\n        \n        # ìë™ ì €ì¥\n        output_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n        with open(output_path, 'w', encoding='utf-8') as f:\n            f.write(generated_paper)\n        \n        print(f\"\\nâœ… ë…¼ë¬¸ ìƒì„± ë° ì €ì¥! ({len(generated_paper)} ë¬¸ì)\")\n        print(f\"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_path}\")\n        print(\"\\n\" + \"=\"*60)\n        print(\"ğŸ“„ ìƒì„±ëœ ë…¼ë¬¸ ë¯¸ë¦¬ë³´ê¸°:\")\n        print(\"=\"*60)\n        print(generated_paper[:1500])\n        print(\"\\n...\")\n        print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ìµœì¢… í™•ì¸\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“‹ ë…¼ë¬¸ ì¤€ë¹„ ìƒíƒœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "my_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n",
    "sample_path = os.path.join(INPUT_DIR, \"sample_manuscript.md\")\n",
    "\n",
    "print(\"\\nğŸ“„ ë…¼ë¬¸ ë¡œë”© ìš°ì„ ìˆœìœ„ (ë…¸íŠ¸ë¶ 3, 4):\")\n",
    "\n",
    "if os.path.exists(my_path):\n",
    "    size = os.path.getsize(my_path) / 1024\n",
    "    print(f\"   1ìˆœìœ„: âœ… my_manuscript.md ({size:.1f} KB) â† ì‚¬ìš©ë¨\")\n",
    "else:\n",
    "    print(f\"   1ìˆœìœ„: âŒ my_manuscript.md (ì—†ìŒ)\")\n",
    "\n",
    "if os.path.exists(sample_path):\n",
    "    size = os.path.getsize(sample_path) / 1024\n",
    "    if os.path.exists(my_path):\n",
    "        print(f\"   2ìˆœìœ„: âœ… sample_manuscript.md ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   2ìˆœìœ„: âœ… sample_manuscript.md ({size:.1f} KB) â† ì‚¬ìš©ë¨\")\n",
    "else:\n",
    "    print(f\"   2ìˆœìœ„: âŒ sample_manuscript.md (ì—†ìŒ)\")\n",
    "\n",
    "# ê²°ê³¼\n",
    "if os.path.exists(my_path) or os.path.exists(sample_path):\n",
    "    print(\"\\nğŸ‰ ë‹¤ìŒ ë‹¨ê³„: ë…¸íŠ¸ë¶ 3 ë˜ëŠ” 4ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ìœ„ì˜ ì˜µì…˜ A, B, ë˜ëŠ” Cë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "| ë…¸íŠ¸ë¶ | ë‚´ìš© | í•„ìš”í•œ íŒŒì¼ |\n",
    "|--------|------|-------------|\n",
    "| **3. AI Paper Review Agent** | agentic-paper-reviewë¡œ ë¦¬ë·° ë°›ê¸° | `input/my_manuscript.md` |\n",
    "| **4. Transparent Peer Review** | Few-shot vs Agentic ë¹„êµ | `input/my_manuscript.md` + ë…¸íŠ¸ë¶ 3 ê²°ê³¼ |\n",
    "\n",
    "### ì˜µì…˜ ìš”ì•½\n",
    "\n",
    "| ì˜µì…˜ | ì…ë ¥ | ì¶œë ¥ |\n",
    "|------|------|------|\n",
    "| **A** | ì™„ì„±ëœ ë…¼ë¬¸ (PDF/DOCX) | `my_manuscript.md` |\n",
    "| **B** | Methods + ì„¹ì…˜ë³„ íŒíŠ¸ | `my_manuscript.md` (Methodê°€ few-shot ì—­í• ) |\n",
    "| **C** | ì„¹ì…˜ë³„ ë‚´ìš© ì§€ì • | `my_manuscript.md` (ì˜ì–´ ì „ì²´ ë…¼ë¬¸) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}