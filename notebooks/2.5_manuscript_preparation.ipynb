{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2.5: ìƒ˜í”Œ ë…¼ë¬¸ ì¤€ë¹„í•˜ê¸°\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. AI ë¦¬ë·°ë¥¼ ìœ„í•œ **ë…¼ë¬¸ ì›ê³  ì¤€ë¹„** ë°©ë²• ì´í•´\n",
    "2. ë³¸ì¸ ë…¼ë¬¸ì´ ì—†ëŠ” ê²½ìš° **ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±**\n",
    "3. ë…¼ë¬¸ì„ **Markdown í˜•ì‹**ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "---\n",
    "\n",
    "## ë…¼ë¬¸ ì¤€ë¹„ ì˜µì…˜\n",
    "\n",
    "| ì˜µì…˜ | ì„¤ëª… | ê¶Œì¥ ëŒ€ìƒ |\n",
    "|------|------|----------|\n",
    "| **A. ë³¸ì¸ ë…¼ë¬¸** | ì§ì ‘ ì‘ì„±í•œ ì´ˆê³  ì‚¬ìš© | ë…¼ë¬¸ ì‘ì„± ì¤‘ì¸ ë¶„ |\n",
    "| **B. AI ìƒì„±** | ê´€ì‹¬ ì£¼ì œë¡œ ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„± | ë³¸ì¸ ë…¼ë¬¸ì´ ì—†ëŠ” ë¶„ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Colab í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "    os.chdir(WORKSHOP_DIR)\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "except ImportError:\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('notebooks'):\n",
    "        os.chdir('..')\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "# input í´ë” ìƒì„±\n",
    "INPUT_DIR = os.path.join(WORKSHOP_DIR, \"input\")\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")\n",
    "print(f\"ë…¼ë¬¸ ì €ì¥ ìœ„ì¹˜: {INPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: API Key ë¡œë”© ë° ì˜ì¡´ì„± ì„¤ì¹˜\n",
    "import os\n",
    "\n",
    "# Colabì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "if IN_COLAB:\n",
    "    %pip install langchain-google-genai pdfplumber python-docx -q\n",
    "    print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        GEMINI_API_KEY = None\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(override=True)\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n",
    "    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
    "    print(\"âœ… Gemini API Key ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n",
    "    print(\"   ë°œê¸‰: https://aistudio.google.com/apikey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: ê¸°ì¡´ ë…¼ë¬¸ íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "\n",
    "# ì§€ì› í˜•ì‹\n",
    "SUPPORTED_EXT = ['.md', '.txt', '.pdf', '.docx']\n",
    "\n",
    "# ê¸°ì¡´ íŒŒì¼ í™•ì¸\n",
    "existing_files = [f for f in os.listdir(INPUT_DIR) \n",
    "                  if os.path.splitext(f)[1].lower() in SUPPORTED_EXT]\n",
    "\n",
    "print(f\"ğŸ“ input í´ë” í™•ì¸: {INPUT_DIR}\")\n",
    "print(f\"\\nğŸ“„ ë°œê²¬ëœ ë…¼ë¬¸ íŒŒì¼ ({len(existing_files)}ê°œ):\")\n",
    "\n",
    "if existing_files:\n",
    "    for f in existing_files:\n",
    "        size = os.path.getsize(os.path.join(INPUT_DIR, f)) / 1024\n",
    "        print(f\"   - {f} ({size:.1f} KB)\")\n",
    "    print(\"\\nâœ… ê¸°ì¡´ íŒŒì¼ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ì•„ë˜ì—ì„œ ìƒˆ ë…¼ë¬¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"   (ì—†ìŒ)\")\n",
    "    print(\"\\nâš ï¸ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì˜µì…˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ A: ë³¸ì¸ ë…¼ë¬¸ ë³€í™˜\n",
    "\n",
    "PDFë‚˜ Word íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: ë³¸ì¸ ë…¼ë¬¸ ë³€í™˜ (PDF/DOCX â†’ Markdown)\n",
    "\n",
    "# âœï¸ ë³€í™˜í•  íŒŒì¼ ê²½ë¡œ ì…ë ¥\n",
    "MY_FILE_PATH = \"\"  # ì˜ˆ: \"input/my_paper.pdf\" ë˜ëŠ” \"input/my_paper.docx\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "if MY_FILE_PATH and os.path.exists(MY_FILE_PATH):\n",
    "    ext = os.path.splitext(MY_FILE_PATH)[1].lower()\n",
    "    text_content = \"\"\n",
    "    \n",
    "    if ext == '.pdf':\n",
    "        try:\n",
    "            import pdfplumber\n",
    "            with pdfplumber.open(MY_FILE_PATH) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text_content += page.extract_text() or \"\"\n",
    "                    text_content += \"\\n\\n\"\n",
    "            print(f\"âœ… PDF ì¶”ì¶œ ì™„ë£Œ: {len(text_content)} ë¬¸ì\")\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ pdfplumber í•„ìš”: pip install pdfplumber\")\n",
    "            \n",
    "    elif ext in ['.docx', '.doc']:\n",
    "        try:\n",
    "            import docx\n",
    "            doc = docx.Document(MY_FILE_PATH)\n",
    "            text_content = \"\\n\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
    "            print(f\"âœ… Word ì¶”ì¶œ ì™„ë£Œ: {len(text_content)} ë¬¸ì\")\n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ python-docx í•„ìš”: pip install python-docx\")\n",
    "            \n",
    "    elif ext in ['.md', '.txt']:\n",
    "        with open(MY_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "            text_content = f.read()\n",
    "        print(f\"âœ… í…ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(text_content)} ë¬¸ì\")\n",
    "    \n",
    "    # my_manuscript.mdë¡œ ì €ì¥\n",
    "    if text_content:\n",
    "        output_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text_content)\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "        print(f\"\\nğŸ“„ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):\")\n",
    "        print(\"=\"*50)\n",
    "        print(text_content[:500])\n",
    "        print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    if MY_FILE_PATH:\n",
    "        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MY_FILE_PATH}\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ MY_FILE_PATHì— íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "        print(\"   ì˜ˆ: MY_FILE_PATH = 'input/my_paper.pdf'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì˜µì…˜ B: AIë¡œ ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„±\n",
    "\n",
    "ê´€ì‹¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ AIê°€ ìƒ˜í”Œ ë…¼ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ìƒ˜í”Œ ë…¼ë¬¸ ìƒì„± ì„¤ì •\n",
    "\n",
    "# âœï¸ ê´€ì‹¬ ì£¼ì œ ì…ë ¥ (í•œê¸€ ë˜ëŠ” ì˜ì–´)\n",
    "RESEARCH_TOPIC = \"\"  # ì˜ˆ: \"ì†Œì…œë¯¸ë””ì–´ì™€ ì²­ì†Œë…„ ìš°ìš¸ì¦ì˜ ê´€ê³„\"\n",
    "\n",
    "# âœï¸ ë…¼ë¬¸ ì–¸ì–´ ì„ íƒ\n",
    "PAPER_LANGUAGE = \"í•œêµ­ì–´\"  # \"í•œêµ­ì–´\" ë˜ëŠ” \"English\"\n",
    "\n",
    "# âœï¸ ì—°êµ¬ ë¶„ì•¼\n",
    "RESEARCH_FIELD = \"ì‹¬ë¦¬í•™\"  # ì˜ˆ: \"ì‹¬ë¦¬í•™\", \"ì¸ì§€ê³¼í•™\", \"ì‹ ê²½ê³¼í•™\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "if RESEARCH_TOPIC:\n",
    "    print(f\"ğŸ“ ì—°êµ¬ ì£¼ì œ: {RESEARCH_TOPIC}\")\n",
    "    print(f\"ğŸŒ ì–¸ì–´: {PAPER_LANGUAGE}\")\n",
    "    print(f\"ğŸ“š ë¶„ì•¼: {RESEARCH_FIELD}\")\n",
    "    print(\"\\nâœ… ë‹¤ìŒ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ë…¼ë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âš ï¸ RESEARCH_TOPICì— ê´€ì‹¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "    print(\"\\nì˜ˆì‹œ ì£¼ì œ:\")\n",
    "    print(\"   - ì†Œì…œë¯¸ë””ì–´ì™€ ì²­ì†Œë…„ ìš°ìš¸ì¦ì˜ ê´€ê³„\")\n",
    "    print(\"   - ëª…ìƒì´ ìŠ¤íŠ¸ë ˆìŠ¤ ê°ì†Œì— ë¯¸ì¹˜ëŠ” ì˜í–¥\")\n",
    "    print(\"   - AI ì±—ë´‡ì˜ ì‹¬ë¦¬ìƒë‹´ íš¨ê³¼\")\n",
    "    print(\"   - ìˆ˜ë©´ ë¶€ì¡±ì´ ì¸ì§€ ê¸°ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥\")\n",
    "    print(\"   - ê¸°í›„ ë¶ˆì•ˆê³¼ ì¹œí™˜ê²½ í–‰ë™ì˜ ê´€ê³„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: AI ë…¼ë¬¸ ìƒì„±\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "if not RESEARCH_TOPIC:\n",
    "    print(\"âŒ ìœ„ ì…€ì—ì„œ RESEARCH_TOPICì„ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(f\"ğŸ”„ '{RESEARCH_TOPIC}' ì£¼ì œë¡œ ë…¼ë¬¸ ìƒì„± ì¤‘...\")\n",
    "    print(\"   (1-2ë¶„ ì†Œìš”)\")\n",
    "    \n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ {RESEARCH_FIELD} ë¶„ì•¼ì˜ ì—°êµ¬ìì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ ì£¼ì œë¡œ í•™ìˆ  ë…¼ë¬¸ ì´ˆê³ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "**ì£¼ì œ**: {RESEARCH_TOPIC}\n",
    "**ì–¸ì–´**: {PAPER_LANGUAGE}\n",
    "**ë¶„ëŸ‰**: ì•½ 3000-4000 ë‹¨ì–´\n",
    "\n",
    "## ë…¼ë¬¸ êµ¬ì¡°\n",
    "\n",
    "ë‹¤ìŒ ì„¹ì…˜ì„ í¬í•¨í•˜ì„¸ìš”:\n",
    "\n",
    "1. **ì œëª©** - êµ¬ì²´ì ì´ê³  í•™ìˆ ì ì¸ ì œëª©\n",
    "2. **ì´ˆë¡ (Abstract)** - 200-300 ë‹¨ì–´, ë°°ê²½/ëª©ì /ë°©ë²•/ê²°ê³¼/ê²°ë¡ \n",
    "3. **ì„œë¡  (Introduction)** - ì—°êµ¬ ë°°ê²½, ì„ í–‰ì—°êµ¬, ì—°êµ¬ ì§ˆë¬¸/ê°€ì„¤\n",
    "4. **ë°©ë²• (Methods)** - ì°¸ê°€ì, ì¸¡ì •ë„êµ¬, ì ˆì°¨, ë¶„ì„ë°©ë²•\n",
    "5. **ê²°ê³¼ (Results)** - ê°€ìƒì˜ í†µê³„ ê²°ê³¼ í¬í•¨ (ì˜ˆ: t=2.45, p<.05)\n",
    "6. **ë…¼ì˜ (Discussion)** - ê²°ê³¼ í•´ì„, í•œê³„ì , í–¥í›„ ì—°êµ¬ ë°©í–¥\n",
    "7. **ì°¸ê³ ë¬¸í—Œ (References)** - APA í˜•ì‹ìœ¼ë¡œ 5-10ê°œ\n",
    "\n",
    "## ìš”êµ¬ì‚¬í•­\n",
    "- í•™ìˆ ì  í†¤ ìœ ì§€\n",
    "- êµ¬ì²´ì ì¸ ê°€ìƒ ë°ì´í„° í¬í•¨ (N, í‰ê· , í‘œì¤€í¸ì°¨, í†µê³„ì¹˜)\n",
    "- Markdown í˜•ì‹ ì‚¬ìš© (# ì œëª©, ## ì„¹ì…˜, **ê°•ì¡°** ë“±)\n",
    "- ì‹¤ì œ ì—°êµ¬ì²˜ëŸ¼ ë³´ì´ë„ë¡ ë””í…Œì¼í•˜ê²Œ ì‘ì„±\n",
    "\n",
    "ë…¼ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”:\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    generated_paper = response.content\n",
    "    \n",
    "    print(f\"\\nâœ… ë…¼ë¬¸ ìƒì„± ì™„ë£Œ! ({len(generated_paper)} ë¬¸ì)\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“„ ìƒì„±ëœ ë…¼ë¬¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 1000ì):\")\n",
    "    print(\"=\"*60)\n",
    "    print(generated_paper[:1000])\n",
    "    print(\"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ìƒì„±ëœ ë…¼ë¬¸ ì €ì¥\n",
    "import re\n",
    "\n",
    "if 'generated_paper' in dir() and generated_paper:\n",
    "    # my_manuscript.mdë¡œ ì €ì¥ (ë…¸íŠ¸ë¶ 3, 4ì—ì„œ 1ìˆœìœ„ë¡œ ì‚¬ìš©)\n",
    "    my_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n",
    "    \n",
    "    with open(my_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(generated_paper)\n",
    "    \n",
    "    print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {my_path}\")\n",
    "    print(f\"   íŒŒì¼ í¬ê¸°: {len(generated_paper)} ë¬¸ì\")\n",
    "    \n",
    "    # ì£¼ì œë³„ ë°±ì—… íŒŒì¼ë„ ì €ì¥\n",
    "    safe_topic = re.sub(r'[^\\w\\sê°€-í£]', '', RESEARCH_TOPIC)[:30]\n",
    "    safe_topic = safe_topic.replace(' ', '_')\n",
    "    backup_path = os.path.join(INPUT_DIR, f\"manuscript_{safe_topic}.md\")\n",
    "    \n",
    "    with open(backup_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(generated_paper)\n",
    "    print(f\"   + ë°±ì—…: {backup_path}\")\n",
    "    \n",
    "    print(\"\\nâœ… ë…¸íŠ¸ë¶ 3, 4ì—ì„œ ì´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\")\n",
    "    print(\"   (my_manuscript.md â†’ 1ìˆœìœ„)\")\n",
    "else:\n",
    "    print(\"âŒ ìœ„ ì…€ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: ìµœì¢… í™•ì¸\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“‹ ë…¼ë¬¸ ì¤€ë¹„ ìƒíƒœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ìš°ì„ ìˆœìœ„ í™•ì¸\n",
    "my_path = os.path.join(INPUT_DIR, \"my_manuscript.md\")\n",
    "sample_path = os.path.join(INPUT_DIR, \"sample_manuscript.md\")\n",
    "\n",
    "print(\"\\nğŸ“„ ë…¼ë¬¸ ë¡œë”© ìš°ì„ ìˆœìœ„ (ë…¸íŠ¸ë¶ 3, 4):\")\n",
    "if os.path.exists(my_path):\n",
    "    size = os.path.getsize(my_path) / 1024\n",
    "    print(f\"   1ìˆœìœ„: âœ… my_manuscript.md ({size:.1f} KB) â† ì‚¬ìš©ë¨\")\n",
    "else:\n",
    "    print(f\"   1ìˆœìœ„: âŒ my_manuscript.md (ì—†ìŒ)\")\n",
    "\n",
    "if os.path.exists(sample_path):\n",
    "    size = os.path.getsize(sample_path) / 1024\n",
    "    if os.path.exists(my_path):\n",
    "        print(f\"   2ìˆœìœ„: âœ… sample_manuscript.md ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   2ìˆœìœ„: âœ… sample_manuscript.md ({size:.1f} KB) â† ì‚¬ìš©ë¨\")\n",
    "else:\n",
    "    print(f\"   2ìˆœìœ„: âŒ sample_manuscript.md (ì—†ìŒ)\")\n",
    "\n",
    "# ê²°ê³¼\n",
    "if os.path.exists(my_path) or os.path.exists(sample_path):\n",
    "    print(\"\\nğŸ‰ ë‹¤ìŒ ë‹¨ê³„: ë…¸íŠ¸ë¶ 3 ë˜ëŠ” 4ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ìœ„ì˜ ì˜µì…˜ A ë˜ëŠ” Bë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "| ë…¸íŠ¸ë¶ | ë‚´ìš© | í•„ìš”í•œ íŒŒì¼ |\n",
    "|--------|------|-------------|\n",
    "| **3. AI Paper Review Agent** | agentic-paper-reviewë¡œ ë¦¬ë·° ë°›ê¸° | `input/my_manuscript.md` |\n",
    "| **4. Transparent Peer Review** | Few-shot vs Agentic ë¹„êµ | `input/my_manuscript.md` + ë…¸íŠ¸ë¶ 3 ê²°ê³¼ |\n",
    "\n",
    "### ë³¸ì¸ ë…¼ë¬¸ ì§ì ‘ ì§€ì •\n",
    "\n",
    "ë…¸íŠ¸ë¶ 3, 4ì—ì„œ `MY_PAPER_PATH`ë¥¼ ì„¤ì •í•˜ë©´ ë‹¤ë¥¸ íŒŒì¼ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "MY_PAPER_PATH = \"input/ë‹¤ë¥¸ë…¼ë¬¸.md\"  # ë˜ëŠ” .pdf, .docx\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
