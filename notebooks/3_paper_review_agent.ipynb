{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part 3: AI Paper Review Agent í™œìš©í•˜ê¸°\n\n**SNU AI Psychology Workshop - February 2026**\n\n---\n\n## í•™ìŠµ ëª©í‘œ\n1. ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ **Paper Review Agent** ë„êµ¬ë“¤ ì•Œì•„ë³´ê¸°\n2. **agentic-paper-review** ì„¤ì¹˜ ë° ì‹¤í–‰\n3. ë³¸ì¸ ë…¼ë¬¸ìœ¼ë¡œ AI ë¦¬ë·° ë°›ì•„ë³´ê¸°\n\n---\n\n## ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬ë“¤\n\n| ë„êµ¬ | íŠ¹ì§• | GitHub |\n|------|------|--------|\n| **agentic-paper-review** | LangGraph 9ë…¸ë“œ, Ï=0.74 | [debashis1983/agentic-paper-review](https://github.com/debashis1983/agentic-paper-review) |\n| **AgentReview** | ë‹¤ì¤‘ ì—ì´ì „íŠ¸, ë¦¬ë·°ì–´ ì„±ê²© ì‹œë®¬ë ˆì´ì…˜ | [Ahren09/AgentReview](https://github.com/Ahren09/AgentReview) |\n| **AI-Scientist** | ì „ì²´ ì—°êµ¬ íŒŒì´í”„ë¼ì¸ | [SakanaAI/AI-Scientist](https://github.com/SakanaAI/AI-Scientist) |\n\nì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **agentic-paper-review**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 1: Setup\n\n### API Key ë°œê¸‰ ë§í¬\n\n| API | ë§í¬ | ë¹„ê³  |\n|-----|------|------|\n| **OpenAI** (í•„ìˆ˜) | https://platform.openai.com/api-keys | agentic-paper-reviewì— í•„ìš” |\n| **Gemini** (ëŒ€ì•ˆ) | https://aistudio.google.com/apikey | ë¬´ë£Œ, ë„‰ë„‰í•œ quota |\n\n> âš ï¸ **agentic-paper-review**ëŠ” OpenAI APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: í™˜ê²½ ì„¤ì •\nimport os\nimport sys\n\n# Colab í™˜ê²½ ê°ì§€\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive/')\n    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n    os.chdir(WORKSHOP_DIR)\n    IN_COLAB = True\n    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\nexcept ImportError:\n    current_dir = os.getcwd()\n    if current_dir.endswith('notebooks'):\n        os.chdir('..')\n    WORKSHOP_DIR = os.getcwd()\n    IN_COLAB = False\n    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n\nprint(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: agentic-paper-review ì„¤ì¹˜\nimport os\n\nAGENT_DIR = os.path.join(WORKSHOP_DIR, \"agentic-paper-review\")\n\nif not os.path.exists(AGENT_DIR):\n    print(\"ğŸ“¥ agentic-paper-review í´ë¡  ì¤‘...\")\n    !git clone https://github.com/debashis1983/agentic-paper-review.git {AGENT_DIR}\n    print(\"âœ… í´ë¡  ì™„ë£Œ!\")\nelse:\n    print(f\"âœ… ì´ë¯¸ ì„¤ì¹˜ë¨: {AGENT_DIR}\")\n\n# ì˜ì¡´ì„± ì„¤ì¹˜\nprint(\"\\nğŸ“¦ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘...\")\n!pip install langgraph langchain langchain-openai langchain-anthropic pdfplumber tavily-python pymupdf -q\nprint(\"âœ… ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: API Key ë¡œë”©\nimport os\n\n# âœï¸ ì‚¬ìš©í•  API ì„ íƒ (ì•„ë˜ ì¤‘ í•˜ë‚˜ë§Œ ì£¼ì„ í•´ì œ)\n# USE_API = \"openai\"   # OpenAI ì‚¬ìš© (agentic-paper-review ê¸°ë³¸)\n# USE_API = \"gemini\"   # Gemini ì‚¬ìš© (ë¬´ë£Œ, ë‹¨ agentic-paper-reviewëŠ” OpenAIë§Œ ì§€ì›)\nUSE_API = \"auto\"       # ìë™ ì„ íƒ (OpenAI ìš°ì„ )\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# API Key ë¡œë”© (override=Trueë¡œ .env ë³€ê²½ì‚¬í•­ ë°˜ì˜)\nif IN_COLAB:\n    try:\n        from google.colab import userdata\n        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n    except:\n        OPENAI_API_KEY = None\n        GEMINI_API_KEY = None\nelse:\n    from dotenv import load_dotenv\n    load_dotenv(override=True)  # ë³€ê²½ëœ .env ê°•ì œ ë°˜ì˜\n    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n\n# API ì„ íƒ ë¡œì§\nAPI_PROVIDER = None\n\nif USE_API == \"openai\":\n    if OPENAI_API_KEY and not OPENAI_API_KEY.startswith('your_'):\n        os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n        API_PROVIDER = 'openai'\n        print(\"âœ… OpenAI API ì‚¬ìš© (ìˆ˜ë™ ì„ íƒ)\")\n    else:\n        print(\"âŒ OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤\")\n\nelif USE_API == \"gemini\":\n    if GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n        os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n        API_PROVIDER = 'gemini'\n        print(\"âœ… Gemini API ì‚¬ìš© (ìˆ˜ë™ ì„ íƒ)\")\n        print(\"   âš ï¸ ë‹¨, agentic-paper-reviewëŠ” OpenAIë§Œ ì§€ì›í•©ë‹ˆë‹¤\")\n    else:\n        print(\"âŒ Gemini API Keyê°€ ì—†ìŠµë‹ˆë‹¤\")\n\nelse:  # auto\n    if OPENAI_API_KEY and not OPENAI_API_KEY.startswith('your_'):\n        os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n        API_PROVIDER = 'openai'\n        print(\"âœ… OpenAI API ì‚¬ìš© (ìë™)\")\n        print(f\"   Key: {OPENAI_API_KEY[:8]}...{OPENAI_API_KEY[-4:]}\")\n    elif GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n        os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n        API_PROVIDER = 'gemini'\n        print(\"âœ… Gemini API ì‚¬ìš© (ìë™)\")\n        print(\"   âš ï¸ ë‹¨, agentic-paper-reviewëŠ” OpenAIë§Œ ì§€ì›í•©ë‹ˆë‹¤\")\n\nif API_PROVIDER is None:\n    print(\"âŒ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤!\")\n    print(\"   .env íŒŒì¼ì— OPENAI_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n    print(\"   ë°œê¸‰: https://platform.openai.com/api-keys\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n## Part 2: agentic-paper-review ì†Œê°œ\n\n### ì•„í‚¤í…ì²˜\n\n**9-Node LangGraph Workflow:**\n```\n[1. PDFâ†’MD] â†’ [2. ë©”íƒ€ë°ì´í„°] â†’ [3. ì¿¼ë¦¬ìƒì„±] â†’ [4. ì›¹ê²€ìƒ‰]\n      â†“\n[5. ê´€ë ¨ì„±í‰ê°€] â†’ [6. ë¦¬í”Œë ‰ì…˜] â†’ [7. ìš”ì•½] â†’ [8. ë¦¬ë·°ìƒì„±] â†’ [9. ì ìˆ˜ì‚°ì •]\n```\n\n> ğŸ’¡ **MD/TXT íŒŒì¼**: 1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ â†’ ë°”ë¡œ 2ë²ˆë¶€í„° ì‹œì‘\n> ğŸ’¡ **DOCX íŒŒì¼**: í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ 2ë²ˆë¶€í„° ì‹œì‘\n\n### í‰ê°€ ì°¨ì›\n- **Soundness**: ë°©ë²•ë¡ ì˜ ì—„ë°€ì„±\n- **Presentation**: ë…¼ë¬¸ì˜ ëª…í™•ì„±\n- **Contribution**: ê¸°ì—¬ë„\n\n### ì„±ëŠ¥\n- Spearman Ï = 0.74 (46,748ê°œ ì‹¤ì œ ë¦¬ë·°ë¡œ í•™ìŠµ)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: ë…¼ë¬¸ ë¡œë”© (PDF, MD, TXT, DOCX ëª¨ë‘ ì§€ì›)\nimport os\n\n# âœï¸ ë³¸ì¸ ë…¼ë¬¸ ê²½ë¡œ ì…ë ¥ (ë¹„ì›Œë‘ë©´ ìë™ íƒìƒ‰)\nMY_PAPER_PATH = \"\"  # ì˜ˆ: \"input/my_draft.pdf\"\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nPAPER_PATH = None\nPAPER_TEXT = None  # MD/TXT/DOCXì¸ ê²½ìš° í…ìŠ¤íŠ¸ ì €ì¥\n\n# 1ìˆœìœ„: ì§ì ‘ ì§€ì •í•œ ê²½ë¡œ\nif MY_PAPER_PATH and os.path.exists(MY_PAPER_PATH):\n    PAPER_PATH = MY_PAPER_PATH\n    ext = os.path.splitext(MY_PAPER_PATH)[1].lower()\n    \n    if ext == '.pdf':\n        print(f\"âœ… PDF ë…¼ë¬¸: {MY_PAPER_PATH}\")\n    elif ext in ['.md', '.txt']:\n        with open(MY_PAPER_PATH, 'r', encoding='utf-8') as f:\n            PAPER_TEXT = f.read()\n        print(f\"âœ… í…ìŠ¤íŠ¸ ë…¼ë¬¸: {MY_PAPER_PATH}\")\n    elif ext in ['.docx', '.doc']:\n        try:\n            import docx\n            doc = docx.Document(MY_PAPER_PATH)\n            PAPER_TEXT = \"\\n\".join([para.text for para in doc.paragraphs])\n            print(f\"âœ… Word ë…¼ë¬¸: {MY_PAPER_PATH}\")\n        except ImportError:\n            print(\"âš ï¸ python-docx í•„ìš”: pip install python-docx\")\n\n# 2ìˆœìœ„: my_manuscript.md (ë…¸íŠ¸ë¶ 2.5ì—ì„œ ìƒì„±)\nif PAPER_PATH is None:\n    MY_MANUSCRIPT = os.path.join(WORKSHOP_DIR, \"input\", \"my_manuscript.md\")\n    if os.path.exists(MY_MANUSCRIPT):\n        PAPER_PATH = MY_MANUSCRIPT\n        with open(MY_MANUSCRIPT, 'r', encoding='utf-8') as f:\n            PAPER_TEXT = f.read()\n        print(f\"âœ… ë‚´ ë…¼ë¬¸ ì‚¬ìš©: my_manuscript.md\")\n\n# 3ìˆœìœ„: sample_manuscript.md (ê¸°ë³¸ ìƒ˜í”Œ)\nif PAPER_PATH is None:\n    SAMPLE_PATH = os.path.join(WORKSHOP_DIR, \"input\", \"sample_manuscript.md\")\n    if os.path.exists(SAMPLE_PATH):\n        PAPER_PATH = SAMPLE_PATH\n        with open(SAMPLE_PATH, 'r', encoding='utf-8') as f:\n            PAPER_TEXT = f.read()\n        print(f\"ğŸ“„ ìƒ˜í”Œ ë…¼ë¬¸ ì‚¬ìš©: sample_manuscript.md\")\n        print(\"\")\n        print(\"=\"*50)\n        print(\"ğŸ’¡ ë³¸ì¸ ë…¼ë¬¸ìœ¼ë¡œ ì‹¤ìŠµí•˜ë ¤ë©´:\")\n        print(\"   1. ë…¸íŠ¸ë¶ 2.5 ì‹¤í–‰ â†’ my_manuscript.md ìƒì„±\")\n        print(\"   2. ë˜ëŠ” MY_PAPER_PATHì— íŒŒì¼ ê²½ë¡œ ì…ë ¥\")\n        print(\"=\"*50)\n\nif PAPER_PATH:\n    print(f\"\\nğŸ“„ ë…¼ë¬¸ ê²½ë¡œ: {PAPER_PATH}\")\n    if PAPER_TEXT:\n        print(f\"   í…ìŠ¤íŠ¸ ê¸¸ì´: {len(PAPER_TEXT)} ë¬¸ì\")\nelse:\n    print(\"âŒ ë…¼ë¬¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n    print(\"   ë…¸íŠ¸ë¶ 2.5ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 3: agentic-paper-review ì‹¤í–‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: agentic-paper-review ëª¨ë“ˆ ë¡œë”©\nimport sys\nsys.path.insert(0, AGENT_DIR)\n\ntry:\n    from agent import AgenticPaperReviewer\n    print(\"âœ… AgenticPaperReviewer ë¡œë”© ì™„ë£Œ\")\nexcept ImportError as e:\n    print(f\"âš ï¸ ëª¨ë“ˆ ë¡œë”© ì‹¤íŒ¨: {e}\")\n    print(\"   Cell 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš” (ì„¤ì¹˜)\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 6: ë¦¬ë·° ì‹¤í–‰\n# agentic-paper-reviewëŠ” paper_content íŒŒë¼ë¯¸í„°ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë°›ìœ¼ë©´\n# ìë™ìœ¼ë¡œ pdf_to_markdown ë…¸ë“œë¥¼ ìŠ¤í‚µí•©ë‹ˆë‹¤!\n\n# âœï¸ í•œê¸€ ë²ˆì—­ ì—¬ë¶€ (True = í•œê¸€, False = ì˜ì–´ ì›ë¬¸)\n# âš ï¸ ë²ˆì—­ ì‹œ ì¶”ê°€ API í˜¸ì¶œ ë°œìƒ â†’ rate limit ì£¼ì˜!\nTRANSLATE_TO_KOREAN = False  # ê¸°ë³¸ê°’: False (rate limit ë°©ì§€)\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nif PAPER_PATH:\n    print(f\"ğŸ”„ ë…¼ë¬¸ ë¦¬ë·° ì‹œì‘: {PAPER_PATH}\")\n    if PAPER_TEXT:\n        print(\"   (í…ìŠ¤íŠ¸ ì…ë ¥ â†’ 1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\")\n    print(\"   (1-2ë¶„ ì†Œìš”)\")\n    print(\"=\"*60)\n    \n    # ë¦¬ë·° ì‹¤í–‰\n    reviewer = AgenticPaperReviewer()\n    \n    if PAPER_TEXT:\n        # í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ paper_contentë¡œ ì „ë‹¬ (1ë²ˆ ë…¸ë“œ ìŠ¤í‚µ)\n        review_result = await reviewer.review_paper(\n            paper_content=PAPER_TEXT,\n            target_venue=\"Psychology\"\n        )\n    else:\n        # PDFë©´ paper_pathë¡œ ì „ë‹¬ (ì „ì²´ ì›Œí¬í”Œë¡œìš°)\n        review_result = await reviewer.review_paper(\n            paper_path=PAPER_PATH,\n            target_venue=\"Psychology\"\n        )\n    \n    print(\"âœ… ë¦¬ë·° ì™„ë£Œ!\")\n    \n    # í•œê¸€ ë²ˆì—­ (ì„ íƒì )\n    if TRANSLATE_TO_KOREAN and review_result and review_result.get('review'):\n        print(\"\\nğŸ”„ í•œê¸€ ë²ˆì—­ ì¤‘...\")\n        \n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n            \n            translator = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.1)\n            \n            translate_prompt = f\"\"\"ì•„ë˜ ì˜ì–´ ë…¼ë¬¸ ë¦¬ë·°ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.\ní•™ìˆ ì  í†¤ì„ ìœ ì§€í•˜ê³ , ì „ë¬¸ ìš©ì–´ëŠ” ì ì ˆíˆ ë²ˆì—­í•˜ê±°ë‚˜ ì˜ì–´ë¥¼ ë³‘ê¸°í•˜ì„¸ìš”.\në§ˆí¬ë‹¤ìš´ í˜•ì‹(##, **, - ë“±)ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.\n\n---\n{review_result['review']}\n---\n\ní•œêµ­ì–´ ë²ˆì—­:\"\"\"\n            \n            translated = translator.invoke(translate_prompt)\n            review_result['review_original'] = review_result['review']  # ì›ë¬¸ ë³´ê´€\n            review_result['review'] = translated.content\n            print(\"âœ… í•œê¸€ ë²ˆì—­ ì™„ë£Œ!\")\n            \n        except Exception as e:\n            print(f\"âš ï¸ ë²ˆì—­ ì‹¤íŒ¨ (ì›ë¬¸ ìœ ì§€): {e}\")\nelse:\n    print(\"âŒ ë…¼ë¬¸ ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš” (Cell 4)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: ê²°ê³¼ í™•ì¸\nif 'review_result' in dir() and review_result:\n    print(\"ğŸ“Š ë¦¬ë·° ê²°ê³¼\")\n    print(\"=\"*60)\n    \n    # ìƒíƒœ í™•ì¸\n    print(f\"\\nìƒíƒœ: {review_result.get('status', 'unknown')}\")\n    \n    # ë…¼ë¬¸ ì •ë³´\n    metadata = review_result.get('paper_metadata')\n    if metadata:\n        print(f\"\\nğŸ“„ ë…¼ë¬¸: {metadata.get('title', 'Unknown')}\")\n    \n    # ì ìˆ˜ ì¶œë ¥\n    scores = review_result.get('scores', {})\n    if scores.get('dimensions'):\n        print(\"\\nğŸ“ˆ ì ìˆ˜:\")\n        for dim in scores['dimensions']:\n            print(f\"  {dim['name']}: {dim['score']} - {dim['justification'][:50]}...\")\n    \n    if scores.get('final_score'):\n        print(f\"\\nğŸ¯ ìµœì¢… ì ìˆ˜: {scores['final_score_display']}\")\n    \n    # ë¦¬ë·° ì¶œë ¥\n    review = review_result.get('review', '')\n    if review:\n        print(\"\\nğŸ“‹ ë¦¬ë·°:\")\n        print(\"=\"*60)\n        print(review[:3000])  # ì²˜ìŒ 3000ìë§Œ\n        if len(review) > 3000:\n            print(f\"\\n... ({len(review)}ì ì¤‘ 3000ìë§Œ í‘œì‹œ)\")\n    \n    # ê´€ë ¨ ì—°êµ¬\n    related = review_result.get('related_works', [])\n    if related:\n        print(f\"\\nğŸ“š ê´€ë ¨ ì—°êµ¬ ({len(related)}ê°œ):\")\n        for w in related[:5]:\n            print(f\"  - {w['title'][:50]}... (ê´€ë ¨ë„: {w['relevance']:.2f})\")\n    \n    # ì—ëŸ¬ í™•ì¸\n    errors = review_result.get('metadata', {}).get('errors', [])\n    if errors:\n        print(f\"\\nâš ï¸ ì—ëŸ¬: {errors}\")\n    \n    print(\"=\"*60)\nelse:\n    print(\"âš ï¸ Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 8: ê²°ê³¼ ì €ì¥ (JSON + Markdown)\nimport json\nimport os\nfrom datetime import datetime\n\nif 'review_result' in dir() and review_result:\n    output_dir = os.path.join(WORKSHOP_DIR, \"outputs\", \"3_agent_result\")\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    # None ê°’ ì•ˆì „ ì²˜ë¦¬\n    paper_metadata = review_result.get('paper_metadata') or {}\n    scores = review_result.get('scores') or {}\n    dimensions = scores.get('dimensions') or []\n    related_works = review_result.get('related_works') or []\n    metadata_obj = review_result.get('metadata') or {}\n    \n    # review_resultëŠ” ë”•ì…”ë„ˆë¦¬ì„\n    result_dict = {\n        \"method\": \"agentic-paper-review\",\n        \"paper_path\": PAPER_PATH,\n        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"status\": review_result.get('status', 'unknown'),\n        \"paper_metadata\": paper_metadata,\n        \"review\": review_result.get('review', ''),\n        \"scores\": scores,\n        \"related_works\": related_works,\n        \"errors\": metadata_obj.get('errors', [])\n    }\n    \n    # 1. JSON ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)\n    json_path = os.path.join(output_dir, f\"review_{timestamp}.json\")\n    with open(json_path, 'w', encoding='utf-8') as f:\n        json.dump(result_dict, f, ensure_ascii=False, indent=2)\n    \n    # 2. Markdown ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)\n    md_path = os.path.join(output_dir, f\"review_{timestamp}.md\")\n    \n    md_content = f\"\"\"# AI Paper Review (agentic-paper-review)\n\n**ìƒì„± ì‹œê°„**: {result_dict['timestamp']}\n\n## ë…¼ë¬¸ ì •ë³´\n- **ì œëª©**: {paper_metadata.get('title', 'Unknown')}\n- **ìƒíƒœ**: {result_dict.get('status', 'unknown')}\n- **ìµœì¢… ì ìˆ˜**: {scores.get('final_score_display', 'N/A')}\n\n## ì ìˆ˜ ìƒì„¸\n\"\"\"\n    for dim in dimensions:\n        md_content += f\"- **{dim.get('name', 'N/A')}**: {dim.get('score', 'N/A')} - {dim.get('justification', 'N/A')}\\n\"\n    \n    md_content += f\"\"\"\n## ë¦¬ë·°\n{result_dict.get('review', 'ë¦¬ë·° ì—†ìŒ')}\n\n## ê´€ë ¨ ì—°êµ¬\n\"\"\"\n    for w in related_works:\n        arxiv_id = w.get('arxiv_id', '')\n        title = w.get('title', 'Unknown')\n        relevance = w.get('relevance', 0)\n        md_content += f\"- [{title}](https://arxiv.org/abs/{arxiv_id}) (ê´€ë ¨ë„: {relevance:.2f})\\n\"\n    \n    with open(md_path, 'w', encoding='utf-8') as f:\n        f.write(md_content)\n    \n    # ìµœì‹  ê²°ê³¼ë¥¼ review.jsonìœ¼ë¡œë„ ì €ì¥ (ë…¸íŠ¸ë¶ 4 ë¹„êµìš©)\n    latest_json = os.path.join(output_dir, \"review.json\")\n    with open(latest_json, 'w', encoding='utf-8') as f:\n        json.dump(result_dict, f, ensure_ascii=False, indent=2)\n    \n    print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥:\")\n    print(f\"   JSON: {json_path}\")\n    print(f\"   Markdown: {md_path}\")\n    print(f\"   (+ review.json ìµœì‹  ë²„ì „ ì—…ë°ì´íŠ¸)\")\n    print(f\"   ë¦¬ë·° ê¸¸ì´: {len(result_dict.get('review', ''))} ë¬¸ì\")\n    print(f\"   ì ìˆ˜: {scores.get('final_score_display', 'N/A')}\")\nelse:\n    print(\"âš ï¸ ë¦¬ë·° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n## Part 4: ê²°ê³¼ ê³µìœ  ë° í† ë¡ \n\n### ê²°ê³¼ ì œì¶œ ë°©ë²•\n\n1. **ì•„ë˜ ì…€ì—ì„œ ì´ë¦„ ì…ë ¥**\n2. **ì…€ ì‹¤í–‰ â†’ íŒŒë€ ë²„íŠ¼ í´ë¦­**\n3. **í¼ì—ì„œ ì˜ê²¬ ì‘ì„± í›„ ì œì¶œ**\n\n> ì ìˆ˜ëŠ” ìë™ ì…ë ¥ë©ë‹ˆë‹¤!\n\n### ë§í¬\n\n| ìš©ë„ | ë§í¬ |\n|------|------|\n| **ì§ì ‘ ì œì¶œ** (ìë™ ì…ë ¥ ì•ˆ ë  ë•Œ) | [Google Forms](https://docs.google.com/forms/d/e/1FAIpQLSfciPtMCZTSNyGvutdFGSdcUjKSdu98Vm7gVPe6TvVcGQKK2g/viewform) |\n| **ê²°ê³¼ í™•ì¸** | [Google Sheet](https://docs.google.com/spreadsheets/d/1wPGTOPGF5yvWQTimikr-rg2VExXiHCE0Xn2EVkffWfo/edit?usp=sharing) |\n\n### í† ë¡  ì§ˆë¬¸\n\n1. **AI ë¦¬ë·°ê°€ ìœ ìš©í–ˆë‚˜ìš”?** (1-5ì )\n2. **ì–´ë–¤ ì ì´ ìœ ìš©í–ˆë‚˜ìš”?**\n3. **ì‹¤ì œ ë¦¬ë·°ì™€ ê³µí†µì **ì€?\n4. **ì‹¤ì œ ë¦¬ë·°ì™€ ì°¨ì´ì **ì€?\n5. **ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„**ì€?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: ê²°ê³¼ ì œì¶œ\n# ============================================================\n# ì´ë¦„ë§Œ ì…ë ¥í•˜ì„¸ìš”! ë‚˜ë¨¸ì§€ëŠ” ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.\n# ============================================================\n\nPARTICIPANT_NAME = \"\"  # <- ë³¸ì¸ ì´ë¦„\n\n# ============================================================\n# ì‹¤í—˜ ê²°ê³¼ ìë™ ìˆ˜ì§‘\n# ============================================================\nimport urllib.parse\nimport json\nfrom datetime import datetime\nfrom IPython.display import display, HTML\n\nif not PARTICIPANT_NAME:\n    print(\"âš ï¸  PARTICIPANT_NAMEì„ ì…ë ¥í•˜ì„¸ìš”!\")\nelif 'review_result' not in dir() or not review_result:\n    print(\"âš ï¸  Cell 6ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”! (ë¦¬ë·° ì‹¤í–‰)\")\nelse:\n    # ê²°ê³¼ ì¶”ì¶œ\n    scores = review_result.get('scores', {})\n    dimensions = scores.get('dimensions', [])\n    \n    # ì ìˆ˜ ì¶”ì¶œ\n    final_score = scores.get('final_score_display', '')\n    soundness = \"\"\n    presentation = \"\"\n    contribution = \"\"\n    \n    for dim in dimensions:\n        name = dim.get('name', '').lower()\n        score = str(dim.get('score', ''))\n        if 'sound' in name:\n            soundness = score\n        elif 'present' in name:\n            presentation = score\n        elif 'contribu' in name:\n            contribution = score\n    \n    # ì‚¬ìš©í•œ ë…¼ë¬¸ ìœ í˜•\n    paper_type = \"ìƒ˜í”Œ ë…¼ë¬¸\" if \"sample_manuscript\" in PAPER_PATH else \"ë³¸ì¸ ë…¼ë¬¸\"\n    \n    # Pre-filled Google Form URL ìƒì„±\n    FORM_BASE = \"https://docs.google.com/forms/d/e/1FAIpQLSfciPtMCZTSNyGvutdFGSdcUjKSdu98Vm7gVPe6TvVcGQKK2g/viewform?usp=pp_url\"\n    \n    params = {\n        \"entry.1176756138\": PARTICIPANT_NAME,  # ì´ë¦„\n        \"entry.1543210690\": paper_type,        # ì‚¬ìš©í•œ ë…¼ë¬¸\n        \"entry.538415097\": final_score,        # ìµœì¢… ì ìˆ˜\n        \"entry.233528916\": soundness,          # Soundness\n        \"entry.2053546740\": presentation,      # Presentation\n        \"entry.1438513897\": contribution,      # Contribution\n        # ë‚˜ë¨¸ì§€ëŠ” í¼ì—ì„œ ì§ì ‘ ì‘ì„±\n        # entry.620778037: AI ë¦¬ë·° ìœ ìš©ì„± (1-5)\n        # entry.1900039021: ì–´ë–¤ ì ì´ ìœ ìš©í–ˆë‚˜ìš”?\n        # entry.2048465412: ì‹¤ì œ ë¦¬ë·°ì™€ ê³µí†µì \n        # entry.1192534948: ì‹¤ì œ ë¦¬ë·°ì™€ ì°¨ì´ì \n        # entry.1803074178: ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„\n    }\n    \n    form_url = FORM_BASE + \"&\" + urllib.parse.urlencode(params)\n    \n    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n    print(\"=\" * 70)\n    print(\"ğŸ“‹ ì œì¶œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°\")\n    print(\"=\" * 70)\n    print(f\"\\nğŸ‘¤ ì´ë¦„: {PARTICIPANT_NAME}\")\n    print(f\"ğŸ“„ ë…¼ë¬¸: {paper_type}\")\n    print(f\"\\nğŸ¯ ìµœì¢… ì ìˆ˜: {final_score}\")\n    print(f\"   Soundness: {soundness}\")\n    print(f\"   Presentation: {presentation}\")\n    print(f\"   Contribution: {contribution}\")\n    \n    # í´ë¦­ ê°€ëŠ¥í•œ ë§í¬ ì¶œë ¥\n    print(\"\\n\" + \"=\" * 70)\n    print(\"ğŸ”— ì•„ë˜ ë²„íŠ¼ í´ë¦­ â†’ ì˜ê²¬ ì‘ì„± â†’ ì œì¶œ\")\n    print(\"=\" * 70)\n    \n    display(HTML(f'''\n    <a href=\"{form_url}\" target=\"_blank\" \n       style=\"display:inline-block; font-size:16px; padding:12px 24px; \n              background:#4285f4; color:white; text-decoration:none; \n              border-radius:5px; margin:10px 0;\">\n       ğŸ“ ê²°ê³¼ ì œì¶œí•˜ê¸° (í´ë¦­)\n    </a>\n    <p style=\"color:#666; font-size:12px;\">â€» ì ìˆ˜ëŠ” ìë™ ì…ë ¥ë©ë‹ˆë‹¤. ì˜ê²¬ë§Œ ì‘ì„±í•˜ì„¸ìš”!</p>\n    '''))\n    \n    # ë¡œì»¬ ë°±ì—… ì €ì¥\n    save_data = {\n        'participant': PARTICIPANT_NAME,\n        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n        'paper_type': paper_type,\n        'scores': {\n            'final': final_score,\n            'soundness': soundness,\n            'presentation': presentation,\n            'contribution': contribution\n        },\n        'review': review_result.get('review', '')[:500]  # ì²˜ìŒ 500ìë§Œ\n    }\n    \n    if IN_COLAB:\n        save_folder = \"/content/drive/MyDrive/aiworkshop_Feb2026/outputs/3_agent_result/\"\n    else:\n        save_folder = os.path.join(WORKSHOP_DIR, \"outputs\", \"3_agent_result\")\n    \n    os.makedirs(save_folder, exist_ok=True)\n    filename = f\"{PARTICIPANT_NAME}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    filepath = os.path.join(save_folder, filename)\n    \n    with open(filepath, 'w', encoding='utf-8') as f:\n        json.dump(save_data, f, ensure_ascii=False, indent=2)\n    \n    print(f\"\\nâœ“ ë¡œì»¬ ë°±ì—…: {filepath}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n## ì •ë¦¬\n\n### ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ê²ƒ\n\n1. **ê¸°ì¡´ ì˜¤í”ˆì†ŒìŠ¤ Paper Review Agent ë„êµ¬ë“¤** íƒìƒ‰\n   - agentic-paper-review, AgentReview, AI-Scientist\n2. **agentic-paper-review ì‹¤í–‰**: Python APIë¡œ ë…¼ë¬¸ ë¦¬ë·°\n3. **LangGraph ê¸°ë°˜ 9ë…¸ë“œ ì›Œí¬í”Œë¡œìš°** ì´í•´\n   - PDFâ†’MD â†’ ë©”íƒ€ë°ì´í„° â†’ ì¿¼ë¦¬ìƒì„± â†’ ì›¹ê²€ìƒ‰ â†’ ê´€ë ¨ì„±í‰ê°€ â†’ ë¦¬í”Œë ‰ì…˜ â†’ ìš”ì•½ â†’ ë¦¬ë·°ìƒì„± â†’ ì ìˆ˜ì‚°ì •\n4. **ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì§€ì›**: PDF, MD, TXT, DOCX\n\n### ë‹¤ìŒ ë…¸íŠ¸ë¶ ì˜ˆê³ \n\n- **Notebook 4**: ì§ì ‘ ë¦¬ë·° ì—ì´ì „íŠ¸ êµ¬í˜„ & ê²°ê³¼ ë¹„êµ\n\n### ì°¸ê³  ìë£Œ\n\n- agentic-paper-review: https://github.com/debashis1983/agentic-paper-review\n- AgentReview Paper: https://arxiv.org/abs/2406.12708\n- LangGraph Docs: https://python.langchain.com/docs/langgraph"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}