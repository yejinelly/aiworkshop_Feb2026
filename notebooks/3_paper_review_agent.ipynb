{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Paper Review Agent with LangGraph\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. **Agent** ê°œë… ì´í•´í•˜ê¸°\n",
    "2. **LangGraph**ë¡œ ë‹¨ê³„ë³„ ì›Œí¬í”Œë¡œìš° êµ¬í˜„\n",
    "3. ë…¼ë¬¸ ë¦¬ë·° Agent ë§Œë“¤ê¸° (7ì°¨ì› í‰ê°€)\n",
    "4. ê° ë‹¨ê³„ë³„ ì¶œë ¥ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì • (Colab/ë¡œì»¬ ìë™ ê°ì§€)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Colab í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "    os.chdir(WORKSHOP_DIR)\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "except ImportError:\n",
    "    # ë¡œì»¬ í™˜ê²½: í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('notebooks'):\n",
    "        os.chdir('..')\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "print(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
    "    %pip install langgraph langchain-openai langchain-google-genai python-dotenv -q\n",
    "    print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âœ… ë¡œì»¬ í™˜ê²½: pyproject.tomlë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: API Key ë¡œë”© ë° LLM ì„ íƒ\n",
    "import os\n",
    "\n",
    "# API Key ë¡œë”©\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        OPENAI_API_KEY = None\n",
    "        GEMINI_API_KEY = None\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# LLM ì„ íƒ (OpenAI ìš°ì„ , Gemini ëŒ€ì•ˆ)\n",
    "LLM_PROVIDER = None\n",
    "\n",
    "if OPENAI_API_KEY and not OPENAI_API_KEY.startswith('your_'):\n",
    "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "    LLM_PROVIDER = 'openai'\n",
    "    print(\"âœ… OpenAI API ì‚¬ìš© (ê¸°ë³¸)\")\n",
    "elif GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n",
    "    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
    "    LLM_PROVIDER = 'gemini'\n",
    "    print(\"âœ… Gemini API ì‚¬ìš© (OpenAI ì—†ìŒ)\")\n",
    "else:\n",
    "    print(\"âŒ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤!\")\n",
    "    print(\"   .env íŒŒì¼ì— OPENAI_API_KEY ë˜ëŠ” GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: LLM ì´ˆê¸°í™”\n",
    "if LLM_PROVIDER == 'openai':\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    print(f\"ğŸ¤– LLM: OpenAI gpt-4o-mini\")\n",
    "    \n",
    "elif LLM_PROVIDER == 'gemini':\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3)\n",
    "    print(f\"ğŸ¤– LLM: Google Gemini 1.5 Flash\")\n",
    "    \n",
    "else:\n",
    "    llm = None\n",
    "    print(\"âš ï¸ LLMì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: ìƒ˜í”Œ ë…¼ë¬¸ ë¡œë”©\nimport os\n\n# ìƒ˜í”Œ ë…¼ë¬¸ ê²½ë¡œ\nSAMPLE_PATH = os.path.join(WORKSHOP_DIR, \"input\", \"sample_manuscript.md\")\n\nif os.path.exists(SAMPLE_PATH):\n    with open(SAMPLE_PATH, 'r', encoding='utf-8') as f:\n        SAMPLE_PAPER = f.read()\n    print(f\"âœ… ìƒ˜í”Œ ë…¼ë¬¸ ë¡œë”©: {SAMPLE_PATH}\")\nelse:\n    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒ˜í”Œ ì‚¬ìš©\n    SAMPLE_PAPER = \"\"\"\nTITLE: The Effects of Mindfulness-Based Cognitive Therapy on Depression Relapse Prevention\n\nABSTRACT:\nThis randomized controlled trial evaluated MBCT compared to treatment as usual (TAU) \nin preventing depression relapse over 12 months. 256 participants with recurrent MDD \nin remission were randomized. Results showed MBCT+TAU had significantly lower relapse \nrates (31%) compared to TAU (48%) at 12 months (HR=0.58, p=.008).\n\nMETHODS:\nParticipants were randomized to MBCT+TAU (n=128) or TAU alone (n=128). Primary outcome \nwas time to relapse. Secondary outcomes included mindfulness skills, rumination, and \nself-compassion.\n\nRESULTS:\nMediation analyses revealed that increases in mindfulness skills and decreases in \nrumination partially mediated treatment effects.\n\nCONCLUSIONS:\nMBCT effectively prevents depression relapse with mindfulness skills and reduced \nrumination serving as key mechanisms.\n\"\"\"\n    print(\"âš ï¸ ìƒ˜í”Œ íŒŒì¼ ì—†ìŒ - ê¸°ë³¸ ìƒ˜í”Œ ì‚¬ìš©\")\n\n# ë…¼ë¬¸ ì •ë³´ ì¶œë ¥\nlines = SAMPLE_PAPER.strip().split('\\n')\ntitle = lines[0].replace('#', '').strip() if lines else \"Unknown\"\nprint(f\"\\nğŸ“„ ìƒ˜í”Œ ë…¼ë¬¸ ì¤€ë¹„ ì™„ë£Œ\")\nprint(f\"   ì œëª©: {title[:60]}...\")\nprint(f\"   ê¸¸ì´: {len(SAMPLE_PAPER)} ë¬¸ì\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Agent ê°œë… ì†Œê°œ\n",
    "\n",
    "### Agentë€?\n",
    "\n",
    "**Agent** = LLM + ë„êµ¬ + ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸ì™€ì˜ ì°¨ì´:\n",
    "\n",
    "| | ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸ | Agent |\n",
    "|--|-------------|-------|\n",
    "| êµ¬ì¡° | í•œ ë²ˆì— ëª¨ë“  ê²ƒ | ë‹¨ê³„ë³„ ì²˜ë¦¬ |\n",
    "| ì¤‘ê°„ ê²°ê³¼ | ë³¼ ìˆ˜ ì—†ìŒ | ê° ë‹¨ê³„ í™•ì¸ ê°€ëŠ¥ |\n",
    "| ì—ëŸ¬ ì²˜ë¦¬ | ì²˜ìŒë¶€í„° ë‹¤ì‹œ | ì‹¤íŒ¨í•œ ë‹¨ê³„ë§Œ ì¬ì‹œë„ |\n",
    "| ë³µì¡í•œ ì‘ì—… | í’ˆì§ˆ ë¶ˆì•ˆì • | ì•ˆì •ì  |\n",
    "\n",
    "### LangGraph ê¸°ë³¸ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "[ì‹œì‘] â†’ [Node 1] â†’ [Node 2] â†’ [Node 3] â†’ [ì¢…ë£Œ]\n",
    "           â†“           â†“           â†“\n",
    "        Output 1    Output 2    Output 3\n",
    "```\n",
    "\n",
    "ê° **Node**ëŠ” í•˜ë‚˜ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ , ê²°ê³¼ë¥¼ **State**ì— ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: LangGraph ê¸°ë³¸ êµ¬ì¡° ì •ì˜\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# State: Agentê°€ ê³µìœ í•˜ëŠ” ë°ì´í„°\n",
    "class ReviewState(TypedDict):\n",
    "    paper: str              # ì…ë ¥ ë…¼ë¬¸\n",
    "    summary: str            # ìš”ì•½\n",
    "    strengths: str          # ê°•ì \n",
    "    weaknesses: str         # ì•½ì \n",
    "    scores: dict            # 7ì°¨ì› ì ìˆ˜\n",
    "    final_review: str       # ìµœì¢… ë¦¬ë·°\n",
    "\n",
    "print(\"âœ… State ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"\")\n",
    "print(\"ReviewState êµ¬ì¡°:\")\n",
    "print(\"  - paper: ì…ë ¥ ë…¼ë¬¸\")\n",
    "print(\"  - summary: ë…¼ë¬¸ ìš”ì•½\")\n",
    "print(\"  - strengths: ê°•ì  ë¶„ì„\")\n",
    "print(\"  - weaknesses: ì•½ì  ë¶„ì„\")\n",
    "print(\"  - scores: 7ì°¨ì› í‰ê°€ ì ìˆ˜\")\n",
    "print(\"  - final_review: ìµœì¢… ë¦¬ë·°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: ë‹¨ê³„ë³„ Node êµ¬í˜„\n",
    "\n",
    "ì´ì œ ê° Nodeë¥¼ í•˜ë‚˜ì”© êµ¬í˜„í•˜ê³  ì‹¤í–‰í•´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "### Node êµ¬ì¡°\n",
    "```\n",
    "[ë…¼ë¬¸] â†’ [ìš”ì•½] â†’ [ê°•ì ] â†’ [ì•½ì ] â†’ [7ì°¨ì› í‰ê°€] â†’ [ìµœì¢… ë¦¬ë·°]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Node 1 - ë…¼ë¬¸ ìš”ì•½\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def summarize_paper(state: ReviewState) -> dict:\n",
    "    \"\"\"ë…¼ë¬¸ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert academic reviewer. Summarize the following paper in 2-3 sentences.\n",
    "Focus on: research question, methodology, and main findings.\n",
    "\n",
    "Paper:\n",
    "{paper}\n",
    "\n",
    "Summary (2-3 sentences):\n",
    "\"\"\")\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"paper\": state[\"paper\"]})\n",
    "    return {\"summary\": result.content}\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ”„ Node 1: ë…¼ë¬¸ ìš”ì•½ ì‹¤í–‰ ì¤‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_state = {\"paper\": SAMPLE_PAPER}\n",
    "result = summarize_paper(test_state)\n",
    "\n",
    "print(\"ğŸ“ [Output] ìš”ì•½:\")\n",
    "print(result[\"summary\"])\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Node 2 - ê°•ì  ë¶„ì„\n",
    "def analyze_strengths(state: ReviewState) -> dict:\n",
    "    \"\"\"ë…¼ë¬¸ì˜ ê°•ì  3-5ê°œ ë¶„ì„\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert academic reviewer. Identify 3-5 key strengths of this paper.\n",
    "Consider: methodology, contribution, clarity, and significance.\n",
    "\n",
    "Paper:\n",
    "{paper}\n",
    "\n",
    "Summary of the paper:\n",
    "{summary}\n",
    "\n",
    "List the strengths (3-5 bullet points):\n",
    "\"\"\")\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"paper\": state[\"paper\"],\n",
    "        \"summary\": state.get(\"summary\", \"\")\n",
    "    })\n",
    "    return {\"strengths\": result.content}\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ”„ Node 2: ê°•ì  ë¶„ì„ ì‹¤í–‰ ì¤‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_state[\"summary\"] = result[\"summary\"]  # ì´ì „ ê²°ê³¼ ì—°ê²°\n",
    "result2 = analyze_strengths(test_state)\n",
    "\n",
    "print(\"ğŸ’ª [Output] ê°•ì :\")\n",
    "print(result2[\"strengths\"])\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Node 3 - ì•½ì  ë¶„ì„\n",
    "def analyze_weaknesses(state: ReviewState) -> dict:\n",
    "    \"\"\"ë…¼ë¬¸ì˜ ì•½ì  3-5ê°œ ë¶„ì„\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert academic reviewer. Identify 3-5 key weaknesses or areas for improvement.\n",
    "Be constructive and specific. Consider: methodology limitations, missing analyses, clarity issues.\n",
    "\n",
    "Paper:\n",
    "{paper}\n",
    "\n",
    "Strengths identified:\n",
    "{strengths}\n",
    "\n",
    "List the weaknesses (3-5 bullet points, be constructive):\n",
    "\"\"\")\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"paper\": state[\"paper\"],\n",
    "        \"strengths\": state.get(\"strengths\", \"\")\n",
    "    })\n",
    "    return {\"weaknesses\": result.content}\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ”„ Node 3: ì•½ì  ë¶„ì„ ì‹¤í–‰ ì¤‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_state[\"strengths\"] = result2[\"strengths\"]  # ì´ì „ ê²°ê³¼ ì—°ê²°\n",
    "result3 = analyze_weaknesses(test_state)\n",
    "\n",
    "print(\"âš ï¸ [Output] ì•½ì :\")\n",
    "print(result3[\"weaknesses\"])\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Node 4 - 7ì°¨ì› í‰ê°€\n",
    "import json\n",
    "import re\n",
    "\n",
    "def evaluate_dimensions(state: ReviewState) -> dict:\n",
    "    \"\"\"7ì°¨ì›ìœ¼ë¡œ ë…¼ë¬¸ í‰ê°€ (Stanford Agentic Reviewer ë°©ì‹)\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert academic reviewer. Rate this paper on 7 dimensions (1-10 scale).\n",
    "\n",
    "Paper:\n",
    "{paper}\n",
    "\n",
    "Strengths: {strengths}\n",
    "Weaknesses: {weaknesses}\n",
    "\n",
    "Rate each dimension (1-10) and provide a brief justification:\n",
    "\n",
    "1. Originality: How novel is the research question or approach?\n",
    "2. Significance: How important is the contribution to the field?\n",
    "3. Soundness: Is the methodology rigorous and appropriate?\n",
    "4. Clarity: Is the paper well-written and easy to follow?\n",
    "5. Reproducibility: Can the study be replicated?\n",
    "6. Ethics: Are ethical considerations addressed?\n",
    "7. Overall: Overall quality of the paper.\n",
    "\n",
    "Respond in this exact JSON format:\n",
    "{{\n",
    "    \"originality\": {{\"score\": X, \"reason\": \"...\"}},\n",
    "    \"significance\": {{\"score\": X, \"reason\": \"...\"}},\n",
    "    \"soundness\": {{\"score\": X, \"reason\": \"...\"}},\n",
    "    \"clarity\": {{\"score\": X, \"reason\": \"...\"}},\n",
    "    \"reproducibility\": {{\"score\": X, \"reason\": \"...\"}},\n",
    "    \"ethics\": {{\"score\": X, \"reason\": \"...\"}},\n",
    "    \"overall\": {{\"score\": X, \"reason\": \"...\"}}\n",
    "}}\n",
    "\"\"\")\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"paper\": state[\"paper\"],\n",
    "        \"strengths\": state.get(\"strengths\", \"\"),\n",
    "        \"weaknesses\": state.get(\"weaknesses\", \"\")\n",
    "    })\n",
    "    \n",
    "    # JSON íŒŒì‹± ì‹œë„\n",
    "    try:\n",
    "        # JSON ë¸”ë¡ ì¶”ì¶œ\n",
    "        json_match = re.search(r'\\{[\\s\\S]*\\}', result.content)\n",
    "        if json_match:\n",
    "            scores = json.loads(json_match.group())\n",
    "        else:\n",
    "            scores = {\"error\": \"JSON íŒŒì‹± ì‹¤íŒ¨\", \"raw\": result.content}\n",
    "    except:\n",
    "        scores = {\"error\": \"JSON íŒŒì‹± ì‹¤íŒ¨\", \"raw\": result.content}\n",
    "    \n",
    "    return {\"scores\": scores}\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ”„ Node 4: 7ì°¨ì› í‰ê°€ ì‹¤í–‰ ì¤‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_state[\"weaknesses\"] = result3[\"weaknesses\"]  # ì´ì „ ê²°ê³¼ ì—°ê²°\n",
    "result4 = evaluate_dimensions(test_state)\n",
    "\n",
    "print(\"ğŸ“Š [Output] 7ì°¨ì› í‰ê°€:\")\n",
    "if \"error\" not in result4[\"scores\"]:\n",
    "    for dim, data in result4[\"scores\"].items():\n",
    "        print(f\"  {dim}: {data['score']}/10 - {data['reason'][:50]}...\")\n",
    "else:\n",
    "    print(result4[\"scores\"])\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Node 5 - ìµœì¢… ë¦¬ë·° ìƒì„±\n",
    "def generate_final_review(state: ReviewState) -> dict:\n",
    "    \"\"\"ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë¦¬ë·° ìƒì„±\"\"\"\n",
    "    \n",
    "    # ì ìˆ˜ ìš”ì•½\n",
    "    scores = state.get(\"scores\", {})\n",
    "    if \"error\" not in scores:\n",
    "        score_summary = \", \".join([f\"{k}: {v['score']}/10\" for k, v in scores.items()])\n",
    "    else:\n",
    "        score_summary = \"ì ìˆ˜ ì—†ìŒ\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert academic reviewer. Write a comprehensive final review.\n",
    "\n",
    "Paper Summary:\n",
    "{summary}\n",
    "\n",
    "Strengths:\n",
    "{strengths}\n",
    "\n",
    "Weaknesses:\n",
    "{weaknesses}\n",
    "\n",
    "Scores: {score_summary}\n",
    "\n",
    "Write a final review that includes:\n",
    "1. Brief summary (1-2 sentences)\n",
    "2. Major strengths (2-3 points)\n",
    "3. Major weaknesses (2-3 points)\n",
    "4. Questions for authors (2-3 questions)\n",
    "5. Recommendation (Accept / Minor Revision / Major Revision / Reject)\n",
    "\n",
    "Final Review:\n",
    "\"\"\")\n",
    "    \n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\n",
    "        \"summary\": state.get(\"summary\", \"\"),\n",
    "        \"strengths\": state.get(\"strengths\", \"\"),\n",
    "        \"weaknesses\": state.get(\"weaknesses\", \"\"),\n",
    "        \"score_summary\": score_summary\n",
    "    })\n",
    "    return {\"final_review\": result.content}\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ”„ Node 5: ìµœì¢… ë¦¬ë·° ìƒì„± ì¤‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_state[\"scores\"] = result4[\"scores\"]  # ì´ì „ ê²°ê³¼ ì—°ê²°\n",
    "result5 = generate_final_review(test_state)\n",
    "\n",
    "print(\"ğŸ“‹ [Output] ìµœì¢… ë¦¬ë·°:\")\n",
    "print(result5[\"final_review\"])\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 4: Agent êµ¬ì„± ë° ê²°ê³¼ ì €ì¥\n\nì´ì œ ëª¨ë“  Nodeë¥¼ LangGraphë¡œ ì—°ê²°í•˜ê³ , Part 3ì—ì„œ ì‹¤í–‰í•œ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: LangGraphë¡œ ì „ì²´ Agent êµ¬ì„±\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "workflow = StateGraph(ReviewState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"summarize\", summarize_paper)\n",
    "workflow.add_node(\"strengths\", analyze_strengths)\n",
    "workflow.add_node(\"weaknesses\", analyze_weaknesses)\n",
    "workflow.add_node(\"evaluate\", evaluate_dimensions)\n",
    "workflow.add_node(\"final_review\", generate_final_review)\n",
    "\n",
    "# ì—£ì§€ ì—°ê²° (ìˆœì„œ ì •ì˜)\n",
    "workflow.set_entry_point(\"summarize\")\n",
    "workflow.add_edge(\"summarize\", \"strengths\")\n",
    "workflow.add_edge(\"strengths\", \"weaknesses\")\n",
    "workflow.add_edge(\"weaknesses\", \"evaluate\")\n",
    "workflow.add_edge(\"evaluate\", \"final_review\")\n",
    "workflow.add_edge(\"final_review\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"âœ… LangGraph Agent êµ¬ì„± ì™„ë£Œ!\")\n",
    "print(\"\")\n",
    "print(\"ì›Œí¬í”Œë¡œìš°:\")\n",
    "print(\"  [ì‹œì‘] â†’ [ìš”ì•½] â†’ [ê°•ì ] â†’ [ì•½ì ] â†’ [7ì°¨ì› í‰ê°€] â†’ [ìµœì¢… ë¦¬ë·°] â†’ [ì¢…ë£Œ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 13: Part 3 ê²°ê³¼ ì €ì¥ (ë‹¤ìŒ ë…¸íŠ¸ë¶ ë¹„êµìš©)\n# ìœ„ì—ì„œ ì´ë¯¸ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í–ˆìœ¼ë¯€ë¡œ ê·¸ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\nimport json\nimport os\n\n# Part 3ì—ì„œ ì‹¤í–‰í•œ ê²°ê³¼ ì·¨í•©\nreview_result = {\n    \"method\": \"basic_langgraph_agent\",\n    \"llm_provider\": LLM_PROVIDER,\n    \"paper_title\": SAMPLE_PAPER.split('TITLE:')[1].split('ABSTRACT:')[0].strip()[:100],\n    \"summary\": result.get(\"summary\", \"\"),\n    \"strengths\": result2.get(\"strengths\", \"\"),\n    \"weaknesses\": result3.get(\"weaknesses\", \"\"),\n    \"scores\": result4.get(\"scores\", {}),\n    \"final_review\": result5.get(\"final_review\", \"\")\n}\n\n# ì €ì¥\noutput_dir = os.path.join(WORKSHOP_DIR, \"outputs\", \"reviews\")\nos.makedirs(output_dir, exist_ok=True)\noutput_path = os.path.join(output_dir, \"review_basic.json\")\n\nwith open(output_path, 'w', encoding='utf-8') as f:\n    json.dump(review_result, f, ensure_ascii=False, indent=2)\n\nprint(\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\nprint(f\"   ê²½ë¡œ: {output_path}\")\nprint(\"\")\nprint(\"ğŸ“Š ì €ì¥ëœ ë‚´ìš©:\")\nprint(f\"   - ìš”ì•½: {len(review_result['summary'])} ë¬¸ì\")\nprint(f\"   - ê°•ì : {len(review_result['strengths'])} ë¬¸ì\")\nprint(f\"   - ì•½ì : {len(review_result['weaknesses'])} ë¬¸ì\")\nprint(f\"   - 7ì°¨ì› ì ìˆ˜: {len(review_result['scores'])} í•­ëª©\")\nprint(f\"   - ìµœì¢… ë¦¬ë·°: {len(review_result['final_review'])} ë¬¸ì\")\nprint(\"\")\nprint(\"ğŸ‘‰ ë‹¤ìŒ ë…¸íŠ¸ë¶(Few-shot Learning)ì—ì„œ ì´ ê²°ê³¼ì™€ ë¹„êµí•©ë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Part 5: DIY - ë³¸ì¸ ë…¼ë¬¸ìœ¼ë¡œ ì‹¤í–‰\n\në³¸ì¸ì˜ ë…¼ë¬¸/ì›ê³  íŒŒì¼ì„ ì…ë ¥í•˜ì—¬ ë¦¬ë·°ë¥¼ ë°›ì•„ë³´ì„¸ìš”.\n\n**ì§€ì› í˜•ì‹:**\n- `.txt` - í…ìŠ¤íŠ¸ íŒŒì¼\n- `.pdf` - PDF íŒŒì¼ (PyPDF2 í•„ìš”)\n- `.docx` - Word ë¬¸ì„œ (python-docx í•„ìš”)\n- ë˜ëŠ” ì§ì ‘ í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DIY Cell 1: ë³¸ì¸ ë…¼ë¬¸ íŒŒì¼ ê²½ë¡œ ì…ë ¥\n# PDF, TXT, MD, ë˜ëŠ” Word ë¬¸ì„œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n\n# ë°©ë²• 1: íŒŒì¼ ê²½ë¡œ ì…ë ¥ (ê¶Œì¥)\n# ì˜ˆì‹œ: os.path.join(WORKSHOP_DIR, \"input\", \"my_paper.pdf\")\nMY_PAPER_PATH = \"\"  # <- íŒŒì¼ ê²½ë¡œ ì…ë ¥\n\n# ğŸ’¡ ìƒ˜í”Œì„ ë‹¤ì‹œ ì‚¬ìš©í•˜ë ¤ë©´:\n# MY_PAPER_PATH = os.path.join(WORKSHOP_DIR, \"input\", \"sample_manuscript.md\")\n\n# ë°©ë²• 2: ì§ì ‘ í…ìŠ¤íŠ¸ ì…ë ¥ (íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)\nMY_PAPER_TEXT = \"\"\"\nTITLE: [ë…¼ë¬¸ ì œëª©]\n\nABSTRACT:\n[ì´ˆë¡ì„ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”]\n\nMETHODS:\n[ë°©ë²•ë¡  ìš”ì•½]\n\nRESULTS:\n[ì£¼ìš” ê²°ê³¼]\n\nCONCLUSIONS:\n[ê²°ë¡ ]\n\"\"\"\n\n# ë…¼ë¬¸ ë¡œë”©\nMY_PAPER = None\n\nif MY_PAPER_PATH:\n    if os.path.exists(MY_PAPER_PATH):\n        ext = os.path.splitext(MY_PAPER_PATH)[1].lower()\n        \n        if ext in ['.txt', '.md']:\n            with open(MY_PAPER_PATH, 'r', encoding='utf-8') as f:\n                MY_PAPER = f.read()\n            print(f\"âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë”©: {MY_PAPER_PATH}\")\n            \n        elif ext == '.pdf':\n            try:\n                import PyPDF2\n                with open(MY_PAPER_PATH, 'rb') as f:\n                    reader = PyPDF2.PdfReader(f)\n                    MY_PAPER = \"\\n\".join([page.extract_text() for page in reader.pages])\n                print(f\"âœ… PDF íŒŒì¼ ë¡œë”©: {MY_PAPER_PATH}\")\n            except ImportError:\n                print(\"âš ï¸ PyPDF2ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install PyPDF2\")\n            except Exception as e:\n                print(f\"âŒ PDF ë¡œë”© ì‹¤íŒ¨: {e}\")\n                \n        elif ext in ['.docx', '.doc']:\n            try:\n                import docx\n                doc = docx.Document(MY_PAPER_PATH)\n                MY_PAPER = \"\\n\".join([para.text for para in doc.paragraphs])\n                print(f\"âœ… Word íŒŒì¼ ë¡œë”©: {MY_PAPER_PATH}\")\n            except ImportError:\n                print(\"âš ï¸ python-docxê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install python-docx\")\n            except Exception as e:\n                print(f\"âŒ Word ë¡œë”© ì‹¤íŒ¨: {e}\")\n        else:\n            print(f\"âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}\")\n    else:\n        print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MY_PAPER_PATH}\")\n\n# íŒŒì¼ì´ ì—†ìœ¼ë©´ ì§ì ‘ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ì‚¬ìš©\nif MY_PAPER is None and len(MY_PAPER_TEXT) > 200:\n    MY_PAPER = MY_PAPER_TEXT\n    print(\"âœ… ì§ì ‘ ì…ë ¥í•œ í…ìŠ¤íŠ¸ ì‚¬ìš©\")\n\n# ê²°ê³¼ í™•ì¸\nif MY_PAPER and len(MY_PAPER) > 200:\n    print(f\"\\nğŸ“„ ë…¼ë¬¸ ì¤€ë¹„ ì™„ë£Œ!\")\n    print(f\"   ê¸¸ì´: {len(MY_PAPER)} ë¬¸ì\")\n    print(f\"   ë¯¸ë¦¬ë³´ê¸°: {MY_PAPER[:150].replace(chr(10), ' ')}...\")\nelse:\n    print(\"\\nâš ï¸ ë…¼ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!\")\n    print(\"   1. MY_PAPER_PATHì— íŒŒì¼ ê²½ë¡œ ì…ë ¥\")\n    print(\"   2. ë˜ëŠ” MY_PAPER_TEXTì— ì§ì ‘ ë¶™ì—¬ë„£ê¸°\")\n    print(f\"\\n   ğŸ“ input í´ë”: {os.path.join(WORKSHOP_DIR, 'input')}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DIY Cell 2: ë³¸ì¸ ë…¼ë¬¸ ë¦¬ë·° ì‹¤í–‰\nif MY_PAPER and len(MY_PAPER) > 200:\n    print(\"ğŸš€ ë³¸ì¸ ë…¼ë¬¸ ë¦¬ë·° ì‹œì‘!\")\n    print(\"=\"*60)\n    \n    # Agent ì‹¤í–‰\n    my_state = {\n        \"paper\": MY_PAPER,\n        \"summary\": \"\",\n        \"strengths\": \"\",\n        \"weaknesses\": \"\",\n        \"scores\": {},\n        \"final_review\": \"\"\n    }\n    \n    my_result = app.invoke(my_state)\n    \n    # ê²°ê³¼ ì¶œë ¥\n    print(\"\\nğŸ“‹ ìµœì¢… ë¦¬ë·°:\")\n    print(\"=\"*60)\n    print(my_result[\"final_review\"])\n    print(\"=\"*60)\n    \n    # ê²°ê³¼ ì €ì¥\n    my_review_result = {\n        \"method\": \"basic_langgraph_agent\",\n        \"llm_provider\": LLM_PROVIDER,\n        \"source\": MY_PAPER_PATH if MY_PAPER_PATH else \"direct_input\",\n        \"summary\": my_result.get(\"summary\", \"\"),\n        \"strengths\": my_result.get(\"strengths\", \"\"),\n        \"weaknesses\": my_result.get(\"weaknesses\", \"\"),\n        \"scores\": my_result.get(\"scores\", {}),\n        \"final_review\": my_result.get(\"final_review\", \"\")\n    }\n    \n    my_output_path = os.path.join(output_dir, \"review_my_paper.json\")\n    with open(my_output_path, 'w', encoding='utf-8') as f:\n        json.dump(my_review_result, f, ensure_ascii=False, indent=2)\n    \n    print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥: {my_output_path}\")\nelse:\n    print(\"âš ï¸ ìœ„ ì…€ì—ì„œ ë…¼ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬\n",
    "\n",
    "### ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ê²ƒ\n",
    "\n",
    "1. **Agent ê°œë…**: LLM + ì›Œí¬í”Œë¡œìš° = Agent\n",
    "2. **LangGraph**: Nodeì™€ Edgeë¡œ ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "3. **ë‹¨ê³„ë³„ ì²˜ë¦¬**: ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ë©° ì§„í–‰\n",
    "4. **7ì°¨ì› í‰ê°€**: Stanford Agentic Reviewer ë°©ì‹\n",
    "\n",
    "### ë‹¤ìŒ ë…¸íŠ¸ë¶ ì˜ˆê³ \n",
    "\n",
    "**Notebook 4: Few-shot Learningìœ¼ë¡œ ë¦¬ë·° í’ˆì§ˆ í–¥ìƒ**\n",
    "- Nature Communicationsì˜ ì‹¤ì œ ë¦¬ë·° ì˜ˆì‹œ ì‚¬ìš©\n",
    "- ê¸°ë³¸ Agent vs Few-shot Agent ë¹„êµ\n",
    "- ì–´ë–¤ ë¦¬ë·°ê°€ ë” ìœ ìš©í•œì§€ íŒë‹¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}