{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Part 4: AI vs Human Review ë¹„êµ\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. **ì‹¤ì œ í”¼ì–´ë¦¬ë·°** ë°ì´í„° ìˆ˜ì§‘í•˜ê¸°\n",
    "2. **ê°„ë‹¨í•œ ë¦¬ë·° ì—ì´ì „íŠ¸** ì§ì ‘ êµ¬í˜„í•˜ê¸°\n",
    "3. **AI vs Human ë¦¬ë·°** ë¹„êµ ë¶„ì„\n",
    "\n",
    "---\n",
    "\n",
    "## ì‹¤ì œ ë¦¬ë·° ë°ì´í„° ì†ŒìŠ¤\n",
    "\n",
    "| ì‚¬ì´íŠ¸ | ë¶„ì•¼ | íŠ¹ì§• |\n",
    "|--------|------|------|\n",
    "| **[OpenReview](https://openreview.net/)** | AI/ML | ICLR, NeurIPS ë“± ê³µê°œ ë¦¬ë·° |\n",
    "| **[PeerJ](https://peerj.com/)** | ìƒëª…ê³¼í•™ | ë¦¬ë·° íˆìŠ¤í† ë¦¬ ê³µê°œ |\n",
    "| **[F1000Research](https://f1000research.com/)** | ë‹¤í•™ì œ | ê³µê°œ í”¼ì–´ë¦¬ë·° |\n",
    "\n",
    "> ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” **OpenReview**ì—ì„œ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì •\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Colab í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "    os.chdir(WORKSHOP_DIR)\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "except ImportError:\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('notebooks'):\n",
    "        os.chdir('..')\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "print(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: API Key ë¡œë”©\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        GEMINI_API_KEY = None\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(override=True)\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if GEMINI_API_KEY and not GEMINI_API_KEY.startswith('your_'):\n",
    "    os.environ['GOOGLE_API_KEY'] = GEMINI_API_KEY\n",
    "    print(\"âœ… Gemini API Key ë¡œë“œ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"âŒ Gemini API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤\")\n",
    "    print(\"   ë°œê¸‰: https://aistudio.google.com/apikey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: ì‹¤ì œ ë¦¬ë·° ìˆ˜ì§‘\n",
    "\n",
    "### Step 1: OpenReviewì—ì„œ ë¦¬ë·° ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "**ì§ì ‘ ìˆ˜ì§‘ ë°©ë²•:**\n",
    "\n",
    "1. **[OpenReview.net](https://openreview.net/)** ì ‘ì†\n",
    "2. ê´€ì‹¬ ìˆëŠ” í•™íšŒ ì„ íƒ (ì˜ˆ: ICLR 2024, NeurIPS 2023)\n",
    "3. ë…¼ë¬¸ ì„ íƒ â†’ **Reviews** íƒ­ í´ë¦­\n",
    "4. ë¦¬ë·° ë‚´ìš© ë³µì‚¬ â†’ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥\n",
    "\n",
    "**ì €ì¥ ìœ„ì¹˜:** `input/human_reviews/`\n",
    "\n",
    "**íŒŒì¼ í˜•ì‹ ì˜ˆì‹œ:**\n",
    "```\n",
    "input/human_reviews/\n",
    "â”œâ”€â”€ review_1.txt\n",
    "â”œâ”€â”€ review_2.txt\n",
    "â””â”€â”€ review_3.txt\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ë¦¬ë·° íŒŒì¼ í˜•ì‹\n",
    "\n",
    "ê° `.txt` íŒŒì¼ì— ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ì„¸ìš”:\n",
    "\n",
    "```\n",
    "=== ë…¼ë¬¸ ì œëª© ===\n",
    "[ë…¼ë¬¸ ì œëª© ì—¬ê¸°]\n",
    "\n",
    "=== ì ìˆ˜ ===\n",
    "Overall: [ì ìˆ˜]\n",
    "Soundness: [ì ìˆ˜]\n",
    "Presentation: [ì ìˆ˜]\n",
    "Contribution: [ì ìˆ˜]\n",
    "\n",
    "=== ë¦¬ë·° ë‚´ìš© ===\n",
    "[ë¦¬ë·° ì „ì²´ ë‚´ìš©]\n",
    "\n",
    "=== Strengths ===\n",
    "[ê°•ì ë“¤]\n",
    "\n",
    "=== Weaknesses ===\n",
    "[ì•½ì ë“¤]\n",
    "```\n",
    "\n",
    "> âš ï¸ **ìµœì†Œ 3ê°œ ì´ìƒì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: ë¦¬ë·° í´ë” ìƒì„± ë° í™•ì¸\n",
    "import os\n",
    "\n",
    "REVIEW_DIR = os.path.join(WORKSHOP_DIR, \"input\", \"human_reviews\")\n",
    "os.makedirs(REVIEW_DIR, exist_ok=True)\n",
    "\n",
    "# ê¸°ì¡´ ë¦¬ë·° íŒŒì¼ í™•ì¸\n",
    "review_files = [f for f in os.listdir(REVIEW_DIR) if f.endswith('.txt')]\n",
    "\n",
    "if len(review_files) >= 3:\n",
    "    print(f\"âœ… {len(review_files)}ê°œì˜ ë¦¬ë·° íŒŒì¼ ë°œê²¬!\")\n",
    "    for f in review_files:\n",
    "        print(f\"   ğŸ“„ {f}\")\n",
    "elif len(review_files) > 0:\n",
    "    print(f\"âš ï¸ {len(review_files)}ê°œì˜ ë¦¬ë·° íŒŒì¼ ë°œê²¬ (ìµœì†Œ 3ê°œ ê¶Œì¥)\")\n",
    "    for f in review_files:\n",
    "        print(f\"   ğŸ“„ {f}\")\n",
    "else:\n",
    "    print(\"âŒ ë¦¬ë·° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"\\nğŸ“ ë¦¬ë·° ì €ì¥ ìœ„ì¹˜: {REVIEW_DIR}\")\n",
    "    print(\"\\nìœ„ ë§ˆí¬ë‹¤ìš´ ì…€ì˜ ì•ˆë‚´ì— ë”°ë¼ OpenReviewì—ì„œ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: ë¦¬ë·° íŒŒì¼ íŒŒì‹±\n",
    "import re\n",
    "\n",
    "def parse_review_file(filepath):\n",
    "    \"\"\"ë¦¬ë·° í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    review = {\n",
    "        'file': os.path.basename(filepath),\n",
    "        'title': '',\n",
    "        'scores': {},\n",
    "        'review': '',\n",
    "        'strengths': '',\n",
    "        'weaknesses': ''\n",
    "    }\n",
    "    \n",
    "    # ì„¹ì…˜ íŒŒì‹±\n",
    "    sections = re.split(r'===\\s*(.+?)\\s*===', content)\n",
    "    \n",
    "    for i in range(1, len(sections), 2):\n",
    "        section_name = sections[i].strip().lower()\n",
    "        section_content = sections[i+1].strip() if i+1 < len(sections) else ''\n",
    "        \n",
    "        if 'ë…¼ë¬¸' in section_name or 'title' in section_name:\n",
    "            review['title'] = section_content\n",
    "        elif 'ì ìˆ˜' in section_name or 'score' in section_name:\n",
    "            # ì ìˆ˜ íŒŒì‹±\n",
    "            for line in section_content.split('\\n'):\n",
    "                if ':' in line:\n",
    "                    key, val = line.split(':', 1)\n",
    "                    review['scores'][key.strip().lower()] = val.strip()\n",
    "        elif 'ë¦¬ë·°' in section_name or 'review' in section_name:\n",
    "            review['review'] = section_content\n",
    "        elif 'strength' in section_name or 'ê°•ì ' in section_name:\n",
    "            review['strengths'] = section_content\n",
    "        elif 'weakness' in section_name or 'ì•½ì ' in section_name:\n",
    "            review['weaknesses'] = section_content\n",
    "    \n",
    "    return review\n",
    "\n",
    "# ëª¨ë“  ë¦¬ë·° íŒŒì‹±\n",
    "human_reviews = []\n",
    "for f in review_files:\n",
    "    filepath = os.path.join(REVIEW_DIR, f)\n",
    "    review = parse_review_file(filepath)\n",
    "    human_reviews.append(review)\n",
    "    print(f\"ğŸ“„ {f}: {review['title'][:50]}...\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {len(human_reviews)}ê°œ ë¦¬ë·° ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: ê°„ë‹¨í•œ ë¦¬ë·° ì—ì´ì „íŠ¸ êµ¬í˜„\n",
    "\n",
    "ë…¸íŠ¸ë¶ 3ì—ì„œëŠ” **agentic-paper-review** (9ë…¸ë“œ)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì—ëŠ” **ì§ì ‘ ê°„ë‹¨í•œ ë¦¬ë·° ì—ì´ì „íŠ¸**ë¥¼ êµ¬í˜„í•´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "### êµ¬ì¡°\n",
    "```\n",
    "[ë…¼ë¬¸ í…ìŠ¤íŠ¸] â†’ [í”„ë¡¬í”„íŠ¸] â†’ [LLM] â†’ [ë¦¬ë·° + ì ìˆ˜]\n",
    "```\n",
    "\n",
    "ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì—†ì´ **ë‹¨ì¼ í”„ë¡¬í”„íŠ¸**ë¡œ ë¦¬ë·°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ê°„ë‹¨í•œ ë¦¬ë·° ì—ì´ì „íŠ¸ ì •ì˜\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "\n",
    "REVIEW_PROMPT = \"\"\"ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ ë¦¬ë·°ì–´ì…ë‹ˆë‹¤. ì•„ë˜ ë…¼ë¬¸ì„ ì½ê³  ìƒì„¸í•œ ë¦¬ë·°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "## ë…¼ë¬¸ ë‚´ìš©:\n",
    "{paper_content}\n",
    "\n",
    "## ë¦¬ë·° í˜•ì‹:\n",
    "\n",
    "### 1. ìš”ì•½ (Summary)\n",
    "ë…¼ë¬¸ì˜ ì£¼ìš” ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n",
    "\n",
    "### 2. ê°•ì  (Strengths)\n",
    "- ê°•ì  1\n",
    "- ê°•ì  2\n",
    "- ê°•ì  3\n",
    "\n",
    "### 3. ì•½ì  (Weaknesses)\n",
    "- ì•½ì  1\n",
    "- ì•½ì  2\n",
    "- ì•½ì  3\n",
    "\n",
    "### 4. ì ìˆ˜ (Scores)\n",
    "ê° í•­ëª©ì„ 1-4ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:\n",
    "- Soundness (ë°©ë²•ë¡  ì—„ë°€ì„±): [1-4]\n",
    "- Presentation (ëª…í™•ì„±): [1-4]\n",
    "- Contribution (ê¸°ì—¬ë„): [1-4]\n",
    "- Overall (ì¢…í•©): [1-10]\n",
    "\n",
    "### 5. ìµœì¢… ê²°ì •\n",
    "Accept / Weak Accept / Weak Reject / Reject ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "def simple_review_agent(paper_content, model_name=\"gemini-2.0-flash\"):\n",
    "    \"\"\"ê°„ë‹¨í•œ ë¦¬ë·° ì—ì´ì „íŠ¸\"\"\"\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    \n",
    "    prompt = REVIEW_PROMPT.format(paper_content=paper_content[:15000])  # í† í° ì œí•œ\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    return {\n",
    "        'review': response.text,\n",
    "        'model': model_name\n",
    "    }\n",
    "\n",
    "print(\"âœ… simple_review_agent() ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ìƒ˜í”Œ ë…¼ë¬¸ìœ¼ë¡œ AI ë¦¬ë·° ìƒì„±\n",
    "\n",
    "# ìƒ˜í”Œ ë…¼ë¬¸ ë¡œë“œ\n",
    "SAMPLE_PATH = os.path.join(WORKSHOP_DIR, \"input\", \"sample_manuscript.md\")\n",
    "\n",
    "if os.path.exists(SAMPLE_PATH):\n",
    "    with open(SAMPLE_PATH, 'r', encoding='utf-8') as f:\n",
    "        sample_paper = f.read()\n",
    "    \n",
    "    print(f\"ğŸ“„ ìƒ˜í”Œ ë…¼ë¬¸ ë¡œë“œ: {len(sample_paper)} ë¬¸ì\")\n",
    "    print(\"\\nğŸ”„ AI ë¦¬ë·° ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    ai_review = simple_review_agent(sample_paper)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ¤– AI ë¦¬ë·° ê²°ê³¼\")\n",
    "    print(\"=\"*60)\n",
    "    print(ai_review['review'])\n",
    "else:\n",
    "    print(\"âŒ ìƒ˜í”Œ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    print(f\"   ê²½ë¡œ: {SAMPLE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: AI vs Human ë¹„êµ\n",
    "\n",
    "ìˆ˜ì§‘í•œ Human ë¦¬ë·°ì™€ AI ë¦¬ë·°ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: ë¹„êµ ë¶„ì„\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "if human_reviews and 'ai_review' in dir():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ“Š AI vs Human ë¦¬ë·° ë¹„êµ\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Human ë¦¬ë·° ìš”ì•½\n",
    "    print(\"\\nğŸ‘¤ Human ë¦¬ë·° ({0}ê°œ):\".format(len(human_reviews)))\n",
    "    for i, hr in enumerate(human_reviews, 1):\n",
    "        print(f\"\\n--- ë¦¬ë·° {i}: {hr['file']} ---\")\n",
    "        print(f\"ë…¼ë¬¸: {hr['title'][:50]}...\")\n",
    "        if hr['scores']:\n",
    "            print(f\"ì ìˆ˜: {hr['scores']}\")\n",
    "        if hr['strengths']:\n",
    "            print(f\"ê°•ì : {hr['strengths'][:100]}...\")\n",
    "        if hr['weaknesses']:\n",
    "            print(f\"ì•½ì : {hr['weaknesses'][:100]}...\")\n",
    "    \n",
    "    # AI ë¦¬ë·° ìš”ì•½\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nğŸ¤– AI ë¦¬ë·° ìš”ì•½:\")\n",
    "    print(ai_review['review'][:1000] + \"...\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Human ë¦¬ë·°ì™€ AI ë¦¬ë·°ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤\")\n",
    "    if not human_reviews:\n",
    "        print(\"   - Human ë¦¬ë·°: Part 2 ì™„ë£Œ í•„ìš”\")\n",
    "    if 'ai_review' not in dir():\n",
    "        print(\"   - AI ë¦¬ë·°: Cell 6 ì‹¤í–‰ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: ë…¸íŠ¸ë¶ 3 ê²°ê³¼ì™€ ë¹„êµ\n",
    "import json\n",
    "\n",
    "# ë…¸íŠ¸ë¶ 3 ê²°ê³¼ ë¡œë“œ\n",
    "notebook3_result_path = os.path.join(WORKSHOP_DIR, \"outputs\", \"3_agent_result\", \"review.json\")\n",
    "\n",
    "notebook3_review = None\n",
    "if os.path.exists(notebook3_result_path):\n",
    "    with open(notebook3_result_path, 'r', encoding='utf-8') as f:\n",
    "        notebook3_review = json.load(f)\n",
    "    \n",
    "    if notebook3_review.get('status') == 'completed' and notebook3_review.get('review'):\n",
    "        print(\"âœ… ë…¸íŠ¸ë¶ 3 ê²°ê³¼ ë¡œë“œ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ë…¸íŠ¸ë¶ 3 ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì‹¤íŒ¨ ìƒíƒœì…ë‹ˆë‹¤\")\n",
    "        notebook3_review = None\n",
    "else:\n",
    "    print(\"âš ï¸ ë…¸íŠ¸ë¶ 3 ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
    "    print(\"   ë…¸íŠ¸ë¶ 3ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "\n",
    "# 3ê°€ì§€ ë¹„êµ\n",
    "if notebook3_review and 'ai_review' in dir():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š 3ê°€ì§€ ë¦¬ë·° ë°©ì‹ ë¹„êµ\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    comparison_data = [\n",
    "        [\"ë°©ì‹\", \"ë³µì¡ë„\", \"íŠ¹ì§•\"],\n",
    "        [\"Human Review\", \"N/A\", \"ì‹¤ì œ ì „ë¬¸ê°€ ë¦¬ë·°\"],\n",
    "        [\"Simple Agent (ë…¸íŠ¸ë¶ 4)\", \"ë‹¨ì¼ í”„ë¡¬í”„íŠ¸\", \"ë¹ ë¥´ê³  ê°„ë‹¨\"],\n",
    "        [\"Agentic Review (ë…¸íŠ¸ë¶ 3)\", \"9ë…¸ë“œ ì›Œí¬í”Œë¡œìš°\", \"ì›¹ê²€ìƒ‰, ë¦¬í”Œë ‰ì…˜ í¬í•¨\"]\n",
    "    ]\n",
    "    \n",
    "    for row in comparison_data:\n",
    "        print(f\"{row[0]:<25} | {row[1]:<15} | {row[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: ê²°ê³¼ ì €ì¥ ë° ì œì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: ê²°ê³¼ ì €ì¥\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "output_dir = os.path.join(WORKSHOP_DIR, \"outputs\", \"4_comparison_result\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ë¹„êµ ê²°ê³¼ ì €ì¥\n",
    "comparison_result = {\n",
    "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'human_reviews_count': len(human_reviews) if human_reviews else 0,\n",
    "    'human_reviews': human_reviews if human_reviews else [],\n",
    "    'ai_simple_review': ai_review if 'ai_review' in dir() else None,\n",
    "    'ai_agentic_review': notebook3_review if notebook3_review else None\n",
    "}\n",
    "\n",
    "json_path = os.path.join(output_dir, \"comparison.json\")\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(comparison_result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ê²°ê³¼ ì œì¶œ (Forms ì—°ë™ì€ ì¶”í›„ ì¶”ê°€)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“‹ ì‹¤ìŠµ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nâœ… ì™„ë£Œí•œ ì‘ì—…:\")\n",
    "print(f\"   1. Human ë¦¬ë·° ìˆ˜ì§‘: {len(human_reviews) if human_reviews else 0}ê°œ\")\n",
    "print(f\"   2. Simple AI ë¦¬ë·° ìƒì„±: {'ì™„ë£Œ' if 'ai_review' in dir() else 'ë¯¸ì™„ë£Œ'}\")\n",
    "print(f\"   3. ë…¸íŠ¸ë¶ 3 ê²°ê³¼ ë¹„êµ: {'ì™„ë£Œ' if notebook3_review else 'ë¯¸ì™„ë£Œ'}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ í† ë¡  ì§ˆë¬¸:\")\n",
    "print(\"   1. Human ë¦¬ë·°ì™€ AI ë¦¬ë·°ì˜ ê°€ì¥ í° ì°¨ì´ì ì€?\")\n",
    "print(\"   2. Simple Agent vs Agentic Agent - ì–´ë–¤ ì°¨ì´ê°€ ìˆì—ˆë‚˜ìš”?\")\n",
    "print(\"   3. AI ë¦¬ë·°ê°€ ì‹¤ì œë¡œ ìœ ìš©í•˜ë ¤ë©´ ë¬´ì—‡ì´ í•„ìš”í• ê¹Œìš”?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## ì •ë¦¬\n",
    "\n",
    "### ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ ê²ƒ\n",
    "\n",
    "1. **ì‹¤ì œ í”¼ì–´ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘** - OpenReview í™œìš©\n",
    "2. **ê°„ë‹¨í•œ ë¦¬ë·° ì—ì´ì „íŠ¸ êµ¬í˜„** - ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ë°©ì‹\n",
    "3. **AI vs Human ë¹„êµ** - ê°•ì /ì•½ì  ë¶„ì„\n",
    "\n",
    "### ë¦¬ë·° ì—ì´ì „íŠ¸ ë¹„êµ\n",
    "\n",
    "| ë°©ì‹ | ì¥ì  | ë‹¨ì  |\n",
    "|------|------|------|\n",
    "| **Human** | ì „ë¬¸ì„±, ë§¥ë½ ì´í•´ | ì‹œê°„ ì†Œìš”, í¸í–¥ ê°€ëŠ¥ |\n",
    "| **Simple Agent** | ë¹ ë¦„, ì¼ê´€ì„± | ê¹Šì´ ë¶€ì¡± |\n",
    "| **Agentic Agent** | ì›¹ê²€ìƒ‰, ë¦¬í”Œë ‰ì…˜ | ë³µì¡, API ë¹„ìš© |\n",
    "\n",
    "### ì°¸ê³  ìë£Œ\n",
    "\n",
    "- OpenReview: https://openreview.net/\n",
    "- PeerRead Dataset: https://github.com/allenai/PeerRead\n",
    "- Google Gemini API: https://ai.google.dev/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
