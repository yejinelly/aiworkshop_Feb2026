{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ì˜¤í”ˆì†ŒìŠ¤ Literature Agent ê°œê´€\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. ì˜¤í”ˆì†ŒìŠ¤ ë¬¸í—Œ ë¦¬ë·° ì—ì´ì „íŠ¸ì˜ ì¢…ë¥˜ì™€ íŠ¹ì§• ì´í•´\n",
    "2. ê° ì—ì´ì „íŠ¸ì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œ íŒŒì•…\n",
    "3. í•™ìˆ  API (Semantic Scholar, arXiv, PubMed) ê¸°ë³¸ ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### Cell 1: í™˜ê²½ ì„¤ì • (Colab/ë¡œì»¬ ìë™ ê°ì§€)\nColabê³¼ ë¡œì»¬ í™˜ê²½ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ì‘ì—… í´ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "source": "### Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜\ní•„ìš”í•œ Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤ (Colabì—ì„œë§Œ ìë™ ì‹¤í–‰).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Cell 3: API Key ë¡œë”©\nGeminiì™€ Semantic Scholar API í‚¤ë¥¼ ë¡œë”©í•˜ê³  ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Cell 3: API Key ë¡œë”©",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜\n# Colab: ìë™ ì„¤ì¹˜\n# ë¡œì»¬: pyproject.tomlë¡œ ë¯¸ë¦¬ ì„¤ì¹˜ í•„ìš” (uv pip install -e . ë˜ëŠ” pip install -e .)\n\nif IN_COLAB:\n    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n    %pip install requests python-dotenv semanticscholar arxiv google-generativeai -q\n    print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")\nelse:\n    print(\"âœ… ë¡œì»¬ í™˜ê²½: pyproject.tomlë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©\")\n    print(\"   (ë¯¸ì„¤ì¹˜ ì‹œ: uv pip install -e . ë˜ëŠ” pip install -e .)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: API Key ë¡œë”©\nimport os\nfrom pathlib import Path\n\n# Colab í™˜ê²½ ì²´í¬\nif IN_COLAB:\n    # Colab userdataì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n    try:\n        from google.colab import userdata\n        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n        SEMANTIC_SCHOLAR_API_KEY = userdata.get('SEMANTIC_SCHOLAR_API_KEY', None)\n        print(\"âœ… Colab Secretsì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n    except:\n        print(\"âš ï¸ Colab Secretsì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n        print(\"   ì¢Œì¸¡ ğŸ”‘ ì•„ì´ì½˜ > Add new secret\")\n        GEMINI_API_KEY = None\n        SEMANTIC_SCHOLAR_API_KEY = None\nelse:\n    # ë¡œì»¬ í™˜ê²½: dotenv ì‚¬ìš©\n    try:\n        from dotenv import load_dotenv\n        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ .env ì°¾ê¸°\n        load_dotenv()\n        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n        SEMANTIC_SCHOLAR_API_KEY = os.getenv('SEMANTIC_SCHOLAR_API_KEY')\n        \n        if GEMINI_API_KEY:\n            print(\"âœ… .env íŒŒì¼ì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n        else:\n            print(\"âš ï¸ .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n            print(\"   ì˜ˆ: GEMINI_API_KEY=your_key_here\")\n    except ImportError:\n        print(\"âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n        print(\"   ì‹¤í–‰: pip install python-dotenv\")\n        GEMINI_API_KEY = None\n        SEMANTIC_SCHOLAR_API_KEY = None\n\n# API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\nprint()\nif GEMINI_API_KEY:\n    print(f\"âœ… Gemini API Key: {GEMINI_API_KEY[:10]}...\")\nelse:\n    print(\"âŒ Gemini API Key: ì—†ìŒ (ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ)\")\n\nif SEMANTIC_SCHOLAR_API_KEY:\n    print(f\"âœ… Semantic Scholar API Key: {SEMANTIC_SCHOLAR_API_KEY[:10]}...\")\nelse:\n    print(\"\\nâš ï¸  Semantic Scholar API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n    print(\"   â†’ API ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ rate limit ì œí•œ (100 req/5ë¶„)\")\n    print(\"   â†’ ë°œê¸‰ ê¶Œì¥ (ë¬´ë£Œ, 5000 req/5ë¶„): https://www.semanticscholar.org/product/api\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: ì˜¤í”ˆì†ŒìŠ¤ Literature Agent ë¹„êµ\n",
    "\n",
    "ì½”ë“œê°€ ê³µê°œëœ ì—ì´ì „íŠ¸ë§Œ ë‹¤ë£¹ë‹ˆë‹¤. ì›¹ ì„œë¹„ìŠ¤(Elicit, Consensus ë“±)ëŠ” ì œì™¸."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì£¼ìš” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸\n",
    "\n",
    "| í”„ë¡œì íŠ¸ | Stars | ìš©ë„ | ê²€ìƒ‰ DB |\n",
    "|----------|------:|------|--------|\n",
    "| [GPT-Researcher](https://github.com/assafelovic/gpt-researcher) | 24.9k | ì›¹ê²€ìƒ‰ â†’ ë³´ê³ ì„œ | ì›¹ (Tavily) |\n",
    "| [AI-Scientist](https://github.com/SakanaAI/AI-Scientist) | 12k | ì•„ì´ë””ì–´â†’ë…¼ë¬¸ ìë™í™” | Semantic Scholar |\n",
    "| [PaperQA2](https://github.com/Future-House/paper-qa) | 8k | PDF RAG Q&A | Semantic Scholar |\n",
    "| [**Agent Laboratory**](https://github.com/SamuelSchmidgall/AgentLaboratory) | 5.2k | **ë¬¸í—Œâ†’ì‹¤í—˜â†’ë³´ê³ ì„œ** | **arXiv** |\n",
    "| [**PaSa**](https://github.com/bytedance/pasa) | 1.5k | **ë…¼ë¬¸ ê²€ìƒ‰ íŠ¹í™”** | **arXiv + Scholar** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜¤ëŠ˜ ì§‘ì¤‘í•  4ê°€ì§€ ë„êµ¬\n",
    "\n",
    "| ë„êµ¬ | ê¸°ëŠ¥ | ì €ì¥ì†Œ |\n",
    "|------|------|--------|\n",
    "| **Agent Laboratory** | ë¬¸í—Œ ê²€ìƒ‰ â†’ ì‹¤í—˜ â†’ ë³´ê³ ì„œ | github.com/SamuelSchmidgall/AgentLaboratory |\n",
    "| **PaSa** | ë…¼ë¬¸ ê²€ìƒ‰ íŠ¹í™” (PPO í•™ìŠµ) | github.com/bytedance/pasa |\n",
    "| **LitLLM** | Related Work ìë™ ìƒì„± | github.com/ServiceNow/litllm |\n",
    "| **AgentReview** | Peer Review ì‹œë®¬ë ˆì´ì…˜ | github.com/ahren09/agentreview |"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### ê° ë„êµ¬ì˜ í•µì‹¬ êµ¬ì¡°\n\n```\nğŸ“ Agent Laboratory\nâ”œâ”€â”€ agents/\nâ”‚   â””â”€â”€ literature_agent.py   # ë¬¸í—Œ ê²€ìƒ‰ ì—ì´ì „íŠ¸\nâ”œâ”€â”€ tools/\nâ”‚   â””â”€â”€ arxiv_search.py       # arXiv API ë˜í¼\nâ””â”€â”€ run.py\n```\nğŸ’¡ ì‹¤í—˜ ì„¤ê³„/ë³´ê³ ì„œ ê¸°ëŠ¥ë„ ìˆì§€ë§Œ, ì›Œí¬ìƒµì—ì„œëŠ” **ë¬¸í—Œ ê²€ìƒ‰**ë§Œ ì‚¬ìš©\n\n```\nğŸ“ PaSa\nâ”œâ”€â”€ agents/\nâ”‚   â”œâ”€â”€ crawler.py    # ë…¼ë¬¸ í¬ë¡¤ë§\nâ”‚   â””â”€â”€ selector.py   # ê´€ë ¨ì„± í‰ê°€ (PPO)\nâ””â”€â”€ search/\n    â”œâ”€â”€ arxiv.py      # arXiv ê²€ìƒ‰\n    â””â”€â”€ scholar.py    # Google Scholar\n```\n\n```\nğŸ“ LitLLM\nâ”œâ”€â”€ retriever.py      # ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\nâ”œâ”€â”€ summarizer.py     # ë…¼ë¬¸ ìš”ì•½\nâ””â”€â”€ writer.py         # Related Work ìƒì„±\n```\n\n```\nğŸ“ AgentReview\nâ”œâ”€â”€ arena.py          # ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„\nâ”œâ”€â”€ paper.py          # ë…¼ë¬¸ íŒŒì‹±\nâ””â”€â”€ reviewer.py       # ë¦¬ë·°ì–´ ì—ì´ì „íŠ¸\n```",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê³µí†µ êµ¬ì„±ìš”ì†Œ\n",
    "\n",
    "ëª¨ë“  Literature AgentëŠ” ë‹¤ìŒ 3ê°€ì§€ í•µì‹¬ ìš”ì†Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ê²€ìƒ‰ ëª¨ë“ˆ** - ë…¼ë¬¸ DBì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ì°¾ê¸°\n",
    "2. **ì²˜ë¦¬ ëª¨ë“ˆ** - ë…¼ë¬¸ íŒŒì‹±, ìš”ì•½, ë¶„ì„\n",
    "3. **ìƒì„± ëª¨ë“ˆ** - ê²°ê³¼ë¬¼ ìƒì„± (ë¦¬ë·°, ë³´ê³ ì„œ ë“±)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Semantic Scholar API í…ŒìŠ¤íŠ¸\nê¸°ë³¸ ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤ (ì¿¼ë¦¬ ë³€ê²½ ê°€ëŠ¥)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### arXiv API í…ŒìŠ¤íŠ¸\narXiv ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ì •ì˜í•˜ê³  ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤ (ì¿¼ë¦¬ ë³€ê²½ ê°€ëŠ¥)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### DIY: ë³¸ì¸ ì—°êµ¬ ì£¼ì œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”\nì¿¼ë¦¬ë§Œ ìˆ˜ì •í•´ì„œ Semantic Scholarì™€ arXivì—ì„œ ê²€ìƒ‰í•´ë´…ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "source": "import requests\n\ndef search_semantic_scholar(query, limit=5):\n    \"\"\"Semantic Scholarì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰\"\"\"\n    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n    params = {\n        \"query\": query,\n        \"limit\": limit,\n        \"fields\": \"paperId,title,authors,year,abstract,citationCount\"  # paperId ì¶”ê°€\n    }\n    \n    # API keyê°€ ìˆìœ¼ë©´ í—¤ë”ì— í¬í•¨\n    headers = {}\n    if SEMANTIC_SCHOLAR_API_KEY:\n        headers['x-api-key'] = SEMANTIC_SCHOLAR_API_KEY\n    \n    response = requests.get(url, params=params, headers=headers)\n    \n    # ì—ëŸ¬ ì²˜ë¦¬\n    if response.status_code == 429:\n        print(\"âš ï¸ Semantic Scholar API rate limit ì´ˆê³¼\")\n        print(\"   ğŸ’¡ ëª‡ ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë‹¤ìŒ Cell(arXiv)ë¡œ ì§„í–‰í•˜ì„¸ìš”\")\n        if not SEMANTIC_SCHOLAR_API_KEY:\n            print(\"   (API key ë°œê¸‰ìœ¼ë¡œ limit ì™„í™” ê°€ëŠ¥: https://www.semanticscholar.org/product/api)\")\n        return {\"data\": []}\n    elif response.status_code != 200:\n        print(f\"âš ï¸ API ì˜¤ë¥˜: {response.status_code}\")\n        return {\"data\": []}\n    \n    return response.json()\n\n# í…ŒìŠ¤íŠ¸: LLM ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\nresults = search_semantic_scholar(\"large language model psychology\")\ndata = results.get('data', [])\n\nif len(data) > 0:\n    print(f\"ê²€ìƒ‰ ê²°ê³¼: {len(data)}ê°œ ë…¼ë¬¸\\n\")\n    for paper in data[:3]:\n        print(f\"ğŸ“„ {paper['title']}\")\n        print(f\"   - ì—°ë„: {paper.get('year', 'N/A')}, ì¸ìš©: {paper.get('citationCount', 0)}\")\n        print(f\"   - ë§í¬: https://www.semanticscholar.org/paper/{paper['paperId']}\")\n        print()\nelse:\n    print(\"ğŸ’¡ ë‹¤ìŒ Cellì—ì„œ arXiv APIë¡œ ì‹¤ìŠµì„ ì§„í–‰í•˜ì„¸ìš”\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import arxiv\n\ndef search_arxiv(query, max_results=5):\n    \"\"\"arXivì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰\"\"\"\n    client = arxiv.Client()\n    search = arxiv.Search(\n        query=query,\n        max_results=max_results,\n        sort_by=arxiv.SortCriterion.Relevance\n    )\n    return list(client.results(search))\n\n# í…ŒìŠ¤íŠ¸\npapers = search_arxiv(\"cognitive psychology AI\")\nprint(f\"arXiv ê²€ìƒ‰ ê²°ê³¼: {len(papers)}ê°œ\\n\")\n\nfor paper in papers[:3]:\n    print(f\"ğŸ“„ {paper.title}\")\n    print(f\"   - ë‚ ì§œ: {paper.published.strftime('%Y-%m-%d')}\")\n    print(f\"   - ë§í¬: {paper.entry_id}\")\n    print()"
  },
  {
   "cell_type": "markdown",
   "source": "### arXiv API í…ŒìŠ¤íŠ¸",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "my_query = \"your research topic here\"  # <- ì´ ë¶€ë¶„ ìˆ˜ì •!\n\n# Semantic Scholar ê²€ìƒ‰\nss_results = search_semantic_scholar(my_query, limit=5)\nprint(\"=== Semantic Scholar ê²°ê³¼ ===\")\nfor paper in ss_results.get('data', []):\n    print(f\"ğŸ“„ {paper['title']}\")\n    print(f\"   {paper.get('year', 'N/A')} | https://www.semanticscholar.org/paper/{paper['paperId']}\")\n    print()\n\nprint(\"=== arXiv ê²°ê³¼ ===\")\narxiv_results = search_arxiv(my_query, max_results=5)\nfor paper in arxiv_results:\n    print(f\"ğŸ“„ {paper.title}\")\n    print(f\"   {paper.published.strftime('%Y-%m-%d')} | {paper.entry_id}\")\n    print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### ì»¤ìŠ¤í…€ ê²€ìƒ‰ í•¨ìˆ˜ ì˜ˆì‹œ\nì—°ë„ ë²”ìœ„ì™€ ìµœì†Œ ì¸ìš©ìˆ˜ í•„í„°ë¥¼ ì¶”ê°€í•œ ê³ ê¸‰ ê²€ìƒ‰ í•¨ìˆ˜ì…ë‹ˆë‹¤."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### DIY: ë³¸ì¸ë§Œì˜ í•„í„° ì¶”ê°€í•˜ê¸°\nì—°ë„, ì¸ìš©ìˆ˜, ì €ë„, ì €ì ë“± ë‹¤ì–‘í•œ ì¡°ê±´ì„ ì¡°í•©í•œ ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### PubMed API ì˜ˆì‹œ (ì‹¬ë¦¬í•™ ì—°êµ¬ìš©)\nì˜í•™/ì‹¬ë¦¬í•™ì— íŠ¹í™”ëœ PubMed ê²€ìƒ‰ í•¨ìˆ˜ì…ë‹ˆë‹¤ (ì¿¼ë¦¬ ë³€ê²½ ê°€ëŠ¥)."
  },
  {
   "cell_type": "markdown",
   "source": "### DIY: ì„¸ DB ê²°ê³¼ ë¹„êµ\nê°™ì€ ì¿¼ë¦¬ë¡œ Semantic Scholar, arXiv, PubMedë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ ê°œìˆ˜ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### DBë³„ íŠ¹ì§• ë¹„êµ\nì„¸ ê°€ì§€ í•™ìˆ  DBì˜ ì¥ë‹¨ì ê³¼ ì¶”ì²œ ìš©ë„ë¥¼ ì •ë¦¬í•œ í‘œì…ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "import requests\n\ndef search_pubmed(query, max_results=5):\n    \"\"\"PubMedì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰ (ì‹¬ë¦¬í•™/ì˜í•™ íŠ¹í™”)\"\"\"\n    # E-utilities API\n    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n    \n    # 1. ê²€ìƒ‰\n    search_url = f\"{base_url}esearch.fcgi\"\n    search_params = {\n        \"db\": \"pubmed\",\n        \"term\": query,\n        \"retmax\": max_results,\n        \"retmode\": \"json\"\n    }\n    search_result = requests.get(search_url, params=search_params).json()\n    ids = search_result.get('esearchresult', {}).get('idlist', [])\n    \n    if not ids:\n        return []\n    \n    # 2. ìƒì„¸ ì •ë³´\n    fetch_url = f\"{base_url}esummary.fcgi\"\n    fetch_params = {\n        \"db\": \"pubmed\",\n        \"id\": \",\".join(ids),\n        \"retmode\": \"json\"\n    }\n    fetch_result = requests.get(fetch_url, params=fetch_params).json()\n    \n    papers = []\n    for pid in ids:\n        info = fetch_result.get('result', {}).get(pid, {})\n        papers.append({\n            'title': info.get('title', ''),\n            'authors': [a.get('name', '') for a in info.get('authors', [])],\n            'year': info.get('pubdate', '')[:4],\n            'journal': info.get('source', '')\n        })\n    return papers\n\n# í…ŒìŠ¤íŠ¸\npubmed_results = search_pubmed(\"cognitive behavioral therapy depression\")\nprint(f\"PubMed ê²°ê³¼: {len(pubmed_results)}ê°œ\")\nfor p in pubmed_results[:3]:\n    print(f\"- {p['title'][:60]}... ({p['year']})\")"
  },
  {
   "cell_type": "markdown",
   "source": "comparison_query = \"your topic\"  # <- ìˆ˜ì •\n\n# ì„¸ DBì—ì„œ ê²€ìƒ‰\nss = search_semantic_scholar(comparison_query)\nax = search_arxiv(comparison_query)\npm = search_pubmed(comparison_query)\n\nprint(f\"Semantic Scholar: {len(ss.get('data', []))}ê°œ\")\nprint(f\"arXiv: {len(ax)}ê°œ\")\nprint(f\"PubMed: {len(pm)}ê°œ\")",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "print(\"\"\"\n| DB | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |\n|----|------|------|----------|\n| Semantic Scholar | ì¸ìš© ë„¤íŠ¸ì›Œí¬, ì„ë² ë”© | rate limit | ì¸ìš© ë¶„ì„ |\n| arXiv | ìµœì‹  ë…¼ë¬¸, ì „ë¬¸ ë¬´ë£Œ | CS í¸ì¤‘ | í”„ë¦¬í”„ë¦°íŠ¸ |\n| PubMed | ì˜í•™/ì‹¬ë¦¬í•™ íŠ¹í™” | ì¼ë°˜ CS ì—†ìŒ | ì‹¬ë¦¬í•™ ë…¼ë¬¸ |\n\"\"\")",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### DBë³„ íŠ¹ì§• ë¹„êµ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 16: ì»¤ìŠ¤í…€ ê²€ìƒ‰ í•¨ìˆ˜ ì˜ˆì‹œ\n\ndef search_semantic_scholar_advanced(query, limit=10, year_from=2020, min_citations=10):\n    \"\"\"í•„í„°ë§ ì˜µì…˜ì´ ì¶”ê°€ëœ ê²€ìƒ‰ í•¨ìˆ˜\"\"\"\n    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n    params = {\n        \"query\": query,\n        \"limit\": limit,\n        \"fields\": \"paperId,title,authors,year,abstract,citationCount,venue\",  # paperId ì¶”ê°€\n        \"year\": f\"{year_from}-\"  # 2020ë…„ ì´í›„ë§Œ\n    }\n    \n    # API keyê°€ ìˆìœ¼ë©´ í—¤ë”ì— í¬í•¨\n    headers = {}\n    if SEMANTIC_SCHOLAR_API_KEY:\n        headers['x-api-key'] = SEMANTIC_SCHOLAR_API_KEY\n    \n    response = requests.get(url, params=params, headers=headers)\n    \n    # ì—ëŸ¬ ì²˜ë¦¬\n    if response.status_code == 429:\n        print(\"âš ï¸ Semantic Scholar API rate limit ì´ˆê³¼\")\n        print(\"   ğŸ’¡ ëª‡ ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”\")\n        return []\n    elif response.status_code != 200:\n        print(f\"âš ï¸ API ì˜¤ë¥˜ ({response.status_code})\")\n        return []\n    \n    data = response.json()\n    \n    # ì¸ìš©ìˆ˜ í•„í„°ë§\n    filtered = [\n        p for p in data.get('data', [])\n        if p.get('citationCount', 0) >= min_citations\n    ]\n    return filtered\n\n# í…ŒìŠ¤íŠ¸\nresults = search_semantic_scholar_advanced(\"LLM reasoning\", year_from=2023, min_citations=50)\nif len(results) > 0:\n    print(f\"í•„í„°ë§ í›„: {len(results)}ê°œ ë…¼ë¬¸\\n\")\n    for p in results[:3]:\n        print(f\"ğŸ“„ {p['title']}\")\n        print(f\"   ì¸ìš©: {p['citationCount']} | https://www.semanticscholar.org/paper/{p['paperId']}\")\n        print()\nelse:\n    print(\"ğŸ’¡ í•„í„° ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë…¼ë¬¸ì´ ì—†ê±°ë‚˜ API ì˜¤ë¥˜ì…ë‹ˆë‹¤\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DIY Cell 17: ë³¸ì¸ë§Œì˜ í•„í„° ì¶”ê°€í•˜ê¸°\n\ndef my_custom_search(query, year_from=2020, min_citations=100, top_venues=None):\n    \"\"\"\n    ë‹¤ì–‘í•œ í•„í„°ë¥¼ ì¡°í•©í•œ ì»¤ìŠ¤í…€ ê²€ìƒ‰\n    \n    Parameters:\n    - year_from: ìµœì†Œ ì—°ë„ (ì˜ˆ: 2020)\n    - min_citations: ìµœì†Œ ì¸ìš©ìˆ˜ (ì˜ˆ: 100)\n    - top_venues: íŠ¹ì • ì €ë„/í•™íšŒë§Œ (ì˜ˆ: [\"Nature\", \"Science\"])\n    \"\"\"\n    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n    params = {\n        \"query\": query,\n        \"limit\": 20,  # í•„í„°ë§ ìœ„í•´ ë§ì´ ê°€ì ¸ì˜¤ê¸°\n        \"fields\": \"paperId,title,authors,year,abstract,citationCount,venue\",  # paperId ì¶”ê°€\n        \"year\": f\"{year_from}-\"\n    }\n    \n    headers = {}\n    if SEMANTIC_SCHOLAR_API_KEY:\n        headers['x-api-key'] = SEMANTIC_SCHOLAR_API_KEY\n    \n    response = requests.get(url, params=params, headers=headers)\n    \n    if response.status_code == 429:\n        print(\"âš ï¸ API rate limit - ëª‡ ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”\")\n        return []\n    elif response.status_code != 200:\n        print(f\"âš ï¸ API ì˜¤ë¥˜: {response.status_code}\")\n        return []\n    \n    papers = response.json().get('data', [])\n    \n    # í•„í„° 1: ì¸ìš©ìˆ˜\n    papers = [p for p in papers if p.get('citationCount', 0) >= min_citations]\n    \n    # í•„í„° 2: Top-tier venue (ì„ íƒì‚¬í•­)\n    if top_venues:\n        papers = [\n            p for p in papers \n            if any(venue.lower() in p.get('venue', {}).get('name', '').lower() \n                   for venue in top_venues)\n        ]\n    \n    # í•„í„° 3: íŠ¹ì • ì €ì í¬í•¨ (ì˜ˆì‹œ - ì£¼ì„ í•´ì œ í›„ ì‚¬ìš©)\n    ### target_author = \"Yann LeCun\"\n    ### papers = [\n    ###     p for p in papers\n    ###     if any(target_author.lower() in author.get('name', '').lower() \n    ###            for author in p.get('authors', []))\n    ### ]\n    \n    return papers\n\n# í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ í•„í„° (2020ë…„ ì´í›„, ì¸ìš©ìˆ˜ 100íšŒ ì´ìƒ)\nresults = my_custom_search(\"deep learning\", year_from=2020, min_citations=100)\nprint(f\"ğŸ“Š í•„í„° ê²°ê³¼: {len(results)}ê°œ ë…¼ë¬¸\\n\")\nfor p in results[:3]:\n    print(f\"ğŸ“„ {p['title'][:60]}...\")\n    print(f\"   ì¸ìš©: {p['citationCount']}, ì—°ë„: {p.get('year', 'N/A')}\")\n    print(f\"   ğŸ”— https://www.semanticscholar.org/paper/{p['paperId']}\")\n    print()\n\n# í…ŒìŠ¤íŠ¸ 2: Top-tier venue í•„í„° (ì£¼ì„ í•´ì œ í›„ ì‚¬ìš©)\n### top_results = my_custom_search(\n###     \"machine learning\", \n###     year_from=2022, \n###     min_citations=50,\n###     top_venues=[\"NeurIPS\", \"ICML\", \"ICLR\", \"Nature\", \"Science\"]\n### )\n### print(f\"\\nğŸ† Top-tier ë…¼ë¬¸: {len(top_results)}ê°œ\")\n### for p in top_results[:3]:\n###     print(f\"ğŸ“„ {p['title'][:50]}...\")\n###     print(f\"   {p.get('venue', {}).get('name', 'N/A')} | https://www.semanticscholar.org/paper/{p['paperId']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: PubMed API ì¶”ê°€ ì˜ˆì‹œ (ì‹¬ë¦¬í•™ ì—°êµ¬ìš©)\n",
    "import requests\n",
    "\n",
    "def search_pubmed(query, max_results=5):\n",
    "    \"\"\"PubMedì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰ (ì‹¬ë¦¬í•™/ì˜í•™ íŠ¹í™”)\"\"\"\n",
    "    # E-utilities API\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    \n",
    "    # 1. ê²€ìƒ‰\n",
    "    search_url = f\"{base_url}esearch.fcgi\"\n",
    "    search_params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": query,\n",
    "        \"retmax\": max_results,\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    search_result = requests.get(search_url, params=search_params).json()\n",
    "    ids = search_result.get('esearchresult', {}).get('idlist', [])\n",
    "    \n",
    "    if not ids:\n",
    "        return []\n",
    "    \n",
    "    # 2. ìƒì„¸ ì •ë³´\n",
    "    fetch_url = f\"{base_url}esummary.fcgi\"\n",
    "    fetch_params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"id\": \",\".join(ids),\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    fetch_result = requests.get(fetch_url, params=fetch_params).json()\n",
    "    \n",
    "    papers = []\n",
    "    for pid in ids:\n",
    "        info = fetch_result.get('result', {}).get(pid, {})\n",
    "        papers.append({\n",
    "            'title': info.get('title', ''),\n",
    "            'authors': [a.get('name', '') for a in info.get('authors', [])],\n",
    "            'year': info.get('pubdate', '')[:4],\n",
    "            'journal': info.get('source', '')\n",
    "        })\n",
    "    return papers\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "pubmed_results = search_pubmed(\"cognitive behavioral therapy depression\")\n",
    "print(f\"PubMed ê²°ê³¼: {len(pubmed_results)}ê°œ\")\n",
    "for p in pubmed_results[:3]:\n",
    "    print(f\"- {p['title'][:60]}... ({p['year']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 19: ì„¸ DB ê²°ê³¼ ë¹„êµ\n",
    "comparison_query = \"your topic\"  # <- ìˆ˜ì •\n",
    "\n",
    "# ì„¸ DBì—ì„œ ê²€ìƒ‰\n",
    "ss = search_semantic_scholar(comparison_query)\n",
    "ax = search_arxiv(comparison_query)\n",
    "pm = search_pubmed(comparison_query)\n",
    "\n",
    "print(f\"Semantic Scholar: {len(ss.get('data', []))}ê°œ\")\n",
    "print(f\"arXiv: {len(ax)}ê°œ\")\n",
    "print(f\"PubMed: {len(pm)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: ê²°ê³¼ ë¹„êµ ë¶„ì„\n",
    "print(\"\"\"\n",
    "ğŸ“Š DBë³„ íŠ¹ì§• ë¹„êµ\n",
    "\n",
    "| DB | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |\n",
    "|----|------|------|----------|\n",
    "| Semantic Scholar | ì¸ìš© ë„¤íŠ¸ì›Œí¬, ì„ë² ë”© | rate limit | ì¸ìš© ë¶„ì„ |\n",
    "| arXiv | ìµœì‹  ë…¼ë¬¸, ì „ë¬¸ ë¬´ë£Œ | CS í¸ì¤‘ | í”„ë¦¬í”„ë¦°íŠ¸ |\n",
    "| PubMed | ì˜í•™/ì‹¬ë¦¬í•™ íŠ¹í™” | ì¼ë°˜ CS ì—†ìŒ | ì‹¬ë¦¬í•™ ë…¼ë¬¸ |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í† ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### í† ë¡  ì§ˆë¬¸\n\n1. **ë³¸ì¸ ì—°êµ¬ì— ê°€ì¥ ìœ ìš©í•  ë„êµ¬ëŠ”?**\n   - Agent Laboratory, PaSa, LitLLM, AgentReview ì¤‘\n\n2. **ì–´ë–¤ API ì¡°í•©ì´ ì¢‹ì„ê¹Œ?**\n   - ì‹¬ë¦¬í•™ ì—°êµ¬: PubMed + Semantic Scholar?\n   - AI ì—°êµ¬: arXiv + Semantic Scholar?\n\n3. **ì»¤ìŠ¤í…€í•˜ê³  ì‹¶ì€ ê¸°ëŠ¥ì€?**\n   - í•œê¸€ ë…¼ë¬¸ ê²€ìƒ‰?\n   - íŠ¹ì • ì €ë„ í•„í„°?\n   - ë©”íƒ€ë¶„ì„ìš© íš¨ê³¼í¬ê¸° ì¶”ì¶œ?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì–´ì„œ ì‹¤ìŠµí•  ë‚´ìš©:\n",
    "- **Part 2**: Agent Laboratory / PaSaë¡œ ë¬¸í—Œ ê²€ìƒ‰ ìë™í™”\n",
    "- **Part 3**: LitLLMìœ¼ë¡œ Related Work ì´ˆì•ˆ ìƒì„±\n",
    "- **Part 4**: AgentReviewë¡œ ë…¼ë¬¸ í”¼ë“œë°± ë°›ê¸°\n",
    "\n",
    "ê° ë…¸íŠ¸ë¶ì—ì„œ **íŒŒì•…í•˜ê¸° â†’ ì¨ë³´ê¸° â†’ ë°”ê¿”ë³´ê¸°** íŒ¨í„´ì„ ë”°ë¦…ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}