{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: ì˜¤í”ˆì†ŒìŠ¤ Literature Agent ê°œê´€\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. ì˜¤í”ˆì†ŒìŠ¤ ë¬¸í—Œ ë¦¬ë·° ì—ì´ì „íŠ¸ì˜ ì¢…ë¥˜ì™€ íŠ¹ì§• ì´í•´\n",
    "2. ê° ì—ì´ì „íŠ¸ì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œ íŒŒì•…\n",
    "3. í•™ìˆ  API (Semantic Scholar, arXiv, PubMed) ê¸°ë³¸ ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: í™˜ê²½ ì„¤ì • (Colab/ë¡œì»¬ ìë™ ê°ì§€)\nimport os\nimport sys\n\n# Colab í™˜ê²½ ê°ì§€\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive/')\n    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n    os.chdir(WORKSHOP_DIR)\n    IN_COLAB = True\n    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\nexcept ImportError:\n    # ë¡œì»¬ í™˜ê²½\n    WORKSHOP_DIR = os.getcwd()\n    IN_COLAB = False\n    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n\nprint(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜\n# Colab: ìë™ ì„¤ì¹˜\n# ë¡œì»¬: pyproject.tomlë¡œ ë¯¸ë¦¬ ì„¤ì¹˜ í•„ìš” (uv pip install -e . ë˜ëŠ” pip install -e .)\n\nif IN_COLAB:\n    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n    !pip install requests python-dotenv semanticscholar arxiv google-generativeai -q\n    print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")\nelse:\n    print(\"âœ… ë¡œì»¬ í™˜ê²½: pyproject.tomlë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©\")\n    print(\"   (ë¯¸ì„¤ì¹˜ ì‹œ: uv pip install -e . ë˜ëŠ” pip install -e .)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: API Key ë¡œë”©\nimport os\nfrom pathlib import Path\n\n# Colab í™˜ê²½ ì²´í¬\nif IN_COLAB:\n    # Colab userdataì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n    try:\n        from google.colab import userdata\n        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n        print(\"âœ… Colab Secretsì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n    except:\n        print(\"âš ï¸ Colab Secretsì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n        print(\"   ì¢Œì¸¡ ğŸ”‘ ì•„ì´ì½˜ > Add new secret\")\n        GEMINI_API_KEY = None\nelse:\n    # ë¡œì»¬ í™˜ê²½: dotenv ì‚¬ìš©\n    try:\n        from dotenv import load_dotenv\n        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ .env ì°¾ê¸°\n        load_dotenv()\n        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n        \n        if GEMINI_API_KEY:\n            print(\"âœ… .env íŒŒì¼ì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n        else:\n            print(\"âš ï¸ .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n            print(\"   ì˜ˆ: GEMINI_API_KEY=your_key_here\")\n    except ImportError:\n        print(\"âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n        print(\"   ì‹¤í–‰: pip install python-dotenv\")\n        GEMINI_API_KEY = None\n\n# API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\nif GEMINI_API_KEY:\n    print(f\"ğŸ”‘ API Key: {GEMINI_API_KEY[:10]}...\")\nelse:\n    print(\"âŒ API Keyë¥¼ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë¶€ ê¸°ëŠ¥ì´ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\")\n    \nprint(\"\\nğŸ’¡ Semantic Scholar, arXiv, PubMedëŠ” API key ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: ì˜¤í”ˆì†ŒìŠ¤ Literature Agent ë¹„êµ\n",
    "\n",
    "ì½”ë“œê°€ ê³µê°œëœ ì—ì´ì „íŠ¸ë§Œ ë‹¤ë£¹ë‹ˆë‹¤. ì›¹ ì„œë¹„ìŠ¤(Elicit, Consensus ë“±)ëŠ” ì œì™¸."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì£¼ìš” ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸\n",
    "\n",
    "| í”„ë¡œì íŠ¸ | Stars | ìš©ë„ | ê²€ìƒ‰ DB |\n",
    "|----------|------:|------|--------|\n",
    "| [GPT-Researcher](https://github.com/assafelovic/gpt-researcher) | 24.9k | ì›¹ê²€ìƒ‰ â†’ ë³´ê³ ì„œ | ì›¹ (Tavily) |\n",
    "| [AI-Scientist](https://github.com/SakanaAI/AI-Scientist) | 12k | ì•„ì´ë””ì–´â†’ë…¼ë¬¸ ìë™í™” | Semantic Scholar |\n",
    "| [PaperQA2](https://github.com/Future-House/paper-qa) | 8k | PDF RAG Q&A | Semantic Scholar |\n",
    "| [**Agent Laboratory**](https://github.com/SamuelSchmidgall/AgentLaboratory) | 5.2k | **ë¬¸í—Œâ†’ì‹¤í—˜â†’ë³´ê³ ì„œ** | **arXiv** |\n",
    "| [**PaSa**](https://github.com/bytedance/pasa) | 1.5k | **ë…¼ë¬¸ ê²€ìƒ‰ íŠ¹í™”** | **arXiv + Scholar** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜¤ëŠ˜ ì§‘ì¤‘í•  4ê°€ì§€ ë„êµ¬\n",
    "\n",
    "| ë„êµ¬ | ê¸°ëŠ¥ | ì €ì¥ì†Œ |\n",
    "|------|------|--------|\n",
    "| **Agent Laboratory** | ë¬¸í—Œ ê²€ìƒ‰ â†’ ì‹¤í—˜ â†’ ë³´ê³ ì„œ | github.com/SamuelSchmidgall/AgentLaboratory |\n",
    "| **PaSa** | ë…¼ë¬¸ ê²€ìƒ‰ íŠ¹í™” (PPO í•™ìŠµ) | github.com/bytedance/pasa |\n",
    "| **LitLLM** | Related Work ìë™ ìƒì„± | github.com/ServiceNow/litllm |\n",
    "| **AgentReview** | Peer Review ì‹œë®¬ë ˆì´ì…˜ | github.com/ahren09/agentreview |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ê° ë„êµ¬ì˜ í•µì‹¬ êµ¬ì¡° í™•ì¸\n",
    "print(\"\"\"\n",
    "ğŸ“ Agent Laboratory êµ¬ì¡°\n",
    "â”œâ”€â”€ agents/\n",
    "â”‚   â”œâ”€â”€ literature_agent.py   # ë¬¸í—Œ ê²€ìƒ‰\n",
    "â”‚   â”œâ”€â”€ experiment_agent.py   # ì‹¤í—˜ ì„¤ê³„\n",
    "â”‚   â””â”€â”€ report_agent.py       # ë³´ê³ ì„œ ìƒì„±\n",
    "â””â”€â”€ tools/arxiv_search.py     # arXiv API\n",
    "\n",
    "ğŸ“ PaSa êµ¬ì¡°\n",
    "â”œâ”€â”€ agents/\n",
    "â”‚   â”œâ”€â”€ crawler.py    # ë…¼ë¬¸ í¬ë¡¤ë§\n",
    "â”‚   â””â”€â”€ selector.py   # ê´€ë ¨ì„± í‰ê°€ (PPO)\n",
    "â””â”€â”€ search/\n",
    "    â”œâ”€â”€ arxiv.py      # arXiv ê²€ìƒ‰\n",
    "    â””â”€â”€ scholar.py    # Google Scholar\n",
    "\n",
    "ğŸ“ LitLLM êµ¬ì¡°\n",
    "â”œâ”€â”€ retriever.py      # ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\n",
    "â”œâ”€â”€ summarizer.py     # ë…¼ë¬¸ ìš”ì•½\n",
    "â””â”€â”€ writer.py         # Related Work ìƒì„±\n",
    "\n",
    "ğŸ“ AgentReview êµ¬ì¡°\n",
    "â”œâ”€â”€ arena.py          # ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„\n",
    "â”œâ”€â”€ paper.py          # ë…¼ë¬¸ íŒŒì‹±\n",
    "â””â”€â”€ reviewer.py       # ë¦¬ë·°ì–´ ì—ì´ì „íŠ¸\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê³µí†µ êµ¬ì„±ìš”ì†Œ\n",
    "\n",
    "ëª¨ë“  Literature AgentëŠ” ë‹¤ìŒ 3ê°€ì§€ í•µì‹¬ ìš”ì†Œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ê²€ìƒ‰ ëª¨ë“ˆ** - ë…¼ë¬¸ DBì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ì°¾ê¸°\n",
    "2. **ì²˜ë¦¬ ëª¨ë“ˆ** - ë…¼ë¬¸ íŒŒì‹±, ìš”ì•½, ë¶„ì„\n",
    "3. **ìƒì„± ëª¨ë“ˆ** - ê²°ê³¼ë¬¼ ìƒì„± (ë¦¬ë·°, ë³´ê³ ì„œ ë“±)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì§ˆë¬¸\n\nì´ êµ¬ì¡°ë¥¼ ë³´ê³  ìƒê°í•´ë³´ì„¸ìš”:\n- ë³¸ì¸ ì—°êµ¬ì—ì„œ ê°€ì¥ ìì£¼ ì“¸ ê²ƒ ê°™ì€ ê¸°ëŠ¥ì€?\n- ì–´ë–¤ ë¶€ë¶„ì„ ì»¤ìŠ¤í…€í•˜ë©´ ìœ ìš©í• ê¹Œ?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ì¨ë³´ê¸°: í•™ìˆ  API ê¸°ë³¸ ì‚¬ìš©ë²•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API ë¹„êµ\n",
    "\n",
    "| API | Key í•„ìš” | ë¹„ìš© | íŠ¹ì§• |\n",
    "|-----|----------|------|------|\n",
    "| **Semantic Scholar** | ì„ íƒ | ë¬´ë£Œ | ì¸ìš© ë„¤íŠ¸ì›Œí¬, ì„ë² ë”© |\n",
    "| **arXiv** | ë¶ˆí•„ìš” | ë¬´ë£Œ | í”„ë¦¬í”„ë¦°íŠ¸, ì „ë¬¸ ì ‘ê·¼ |\n",
    "| **PubMed** | ë¶ˆí•„ìš” | ë¬´ë£Œ | ì˜í•™/ì‹¬ë¦¬í•™ íŠ¹í™” |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Semantic Scholar API í…ŒìŠ¤íŠ¸\n",
    "import requests\n",
    "\n",
    "def search_semantic_scholar(query, limit=5):\n",
    "    \"\"\"Semantic Scholarì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰\"\"\"\n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"limit\": limit,\n",
    "        \"fields\": \"title,authors,year,abstract,citationCount\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: LLM ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\n",
    "results = search_semantic_scholar(\"large language model psychology\")\n",
    "print(f\"ê²€ìƒ‰ ê²°ê³¼: {len(results.get('data', []))}ê°œ ë…¼ë¬¸\\n\")\n",
    "\n",
    "for paper in results.get('data', [])[:3]:\n",
    "    print(f\"ğŸ“„ {paper['title']}\")\n",
    "    print(f\"   - ì—°ë„: {paper.get('year', 'N/A')}, ì¸ìš©: {paper.get('citationCount', 0)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: arXiv API í…ŒìŠ¤íŠ¸\n",
    "import arxiv\n",
    "\n",
    "def search_arxiv(query, max_results=5):\n",
    "    \"\"\"arXivì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰\"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    return list(search.results())\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "papers = search_arxiv(\"cognitive psychology AI\")\n",
    "print(f\"arXiv ê²€ìƒ‰ ê²°ê³¼: {len(papers)}ê°œ\\n\")\n",
    "\n",
    "for paper in papers[:3]:\n",
    "    print(f\"ğŸ“„ {paper.title}\")\n",
    "    print(f\"   - ë‚ ì§œ: {paper.published.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"   - PDF: {paper.pdf_url}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: ë³¸ì¸ ì—°êµ¬ ì£¼ì œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 13: ë³¸ì¸ ì—°êµ¬ ì£¼ì œë¡œ ê²€ìƒ‰\n",
    "# íŒíŠ¸: query ë³€ìˆ˜ë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤\n",
    "\n",
    "my_query = \"your research topic here\"  # <- ì´ ë¶€ë¶„ ìˆ˜ì •!\n",
    "\n",
    "# Semantic Scholar ê²€ìƒ‰\n",
    "ss_results = search_semantic_scholar(my_query, limit=5)\n",
    "print(\"=== Semantic Scholar ê²°ê³¼ ===\")\n",
    "for paper in ss_results.get('data', []):\n",
    "    print(f\"- {paper['title']} ({paper.get('year', 'N/A')})\")\n",
    "\n",
    "print(\"\\n=== arXiv ê²°ê³¼ ===\")\n",
    "arxiv_results = search_arxiv(my_query, max_results=5)\n",
    "for paper in arxiv_results:\n",
    "    print(f\"- {paper.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 14: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n",
    "# ì–´ë–¤ DBê°€ ë” ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ë¥¼ ì£¼ë‚˜ìš”?\n",
    "\n",
    "# ë©”ëª¨:\n",
    "# - Semantic Scholar: \n",
    "# - arXiv: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°”ê¿”ë³´ê¸°: ê²€ìƒ‰ í•¨ìˆ˜ ì»¤ìŠ¤í…€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìˆ˜ì • í¬ì¸íŠ¸\n",
    "\n",
    "| í•­ëª© | ê¸°ë³¸ê°’ | ì»¤ìŠ¤í…€ ì•„ì´ë””ì–´ |\n",
    "|------|--------|----------------|\n",
    "| ê²€ìƒ‰ í•„ë“œ | title, abstract | + authors, venue |\n",
    "| ì •ë ¬ ê¸°ì¤€ | relevance | citationCount, year |\n",
    "| í•„í„° | ì—†ìŒ | ì—°ë„ ë²”ìœ„, ìµœì†Œ ì¸ìš©ìˆ˜ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: ì»¤ìŠ¤í…€ ê²€ìƒ‰ í•¨ìˆ˜ ì˜ˆì‹œ\n",
    "\n",
    "def search_semantic_scholar_advanced(query, limit=10, year_from=2020, min_citations=10):\n",
    "    \"\"\"í•„í„°ë§ ì˜µì…˜ì´ ì¶”ê°€ëœ ê²€ìƒ‰ í•¨ìˆ˜\"\"\"\n",
    "    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"limit\": limit,\n",
    "        \"fields\": \"title,authors,year,abstract,citationCount,venue\",\n",
    "        \"year\": f\"{year_from}-\"  # 2020ë…„ ì´í›„ë§Œ\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # ì¸ìš©ìˆ˜ í•„í„°ë§\n",
    "    filtered = [\n",
    "        p for p in data.get('data', [])\n",
    "        if p.get('citationCount', 0) >= min_citations\n",
    "    ]\n",
    "    return filtered\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "results = search_semantic_scholar_advanced(\"LLM reasoning\", year_from=2023, min_citations=50)\n",
    "print(f\"í•„í„°ë§ í›„: {len(results)}ê°œ ë…¼ë¬¸\")\n",
    "for p in results[:3]:\n",
    "    print(f\"- {p['title']} (ì¸ìš©: {p['citationCount']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 17: ë³¸ì¸ë§Œì˜ í•„í„° ì¶”ê°€í•˜ê¸°\n",
    "# ì˜ˆ: íŠ¹ì • ì €ì í•„í„°, íŠ¹ì • ì €ë„ í•„í„° ë“±\n",
    "\n",
    "def my_custom_search(query):\n",
    "    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: PubMed API ì¶”ê°€ ì˜ˆì‹œ (ì‹¬ë¦¬í•™ ì—°êµ¬ìš©)\n",
    "import requests\n",
    "\n",
    "def search_pubmed(query, max_results=5):\n",
    "    \"\"\"PubMedì—ì„œ ë…¼ë¬¸ ê²€ìƒ‰ (ì‹¬ë¦¬í•™/ì˜í•™ íŠ¹í™”)\"\"\"\n",
    "    # E-utilities API\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    \n",
    "    # 1. ê²€ìƒ‰\n",
    "    search_url = f\"{base_url}esearch.fcgi\"\n",
    "    search_params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": query,\n",
    "        \"retmax\": max_results,\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    search_result = requests.get(search_url, params=search_params).json()\n",
    "    ids = search_result.get('esearchresult', {}).get('idlist', [])\n",
    "    \n",
    "    if not ids:\n",
    "        return []\n",
    "    \n",
    "    # 2. ìƒì„¸ ì •ë³´\n",
    "    fetch_url = f\"{base_url}esummary.fcgi\"\n",
    "    fetch_params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"id\": \",\".join(ids),\n",
    "        \"retmode\": \"json\"\n",
    "    }\n",
    "    fetch_result = requests.get(fetch_url, params=fetch_params).json()\n",
    "    \n",
    "    papers = []\n",
    "    for pid in ids:\n",
    "        info = fetch_result.get('result', {}).get(pid, {})\n",
    "        papers.append({\n",
    "            'title': info.get('title', ''),\n",
    "            'authors': [a.get('name', '') for a in info.get('authors', [])],\n",
    "            'year': info.get('pubdate', '')[:4],\n",
    "            'journal': info.get('source', '')\n",
    "        })\n",
    "    return papers\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "pubmed_results = search_pubmed(\"cognitive behavioral therapy depression\")\n",
    "print(f\"PubMed ê²°ê³¼: {len(pubmed_results)}ê°œ\")\n",
    "for p in pubmed_results[:3]:\n",
    "    print(f\"- {p['title'][:60]}... ({p['year']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 19: ì„¸ DB ê²°ê³¼ ë¹„êµ\n",
    "comparison_query = \"your topic\"  # <- ìˆ˜ì •\n",
    "\n",
    "# ì„¸ DBì—ì„œ ê²€ìƒ‰\n",
    "ss = search_semantic_scholar(comparison_query)\n",
    "ax = search_arxiv(comparison_query)\n",
    "pm = search_pubmed(comparison_query)\n",
    "\n",
    "print(f\"Semantic Scholar: {len(ss.get('data', []))}ê°œ\")\n",
    "print(f\"arXiv: {len(ax)}ê°œ\")\n",
    "print(f\"PubMed: {len(pm)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: ê²°ê³¼ ë¹„êµ ë¶„ì„\n",
    "print(\"\"\"\n",
    "ğŸ“Š DBë³„ íŠ¹ì§• ë¹„êµ\n",
    "\n",
    "| DB | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |\n",
    "|----|------|------|----------|\n",
    "| Semantic Scholar | ì¸ìš© ë„¤íŠ¸ì›Œí¬, ì„ë² ë”© | rate limit | ì¸ìš© ë¶„ì„ |\n",
    "| arXiv | ìµœì‹  ë…¼ë¬¸, ì „ë¬¸ ë¬´ë£Œ | CS í¸ì¤‘ | í”„ë¦¬í”„ë¦°íŠ¸ |\n",
    "| PubMed | ì˜í•™/ì‹¬ë¦¬í•™ íŠ¹í™” | ì¼ë°˜ CS ì—†ìŒ | ì‹¬ë¦¬í•™ ë…¼ë¬¸ |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í† ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### í† ë¡  ì§ˆë¬¸\n\n1. **ë³¸ì¸ ì—°êµ¬ì— ê°€ì¥ ìœ ìš©í•  ë„êµ¬ëŠ”?**\n   - Agent Laboratory, PaSa, LitLLM, AgentReview ì¤‘\n\n2. **ì–´ë–¤ API ì¡°í•©ì´ ì¢‹ì„ê¹Œ?**\n   - ì‹¬ë¦¬í•™ ì—°êµ¬: PubMed + Semantic Scholar?\n   - AI ì—°êµ¬: arXiv + Semantic Scholar?\n\n3. **ì»¤ìŠ¤í…€í•˜ê³  ì‹¶ì€ ê¸°ëŠ¥ì€?**\n   - í•œê¸€ ë…¼ë¬¸ ê²€ìƒ‰?\n   - íŠ¹ì • ì €ë„ í•„í„°?\n   - ë©”íƒ€ë¶„ì„ìš© íš¨ê³¼í¬ê¸° ì¶”ì¶œ?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì–´ì„œ ì‹¤ìŠµí•  ë‚´ìš©:\n",
    "- **Part 2**: Agent Laboratory / PaSaë¡œ ë¬¸í—Œ ê²€ìƒ‰ ìë™í™”\n",
    "- **Part 3**: LitLLMìœ¼ë¡œ Related Work ì´ˆì•ˆ ìƒì„±\n",
    "- **Part 4**: AgentReviewë¡œ ë…¼ë¬¸ í”¼ë“œë°± ë°›ê¸°\n",
    "\n",
    "ê° ë…¸íŠ¸ë¶ì—ì„œ **íŒŒì•…í•˜ê¸° â†’ ì¨ë³´ê¸° â†’ ë°”ê¿”ë³´ê¸°** íŒ¨í„´ì„ ë”°ë¦…ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}