{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Deep Dive - Related Work ìƒì„± (LitLLM)\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. LitLLMì˜ ì½”ë“œ êµ¬ì¡°ì™€ ë°ì´í„° íë¦„ ì´í•´\n",
    "2. ë³¸ì¸ ì´ˆë¡ìœ¼ë¡œ Related Work ì´ˆì•ˆ ìƒì„±\n",
    "3. í”„ë¡¬í”„íŠ¸/ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ìœ¼ë¡œ ì¶œë ¥ í’ˆì§ˆ ê°œì„ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: í™˜ê²½ ì„¤ì • (Colab/ë¡œì»¬ ìë™ ê°ì§€)\nimport os\nimport sys\n\n# Colab í™˜ê²½ ê°ì§€\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive/')\n    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n    os.chdir(WORKSHOP_DIR)\n    IN_COLAB = True\n    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\nexcept ImportError:\n    # ë¡œì»¬ í™˜ê²½\n    WORKSHOP_DIR = os.getcwd()\n    IN_COLAB = False\n    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n\nprint(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜\n# Colab: ìë™ ì„¤ì¹˜\n# ë¡œì»¬: pyproject.tomlë¡œ ë¯¸ë¦¬ ì„¤ì¹˜ í•„ìš” (uv pip install -e . ë˜ëŠ” pip install -e .)\n\nif IN_COLAB:\n    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n    %pip install google-generativeai python-dotenv requests semanticscholar -q\n    print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")\nelse:\n    print(\"âœ… ë¡œì»¬ í™˜ê²½: pyproject.tomlë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©\")\n    print(\"   (ë¯¸ì„¤ì¹˜ ì‹œ: uv pip install -e . ë˜ëŠ” pip install -e .)\")\n\nprint(\"\\nğŸ’¡ LitLLM ì›¹ ë°ëª¨: https://litllm.onrender.com\")\nprint(\"   ì´ ë…¸íŠ¸ë¶ì€ LitLLM ë°©ì‹ì„ ì¬í˜„í•œ ê°„ì†Œí™” ë²„ì „ì…ë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: API Key ë¡œë”©\nimport os\n\nif IN_COLAB:\n    try:\n        from google.colab import userdata\n        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n        print(\"âœ… Colab Secretsì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n    except:\n        OPENAI_API_KEY = None\n        GEMINI_API_KEY = None\n        print(\"âš ï¸ Colab Secretsì— API KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\nelse:\n    try:\n        from dotenv import load_dotenv\n        load_dotenv()\n        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n        if OPENAI_API_KEY or GEMINI_API_KEY:\n            print(\"âœ… .env íŒŒì¼ì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n        else:\n            print(\"âš ï¸ .env íŒŒì¼ì— API KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n    except ImportError:\n        OPENAI_API_KEY = None\n        GEMINI_API_KEY = None\n\nos.environ['OPENAI_API_KEY'] = OPENAI_API_KEY or ''\nos.environ['GEMINI_API_KEY'] = GEMINI_API_KEY or ''\n\nprint(f\"\\nğŸ”‘ OpenAI: {'ì„¤ì •ë¨' if OPENAI_API_KEY else 'ì—†ìŒ (LLM ê¸°ëŠ¥ ì œí•œ)'}\")\nprint(f\"ğŸ”‘ Gemini: {'ì„¤ì •ë¨' if GEMINI_API_KEY else 'ì—†ìŒ (LLM ê¸°ëŠ¥ ì œí•œ)'}\")\nprint(\"ğŸ’¡ Semantic Scholar ê²€ìƒ‰ì€ API key ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: LitLLM ì½”ë“œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### LitLLM êµ¬ì¡° (TMLR 2024)\n\nLitLLMì€ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤: https://litllm.onrender.com\n\n**í•µì‹¬ íŒŒì´í”„ë¼ì¸ (ì´ ë…¸íŠ¸ë¶ì—ì„œ ì¬í˜„):**\n\n```\n1. Retriever  â†’ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ (Semantic Scholar)\n2. Summarizer â†’ ë…¼ë¬¸ ìš”ì•½ (LLM)\n3. Writer     â†’ Related Work ìƒì„± (LLM)\n```\n\n**ì›Œí¬í”Œë¡œìš°:**\n1. ë…¼ë¬¸ ì´ˆë¡ ì…ë ¥ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ\n2. `retriever`ê°€ Semantic Scholarì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\n3. `summarizer`ê°€ ê° ë…¼ë¬¸ ìš”ì•½\n4. `writer`ê°€ Related Work ë¬¸ë‹¨ ìƒì„± (ì¸ìš© í¬í•¨)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: í•µì‹¬ ëª¨ë“ˆ ì§ì ‘ êµ¬í˜„ (LitLLM ìŠ¤íƒ€ì¼)\nimport requests\nimport google.generativeai as genai\n\nclass LitLLMPipeline:\n    \"\"\"\n    LitLLM í•µì‹¬ íŒŒì´í”„ë¼ì¸ ì¬í˜„\n    retriever â†’ summarizer â†’ writer\n    \"\"\"\n    \n    def __init__(self):\n        if GEMINI_API_KEY:\n            genai.configure(api_key=GEMINI_API_KEY)\n            self.model = genai.GenerativeModel('gemini-1.5-flash')\n        else:\n            self.model = None\n    \n    def retrieve_papers(self, abstract, num_papers=5):\n        \"\"\"Step 1: ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ (Semantic Scholar)\"\"\"\n        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)\n        keywords = self._extract_keywords(abstract)\n        \n        # Semantic Scholar ê²€ìƒ‰\n        url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n        params = {\n            \"query\": \" \".join(keywords),\n            \"limit\": num_papers,\n            \"fields\": \"title,authors,year,abstract,citationCount\"\n        }\n        response = requests.get(url, params=params)\n        return response.json().get('data', [])\n    \n    def summarize_paper(self, paper):\n        \"\"\"Step 2: ë…¼ë¬¸ ìš”ì•½ (LLM)\"\"\"\n        if not self.model:\n            return f\"{paper['title']}: {paper.get('abstract', '')[:100]}...\"\n        \n        prompt = f\"\"\"Summarize this paper in 1-2 sentences for a Related Work section:\n\nTitle: {paper['title']}\nAbstract: {paper.get('abstract', 'N/A')}\n\nFocus on the main contribution and methodology.\"\"\"\n        \n        response = self.model.generate_content(prompt)\n        return response.text\n    \n    def write_related_work(self, abstract, summaries):\n        \"\"\"Step 3: Related Work ìƒì„± (LLM)\"\"\"\n        if not self.model:\n            return \"LLM API key í•„ìš”\"\n        \n        papers_text = \"\\n\".join([f\"- {s}\" for s in summaries])\n        \n        prompt = f\"\"\"Write a Related Work section for a paper with this abstract:\n\nABSTRACT:\n{abstract}\n\nRELATED PAPERS:\n{papers_text}\n\nRequirements:\n- Write 2-3 paragraphs\n- Group papers by theme\n- Use academic writing style\n- Include citations as (Author et al., Year)\"\"\"\n        \n        response = self.model.generate_content(prompt)\n        return response.text\n    \n    def _extract_keywords(self, text):\n        \"\"\"ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n        # ë¶ˆìš©ì–´ ì œê±° í›„ ë¹ˆë„ìˆœ ì •ë ¬ (ê°„ë‹¨ ë²„ì „)\n        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', \n                     'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n                     'would', 'could', 'should', 'may', 'might', 'must', 'shall',\n                     'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',\n                     'as', 'into', 'through', 'during', 'before', 'after', 'and',\n                     'but', 'or', 'nor', 'so', 'yet', 'both', 'either', 'neither',\n                     'not', 'only', 'own', 'same', 'than', 'too', 'very', 'just',\n                     'this', 'that', 'these', 'those', 'we', 'our', 'they', 'their'}\n        \n        words = text.lower().split()\n        keywords = [w for w in words if w.isalpha() and w not in stopwords and len(w) > 3]\n        \n        # ë¹ˆë„ ê³„ì‚°\n        from collections import Counter\n        freq = Counter(keywords)\n        return [w for w, _ in freq.most_common(5)]\n\nprint(\"âœ… LitLLMPipeline í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ (Gemini ì‚¬ìš©)\")\nprint(\"   ë©”ì„œë“œ: retrieve_papers(), summarize_paper(), write_related_work()\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì§ˆë¬¸\n",
    "\n",
    "LitLLMì˜ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ë³´ê³  ìƒê°í•´ë³´ì„¸ìš”:\n",
    "- ì–´ë–¤ ë‹¨ê³„ì—ì„œ í’ˆì§ˆ ì†ì‹¤ì´ ê°€ì¥ í´ê¹Œ?\n",
    "- ì–´ë–¤ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´ ê²°ê³¼ê°€ ì¢‹ì•„ì§ˆê¹Œ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ì¨ë³´ê¸°: Related Work ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìƒ˜í”Œ ë°ì´í„°\n",
    "\n",
    "í…ŒìŠ¤íŠ¸í•  ë…¼ë¬¸ ì´ˆë¡ (AI ì‹¬ë¦¬í•™ ê´€ë ¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ìƒ˜í”Œ ì‹¤í–‰ (ë°œí‘œì ë°ëª¨)\n",
    "sample_abstract = \"\"\"\n",
    "Large language models (LLMs) have shown remarkable capabilities in various \n",
    "cognitive tasks. This paper investigates whether LLMs exhibit human-like \n",
    "cognitive biases, specifically focusing on anchoring effects and confirmation \n",
    "bias. We design a series of experiments adapted from classical psychology \n",
    "studies and evaluate GPT-4 and Claude on these tasks. Our results show that \n",
    "LLMs do exhibit similar biases to humans, but with different magnitudes. \n",
    "This has implications for using LLMs as cognitive models and for AI safety.\n",
    "\"\"\"\n",
    "\n",
    "pipeline = LitLLMPipeline()\n",
    "\n",
    "# Step 1: ë…¼ë¬¸ ê²€ìƒ‰\n",
    "print(\"ğŸ” Step 1: ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰...\")\n",
    "papers = pipeline.retrieve_papers(sample_abstract, num_papers=5)\n",
    "print(f\"   {len(papers)}ê°œ ë…¼ë¬¸ ë°œê²¬\\n\")\n",
    "\n",
    "for p in papers[:3]:\n",
    "    print(f\"   - {p['title'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: ìš”ì•½ + Related Work ìƒì„±\nif GEMINI_API_KEY and papers:\n    # Step 2: ê° ë…¼ë¬¸ ìš”ì•½\n    print(\"ğŸ“ Step 2: ë…¼ë¬¸ ìš”ì•½...\")\n    summaries = []\n    for paper in papers[:5]:\n        summary = pipeline.summarize_paper(paper)\n        summaries.append(summary)\n        print(f\"   âœ“ {paper['title'][:40]}...\")\n    \n    # Step 3: Related Work ìƒì„±\n    print(\"\\nâœï¸ Step 3: Related Work ìƒì„±...\\n\")\n    related_work = pipeline.write_related_work(sample_abstract, summaries)\n    \n    print(\"=\" * 60)\n    print(\"RELATED WORK\")\n    print(\"=\" * 60)\n    print(related_work)\nelse:\n    print(\"Gemini API key ì—†ìŒ - ìš”ì•½/ìƒì„± ë‹¨ê³„ ê±´ë„ˆëœ€\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: ë³¸ì¸ ì´ˆë¡ìœ¼ë¡œ Related Work ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 13: ë³¸ì¸ ì´ˆë¡ ì…ë ¥\n",
    "# íŒíŠ¸: my_abstract ë³€ìˆ˜ì— ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”\n",
    "\n",
    "my_abstract = \"\"\"\n",
    "ì—¬ê¸°ì— ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\n",
    "ë˜ëŠ” ì—°êµ¬ ì•„ì´ë””ì–´ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸ” ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘...\")\n",
    "my_papers = pipeline.retrieve_papers(my_abstract, num_papers=5)\n",
    "print(f\"ê²€ìƒ‰ ê²°ê³¼: {len(my_papers)}ê°œ\\n\")\n",
    "\n",
    "for p in my_papers:\n",
    "    print(f\"- {p['title']}\")\n",
    "    print(f\"  ({p.get('year', 'N/A')}, ì¸ìš©: {p.get('citationCount', 0)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DIY Cell 14: Related Work ìƒì„±\nif GEMINI_API_KEY and my_papers:\n    print(\"ğŸ“ ìš”ì•½ ì¤‘...\")\n    my_summaries = [pipeline.summarize_paper(p) for p in my_papers[:5]]\n    \n    print(\"\\nâœï¸ Related Work ìƒì„± ì¤‘...\\n\")\n    my_related_work = pipeline.write_related_work(my_abstract, my_summaries)\n    \n    print(\"=\" * 60)\n    print(\"MY RELATED WORK\")\n    print(\"=\" * 60)\n    print(my_related_work)\nelse:\n    print(\"Gemini API keyê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°”ê¿”ë³´ê¸°: í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í…€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìˆ˜ì • í¬ì¸íŠ¸\n",
    "\n",
    "| í•­ëª© | ê¸°ë³¸ê°’ | ì»¤ìŠ¤í…€ ì•„ì´ë””ì–´ |\n",
    "|------|--------|----------------|\n",
    "| ìš”ì•½ ìŠ¤íƒ€ì¼ | ì¼ë°˜ ìš”ì•½ | \"ë°©ë²•ë¡  ì¤‘ì‹¬ìœ¼ë¡œ\", \"ê²°ê³¼ ì¤‘ì‹¬ìœ¼ë¡œ\" |\n",
    "| ì‘ì„± ìŠ¤íƒ€ì¼ | ì¼ë°˜ í•™ìˆ ì²´ | \"APA ìŠ¤íƒ€ì¼\", \"ë¹„íŒì  í†¤\" |\n",
    "| ì–¸ì–´ | ì˜ì–´ | í•œê¸€ |\n",
    "| ê¸¸ì´ | 2-3 ë¬¸ë‹¨ | 1 ë¬¸ë‹¨, 5 ë¬¸ë‹¨ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì˜ˆì‹œ (Before/After)\n",
    "\n",
    "# Before: ê¸°ë³¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "SUMMARY_PROMPT_BASIC = \"\"\"Summarize this paper in 1-2 sentences.\n",
    "Title: {title}\n",
    "Abstract: {abstract}\"\"\"\n",
    "\n",
    "# After: ë°©ë²•ë¡  ì¤‘ì‹¬ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "SUMMARY_PROMPT_METHOD = \"\"\"Summarize this paper's METHODOLOGY in 1-2 sentences.\n",
    "Focus on: experimental design, dataset, evaluation metrics.\n",
    "\n",
    "Title: {title}\n",
    "Abstract: {abstract}\n",
    "\n",
    "Format: \"[Author] used [method] to [goal], evaluating on [dataset].\"\"\"\n",
    "\n",
    "# After: ê²°ê³¼ ì¤‘ì‹¬ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "SUMMARY_PROMPT_RESULTS = \"\"\"Summarize this paper's KEY FINDINGS in 1-2 sentences.\n",
    "Focus on: main results, performance numbers, implications.\n",
    "\n",
    "Title: {title}\n",
    "Abstract: {abstract}\n",
    "\n",
    "Format: \"[Author] found that [finding], achieving [result].\"\"\"\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"- SUMMARY_PROMPT_BASIC: ì¼ë°˜ ìš”ì•½\")\n",
    "print(\"- SUMMARY_PROMPT_METHOD: ë°©ë²•ë¡  ì¤‘ì‹¬\")\n",
    "print(\"- SUMMARY_PROMPT_RESULTS: ê²°ê³¼ ì¤‘ì‹¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 17: ë³¸ì¸ë§Œì˜ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "\n",
    "MY_SUMMARY_PROMPT = \"\"\"\n",
    "# TODO: ë³¸ì¸ ì—°êµ¬ì— ë§ëŠ” ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "\n",
    "ì•„ì´ë””ì–´:\n",
    "- \"ì‹¬ë¦¬í•™ ê´€ì ì—ì„œ ìš”ì•½\"\n",
    "- \"ì„ìƒ ì ìš© ê°€ëŠ¥ì„± ì¤‘ì‹¬ìœ¼ë¡œ\"\n",
    "- \"í•œê³„ì  í¬í•¨í•´ì„œ ìš”ì•½\"\n",
    "\n",
    "Title: {title}\n",
    "Abstract: {abstract}\n",
    "\"\"\"\n",
    "\n",
    "MY_WRITER_PROMPT = \"\"\"\n",
    "# TODO: ë³¸ì¸ ìŠ¤íƒ€ì¼ì— ë§ëŠ” Related Work ì‘ì„± í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "ì•„ì´ë””ì–´:\n",
    "- \"APA 7th ìŠ¤íƒ€ì¼ë¡œ\"\n",
    "- \"ë¹„íŒì  í†¤ìœ¼ë¡œ (ê° ë…¼ë¬¸ì˜ í•œê³„ì  ì–¸ê¸‰)\"\n",
    "- \"í•œê¸€ë¡œ ì‘ì„±\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 18: í•œê¸€ Related Work ìƒì„± ì˜ˆì‹œ\nimport google.generativeai as genai\n\nKOREAN_WRITER_PROMPT = \"\"\"ë‹¤ìŒ ë…¼ë¬¸ ì´ˆë¡ì„ ìœ„í•œ 'ì„ í–‰ì—°êµ¬' ì„¹ì…˜ì„ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n\nì´ˆë¡:\n{abstract}\n\nê´€ë ¨ ë…¼ë¬¸ ìš”ì•½:\n{summaries}\n\nì‘ì„± ìš”êµ¬ì‚¬í•­:\n- 2-3ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±\n- ì£¼ì œë³„ë¡œ ë…¼ë¬¸ ê·¸ë£¹í™”\n- í•™ìˆ  ë…¼ë¬¸ ìŠ¤íƒ€ì¼ (ì¡´ëŒ“ë§ X)\n- ì¸ìš©ì€ (ì €ì, ì—°ë„) í˜•ì‹\n- ë§ˆì§€ë§‰ì— ë³¸ ì—°êµ¬ì™€ì˜ ì°¨ë³„ì  1-2ë¬¸ì¥ ì¶”ê°€\"\"\"\n\ndef write_korean_related_work(abstract, summaries):\n    if not GEMINI_API_KEY:\n        return \"Gemini API key í•„ìš”\"\n    \n    genai.configure(api_key=GEMINI_API_KEY)\n    model = genai.GenerativeModel('gemini-1.5-flash')\n    papers_text = \"\\n\".join([f\"- {s}\" for s in summaries])\n    \n    prompt = KOREAN_WRITER_PROMPT.format(\n        abstract=abstract, \n        summaries=papers_text\n    )\n    \n    response = model.generate_content(prompt)\n    return response.text\n\n# í…ŒìŠ¤íŠ¸\nif GEMINI_API_KEY and 'summaries' in dir():\n    korean_rw = write_korean_related_work(sample_abstract, summaries)\n    print(\"=== í•œê¸€ ì„ í–‰ì—°êµ¬ ===\")\n    print(korean_rw)\nelse:\n    print(\"ì´ì „ ì…€ì—ì„œ summariesë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 19: ìŠ¤íƒ€ì¼ ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "# ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ Related Work ìƒì„±í•´ë³´ê¸°\n",
    "styles = {\n",
    "    \"ê¸°ë³¸\": \"Write a Related Work section in academic style.\",\n",
    "    \"ë¹„íŒì \": \"Write a critical Related Work section, pointing out limitations of each work.\",\n",
    "    \"ê°„ê²°\": \"Write a concise Related Work section in exactly 3 sentences.\"\n",
    "}\n",
    "\n",
    "# TODO: ê° ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ê³  ë¹„êµí•´ë³´ì„¸ìš”\n",
    "# for style_name, style_prompt in styles.items():\n",
    "#     result = generate_with_style(abstract, summaries, style_prompt)\n",
    "#     print(f\"=== {style_name} ===\")\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: ê²°ê³¼ ë¹„êµ (ì›ë³¸ vs ì»¤ìŠ¤í…€)\n",
    "print(\"\"\"\n",
    "ğŸ“Š í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ë³„ ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "| ìŠ¤íƒ€ì¼ | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |\n",
    "|--------|------|------|----------|\n",
    "| ê¸°ë³¸ | ë¬´ë‚œí•¨ | íŠ¹ìƒ‰ ì—†ìŒ | ì´ˆì•ˆ ì‘ì„± |\n",
    "| ë°©ë²•ë¡  ì¤‘ì‹¬ | ê¸°ìˆ ì  ë””í…Œì¼ | ì´ë¡  ë¶€ì¡± | ì‹¤í—˜ ë…¼ë¬¸ |\n",
    "| ë¹„íŒì  | ì°¨ë³„ì  ëª…í™• | ë„ˆë¬´ ë¶€ì •ì  | ë¦¬ë·° ë…¼ë¬¸ |\n",
    "| í•œê¸€ | ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥ | ì¸ìš© í˜•ì‹ í™•ì¸ í•„ìš” | êµ­ë‚´ í•™íšŒ |\n",
    "\n",
    "ğŸ’¡ íŒ: ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ì˜ ê²°ê³¼ë¥¼ ì¡°í•©í•˜ë©´ ë” ì¢‹ì€ ì´ˆì•ˆì´ ë©ë‹ˆë‹¤.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í† ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í† ë¡  ì§ˆë¬¸\n",
    "\n",
    "1. **ìƒì„±ëœ Related Workì˜ í’ˆì§ˆì€ ì–´ë–¤ê°€ìš”?**\n",
    "   - ì¸ìš©ì´ ì •í™•í•œê°€?\n",
    "   - ë…¼ë¦¬ì  íë¦„ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?\n",
    "   - ì–´ë–¤ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì•¼ í• ê¹Œ?\n",
    "\n",
    "2. **ì–´ë–¤ í”„ë¡¬í”„íŠ¸ê°€ ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë‚˜ìš”?**\n",
    "   - ê¸°ë³¸ vs ë°©ë²•ë¡  ì¤‘ì‹¬ vs ë¹„íŒì \n",
    "   - ì˜ì–´ vs í•œê¸€\n",
    "\n",
    "3. **ì‹¤ì œ ë…¼ë¬¸ ì‘ì„±ì— ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆì„ê¹Œ?**\n",
    "   - ì´ˆì•ˆìœ¼ë¡œ ì‹œì‘í•´ì„œ ìˆ˜ì •?\n",
    "   - ë¹ ì§„ ë…¼ë¬¸ ì¶”ê°€ ë°©ë²•?\n",
    "   - ì¸ìš© í˜•ì‹ ìë™ ë³€í™˜?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì–´ì„œ ì‹¤ìŠµí•  ë‚´ìš©:\n",
    "- **Part 4**: AgentReviewë¡œ ì‘ì„±í•œ ë…¼ë¬¸ì— AI í”¼ë“œë°± ë°›ê¸°\n",
    "\n",
    "### ê³¼ì œ ì•„ì´ë””ì–´\n",
    "```python\n",
    "# PubMed ê²€ìƒ‰ ì¶”ê°€ (ì‹¬ë¦¬í•™ ë…¼ë¬¸ìš©)\n",
    "def retrieve_from_pubmed(abstract):\n",
    "    # E-utilities API ì‚¬ìš©\n",
    "    pass\n",
    "\n",
    "# ë©”íƒ€ë¶„ì„ìš© ìš”ì•½ í…œí”Œë¦¿\n",
    "META_ANALYSIS_PROMPT = \"\"\"\n",
    "íš¨ê³¼í¬ê¸°(d ë˜ëŠ” r), ìƒ˜í”Œ ìˆ˜, ì‹¤í—˜ ì¡°ê±´ì„ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# BibTeX ìë™ ìƒì„±\n",
    "def generate_bibtex(papers):\n",
    "    pass\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}