{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Deep Dive - Related Work ìƒì„± (LitLLM)\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. LitLLMì˜ ì½”ë“œ êµ¬ì¡°ì™€ ë°ì´í„° íë¦„ ì´í•´\n",
    "2. ë³¸ì¸ ì´ˆë¡ìœ¼ë¡œ Related Work ì´ˆì•ˆ ìƒì„±\n",
    "3. í”„ë¡¬í”„íŠ¸/ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ìœ¼ë¡œ ì¶œë ¥ í’ˆì§ˆ ê°œì„ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Google Drive Mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import os\n",
    "WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "os.chdir(WORKSHOP_DIR)\n",
    "print(f\"ì‘ì—… í´ë”: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜ + ì €ì¥ì†Œ í´ë¡ \n",
    "!pip install openai python-dotenv requests semanticscholar -q\n",
    "\n",
    "# LitLLM í´ë¡ \n",
    "!git clone https://github.com/ServiceNow/litllm.git 2>/dev/null || echo \"Already cloned\"\n",
    "\n",
    "print(\"ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: API Key ë¡œë”©\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "except:\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY or ''\n",
    "print(\"API Key ì„¤ì • ì™„ë£Œ!\" if OPENAI_API_KEY else \"API Key ì—†ìŒ - LLM ê¸°ëŠ¥ ì œí•œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: LitLLM ì½”ë“œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LitLLM êµ¬ì¡° (TMLR 2024)\n",
    "\n",
    "```\n",
    "litllm/\n",
    "â”œâ”€â”€ litllm/\n",
    "â”‚   â”œâ”€â”€ retriever.py      # ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ â­\n",
    "â”‚   â”œâ”€â”€ summarizer.py     # ë…¼ë¬¸ ìš”ì•½ â­\n",
    "â”‚   â”œâ”€â”€ writer.py         # Related Work ìƒì„± â­\n",
    "â”‚   â””â”€â”€ prompts/          # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ arxiv_cache/      # ë…¼ë¬¸ ìºì‹œ\n",
    "â””â”€â”€ generate_related_work.py\n",
    "```\n",
    "\n",
    "**í•µì‹¬ íë¦„:**\n",
    "1. ë…¼ë¬¸ ì´ˆì•ˆ ì…ë ¥ â†’ í‚¤ì›Œë“œ ì¶”ì¶œ\n",
    "2. `retriever`ê°€ Semantic Scholarì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\n",
    "3. `summarizer`ê°€ ê° ë…¼ë¬¸ ìš”ì•½\n",
    "4. `writer`ê°€ Related Work ë¬¸ë‹¨ ìƒì„± (ì¸ìš© í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: LitLLM í´ë” êµ¬ì¡° í™•ì¸\n",
    "import os\n",
    "\n",
    "litllm_path = \"litllm\"\n",
    "if os.path.exists(litllm_path):\n",
    "    print(\"ğŸ“ LitLLM êµ¬ì¡°:\")\n",
    "    for root, dirs, files in os.walk(litllm_path):\n",
    "        # ìˆ¨ê¹€ í´ë” ì œì™¸\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "        \n",
    "        level = root.replace(litllm_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:\n",
    "            if file.endswith('.py'):\n",
    "                print(f\"{subindent}{file}\")\n",
    "else:\n",
    "    print(\"LitLLMì´ í´ë¡ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cell 2ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: í•µì‹¬ ëª¨ë“ˆ ì§ì ‘ êµ¬í˜„ (LitLLM ìŠ¤íƒ€ì¼)\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "class LitLLMPipeline:\n",
    "    \"\"\"\n",
    "    LitLLM í•µì‹¬ íŒŒì´í”„ë¼ì¸ ì¬í˜„\n",
    "    retriever â†’ summarizer â†’ writer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = OpenAI() if OPENAI_API_KEY else None\n",
    "    \n",
    "    def retrieve_papers(self, abstract, num_papers=5):\n",
    "        \"\"\"Step 1: ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰ (Semantic Scholar)\"\"\"\n",
    "        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)\n",
    "        keywords = self._extract_keywords(abstract)\n",
    "        \n",
    "        # Semantic Scholar ê²€ìƒ‰\n",
    "        url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "        params = {\n",
    "            \"query\": \" \".join(keywords),\n",
    "            \"limit\": num_papers,\n",
    "            \"fields\": \"title,authors,year,abstract,citationCount\"\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        return response.json().get('data', [])\n",
    "    \n",
    "    def summarize_paper(self, paper):\n",
    "        \"\"\"Step 2: ë…¼ë¬¸ ìš”ì•½ (LLM)\"\"\"\n",
    "        if not self.client:\n",
    "            return f\"{paper['title']}: {paper.get('abstract', '')[:100]}...\"\n",
    "        \n",
    "        prompt = f\"\"\"Summarize this paper in 1-2 sentences for a Related Work section:\n",
    "\n",
    "Title: {paper['title']}\n",
    "Abstract: {paper.get('abstract', 'N/A')}\n",
    "\n",
    "Focus on the main contribution and methodology.\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def write_related_work(self, abstract, summaries):\n",
    "        \"\"\"Step 3: Related Work ìƒì„± (LLM)\"\"\"\n",
    "        if not self.client:\n",
    "            return \"LLM API key í•„ìš”\"\n",
    "        \n",
    "        papers_text = \"\\n\".join([f\"- {s}\" for s in summaries])\n",
    "        \n",
    "        prompt = f\"\"\"Write a Related Work section for a paper with this abstract:\n",
    "\n",
    "ABSTRACT:\n",
    "{abstract}\n",
    "\n",
    "RELATED PAPERS:\n",
    "{papers_text}\n",
    "\n",
    "Requirements:\n",
    "- Write 2-3 paragraphs\n",
    "- Group papers by theme\n",
    "- Use academic writing style\n",
    "- Include citations as (Author et al., Year)\"\"\"\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.5\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def _extract_keywords(self, text):\n",
    "        \"\"\"ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ\"\"\"\n",
    "        # ë¶ˆìš©ì–´ ì œê±° í›„ ë¹ˆë„ìˆœ ì •ë ¬ (ê°„ë‹¨ ë²„ì „)\n",
    "        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', \n",
    "                     'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
    "                     'would', 'could', 'should', 'may', 'might', 'must', 'shall',\n",
    "                     'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',\n",
    "                     'as', 'into', 'through', 'during', 'before', 'after', 'and',\n",
    "                     'but', 'or', 'nor', 'so', 'yet', 'both', 'either', 'neither',\n",
    "                     'not', 'only', 'own', 'same', 'than', 'too', 'very', 'just',\n",
    "                     'this', 'that', 'these', 'those', 'we', 'our', 'they', 'their'}\n",
    "        \n",
    "        words = text.lower().split()\n",
    "        keywords = [w for w in words if w.isalpha() and w not in stopwords and len(w) > 3]\n",
    "        \n",
    "        # ë¹ˆë„ ê³„ì‚°\n",
    "        from collections import Counter\n",
    "        freq = Counter(keywords)\n",
    "        return [w for w, _ in freq.most_common(5)]\n",
    "\n",
    "print(\"LitLLMPipeline í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"ë©”ì„œë“œ: retrieve_papers(), summarize_paper(), write_related_work()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì§ˆë¬¸\n",
    "\n",
    "LitLLMì˜ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì„ ë³´ê³  ìƒê°í•´ë³´ì„¸ìš”:\n",
    "- ì–´ë–¤ ë‹¨ê³„ì—ì„œ í’ˆì§ˆ ì†ì‹¤ì´ ê°€ì¥ í´ê¹Œ?\n",
    "- ì–´ë–¤ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ë©´ ê²°ê³¼ê°€ ì¢‹ì•„ì§ˆê¹Œ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ì¨ë³´ê¸°: Related Work ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìƒ˜í”Œ ë°ì´í„°\n",
    "\n",
    "í…ŒìŠ¤íŠ¸í•  ë…¼ë¬¸ ì´ˆë¡ (AI ì‹¬ë¦¬í•™ ê´€ë ¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ìƒ˜í”Œ ì‹¤í–‰ (ë°œí‘œì ë°ëª¨)\n",
    "sample_abstract = \"\"\"\n",
    "Large language models (LLMs) have shown remarkable capabilities in various \n",
    "cognitive tasks. This paper investigates whether LLMs exhibit human-like \n",
    "cognitive biases, specifically focusing on anchoring effects and confirmation \n",
    "bias. We design a series of experiments adapted from classical psychology \n",
    "studies and evaluate GPT-4 and Claude on these tasks. Our results show that \n",
    "LLMs do exhibit similar biases to humans, but with different magnitudes. \n",
    "This has implications for using LLMs as cognitive models and for AI safety.\n",
    "\"\"\"\n",
    "\n",
    "pipeline = LitLLMPipeline()\n",
    "\n",
    "# Step 1: ë…¼ë¬¸ ê²€ìƒ‰\n",
    "print(\"ğŸ” Step 1: ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰...\")\n",
    "papers = pipeline.retrieve_papers(sample_abstract, num_papers=5)\n",
    "print(f\"   {len(papers)}ê°œ ë…¼ë¬¸ ë°œê²¬\\n\")\n",
    "\n",
    "for p in papers[:3]:\n",
    "    print(f\"   - {p['title'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: ìš”ì•½ + Related Work ìƒì„±\n",
    "if OPENAI_API_KEY and papers:\n",
    "    # Step 2: ê° ë…¼ë¬¸ ìš”ì•½\n",
    "    print(\"ğŸ“ Step 2: ë…¼ë¬¸ ìš”ì•½...\")\n",
    "    summaries = []\n",
    "    for paper in papers[:5]:\n",
    "        summary = pipeline.summarize_paper(paper)\n",
    "        summaries.append(summary)\n",
    "        print(f\"   âœ“ {paper['title'][:40]}...\")\n",
    "    \n",
    "    # Step 3: Related Work ìƒì„±\n",
    "    print(\"\\nâœï¸ Step 3: Related Work ìƒì„±...\\n\")\n",
    "    related_work = pipeline.write_related_work(sample_abstract, summaries)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"RELATED WORK\")\n",
    "    print(\"=\" * 60)\n",
    "    print(related_work)\n",
    "else:\n",
    "    print(\"API key ì—†ìŒ - ìš”ì•½/ìƒì„± ë‹¨ê³„ ê±´ë„ˆëœ€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: ë³¸ì¸ ì´ˆë¡ìœ¼ë¡œ Related Work ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 13: ë³¸ì¸ ì´ˆë¡ ì…ë ¥\n",
    "# íŒíŠ¸: my_abstract ë³€ìˆ˜ì— ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”\n",
    "\n",
    "my_abstract = \"\"\"\n",
    "ì—¬ê¸°ì— ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\n",
    "ë˜ëŠ” ì—°êµ¬ ì•„ì´ë””ì–´ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print(\"ğŸ” ë…¼ë¬¸ ê²€ìƒ‰ ì¤‘...\")\n",
    "my_papers = pipeline.retrieve_papers(my_abstract, num_papers=5)\n",
    "print(f\"ê²€ìƒ‰ ê²°ê³¼: {len(my_papers)}ê°œ\\n\")\n",
    "\n",
    "for p in my_papers:\n",
    "    print(f\"- {p['title']}\")\n",
    "    print(f\"  ({p.get('year', 'N/A')}, ì¸ìš©: {p.get('citationCount', 0)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 14: Related Work ìƒì„±\n",
    "if OPENAI_API_KEY and my_papers:\n",
    "    print(\"ğŸ“ ìš”ì•½ ì¤‘...\")\n",
    "    my_summaries = [pipeline.summarize_paper(p) for p in my_papers[:5]]\n",
    "    \n",
    "    print(\"\\nâœï¸ Related Work ìƒì„± ì¤‘...\\n\")\n",
    "    my_related_work = pipeline.write_related_work(my_abstract, my_summaries)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"MY RELATED WORK\")\n",
    "    print(\"=\" * 60)\n",
    "    print(my_related_work)\n",
    "else:\n",
    "    print(\"API keyê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°”ê¿”ë³´ê¸°: í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í…€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìˆ˜ì • í¬ì¸íŠ¸\n",
    "\n",
    "| í•­ëª© | ê¸°ë³¸ê°’ | ì»¤ìŠ¤í…€ ì•„ì´ë””ì–´ |\n",
    "|------|--------|----------------|\n",
    "| ìš”ì•½ ìŠ¤íƒ€ì¼ | ì¼ë°˜ ìš”ì•½ | \"ë°©ë²•ë¡  ì¤‘ì‹¬ìœ¼ë¡œ\", \"ê²°ê³¼ ì¤‘ì‹¬ìœ¼ë¡œ\" |\n",
    "| ì‘ì„± ìŠ¤íƒ€ì¼ | ì¼ë°˜ í•™ìˆ ì²´ | \"APA ìŠ¤íƒ€ì¼\", \"ë¹„íŒì  í†¤\" |\n",
    "| ì–¸ì–´ | ì˜ì–´ | í•œê¸€ |\n",
    "| ê¸¸ì´ | 2-3 ë¬¸ë‹¨ | 1 ë¬¸ë‹¨, 5 ë¬¸ë‹¨ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ì˜ˆì‹œ (Before/After)\n",
    "\n",
    "# Before: ê¸°ë³¸ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "SUMMARY_PROMPT_BASIC = \"\"\"Summarize this paper in 1-2 sentences.\n",
    "Title: {title}\n",
    "Abstract: {abstract}\"\"\"\n",
    "\n",
    "# After: ë°©ë²•ë¡  ì¤‘ì‹¬ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "SUMMARY_PROMPT_METHOD = \"\"\"Summarize this paper's METHODOLOGY in 1-2 sentences.\n",
    "Focus on: experimental design, dataset, evaluation metrics.\n",
    "\n",
    "Title: {title}\n",
    "Abstract: {abstract}\n",
    "\n",
    "Format: \"[Author] used [method] to [goal], evaluating on [dataset].\"\"\"\n",
    "\n",
    "# After: ê²°ê³¼ ì¤‘ì‹¬ ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "SUMMARY_PROMPT_RESULTS = \"\"\"Summarize this paper's KEY FINDINGS in 1-2 sentences.\n",
    "Focus on: main results, performance numbers, implications.\n",
    "\n",
    "Title: {title}\n",
    "Abstract: {abstract}\n",
    "\n",
    "Format: \"[Author] found that [finding], achieving [result].\"\"\"\n",
    "\n",
    "print(\"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"- SUMMARY_PROMPT_BASIC: ì¼ë°˜ ìš”ì•½\")\n",
    "print(\"- SUMMARY_PROMPT_METHOD: ë°©ë²•ë¡  ì¤‘ì‹¬\")\n",
    "print(\"- SUMMARY_PROMPT_RESULTS: ê²°ê³¼ ì¤‘ì‹¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 17: ë³¸ì¸ë§Œì˜ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "\n",
    "MY_SUMMARY_PROMPT = \"\"\"\n",
    "# TODO: ë³¸ì¸ ì—°êµ¬ì— ë§ëŠ” ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "\n",
    "ì•„ì´ë””ì–´:\n",
    "- \"ì‹¬ë¦¬í•™ ê´€ì ì—ì„œ ìš”ì•½\"\n",
    "- \"ì„ìƒ ì ìš© ê°€ëŠ¥ì„± ì¤‘ì‹¬ìœ¼ë¡œ\"\n",
    "- \"í•œê³„ì  í¬í•¨í•´ì„œ ìš”ì•½\"\n",
    "\n",
    "Title: {title}\n",
    "Abstract: {abstract}\n",
    "\"\"\"\n",
    "\n",
    "MY_WRITER_PROMPT = \"\"\"\n",
    "# TODO: ë³¸ì¸ ìŠ¤íƒ€ì¼ì— ë§ëŠ” Related Work ì‘ì„± í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "ì•„ì´ë””ì–´:\n",
    "- \"APA 7th ìŠ¤íƒ€ì¼ë¡œ\"\n",
    "- \"ë¹„íŒì  í†¤ìœ¼ë¡œ (ê° ë…¼ë¬¸ì˜ í•œê³„ì  ì–¸ê¸‰)\"\n",
    "- \"í•œê¸€ë¡œ ì‘ì„±\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: í•œê¸€ Related Work ìƒì„± ì˜ˆì‹œ\n",
    "\n",
    "KOREAN_WRITER_PROMPT = \"\"\"ë‹¤ìŒ ë…¼ë¬¸ ì´ˆë¡ì„ ìœ„í•œ 'ì„ í–‰ì—°êµ¬' ì„¹ì…˜ì„ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì´ˆë¡:\n",
    "{abstract}\n",
    "\n",
    "ê´€ë ¨ ë…¼ë¬¸ ìš”ì•½:\n",
    "{summaries}\n",
    "\n",
    "ì‘ì„± ìš”êµ¬ì‚¬í•­:\n",
    "- 2-3ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±\n",
    "- ì£¼ì œë³„ë¡œ ë…¼ë¬¸ ê·¸ë£¹í™”\n",
    "- í•™ìˆ  ë…¼ë¬¸ ìŠ¤íƒ€ì¼ (ì¡´ëŒ“ë§ X)\n",
    "- ì¸ìš©ì€ (ì €ì, ì—°ë„) í˜•ì‹\n",
    "- ë§ˆì§€ë§‰ì— ë³¸ ì—°êµ¬ì™€ì˜ ì°¨ë³„ì  1-2ë¬¸ì¥ ì¶”ê°€\"\"\"\n",
    "\n",
    "def write_korean_related_work(abstract, summaries):\n",
    "    if not OPENAI_API_KEY:\n",
    "        return \"API key í•„ìš”\"\n",
    "    \n",
    "    client = OpenAI()\n",
    "    papers_text = \"\\n\".join([f\"- {s}\" for s in summaries])\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \n",
    "            \"content\": KOREAN_WRITER_PROMPT.format(\n",
    "                abstract=abstract, \n",
    "                summaries=papers_text\n",
    "            )\n",
    "        }],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "if OPENAI_API_KEY and 'summaries' in dir():\n",
    "    korean_rw = write_korean_related_work(sample_abstract, summaries)\n",
    "    print(\"=== í•œê¸€ ì„ í–‰ì—°êµ¬ ===\")\n",
    "    print(korean_rw)\n",
    "else:\n",
    "    print(\"ì´ì „ ì…€ì—ì„œ summariesë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 19: ìŠ¤íƒ€ì¼ ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "# ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ Related Work ìƒì„±í•´ë³´ê¸°\n",
    "styles = {\n",
    "    \"ê¸°ë³¸\": \"Write a Related Work section in academic style.\",\n",
    "    \"ë¹„íŒì \": \"Write a critical Related Work section, pointing out limitations of each work.\",\n",
    "    \"ê°„ê²°\": \"Write a concise Related Work section in exactly 3 sentences.\"\n",
    "}\n",
    "\n",
    "# TODO: ê° ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ê³  ë¹„êµí•´ë³´ì„¸ìš”\n",
    "# for style_name, style_prompt in styles.items():\n",
    "#     result = generate_with_style(abstract, summaries, style_prompt)\n",
    "#     print(f\"=== {style_name} ===\")\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: ê²°ê³¼ ë¹„êµ (ì›ë³¸ vs ì»¤ìŠ¤í…€)\n",
    "print(\"\"\"\n",
    "ğŸ“Š í”„ë¡¬í”„íŠ¸ ìŠ¤íƒ€ì¼ë³„ ê²°ê³¼ ë¹„êµ\n",
    "\n",
    "| ìŠ¤íƒ€ì¼ | ì¥ì  | ë‹¨ì  | ì¶”ì²œ ìš©ë„ |\n",
    "|--------|------|------|----------|\n",
    "| ê¸°ë³¸ | ë¬´ë‚œí•¨ | íŠ¹ìƒ‰ ì—†ìŒ | ì´ˆì•ˆ ì‘ì„± |\n",
    "| ë°©ë²•ë¡  ì¤‘ì‹¬ | ê¸°ìˆ ì  ë””í…Œì¼ | ì´ë¡  ë¶€ì¡± | ì‹¤í—˜ ë…¼ë¬¸ |\n",
    "| ë¹„íŒì  | ì°¨ë³„ì  ëª…í™• | ë„ˆë¬´ ë¶€ì •ì  | ë¦¬ë·° ë…¼ë¬¸ |\n",
    "| í•œê¸€ | ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥ | ì¸ìš© í˜•ì‹ í™•ì¸ í•„ìš” | êµ­ë‚´ í•™íšŒ |\n",
    "\n",
    "ğŸ’¡ íŒ: ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ì˜ ê²°ê³¼ë¥¼ ì¡°í•©í•˜ë©´ ë” ì¢‹ì€ ì´ˆì•ˆì´ ë©ë‹ˆë‹¤.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í† ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í† ë¡  ì§ˆë¬¸\n",
    "\n",
    "1. **ìƒì„±ëœ Related Workì˜ í’ˆì§ˆì€ ì–´ë–¤ê°€ìš”?**\n",
    "   - ì¸ìš©ì´ ì •í™•í•œê°€?\n",
    "   - ë…¼ë¦¬ì  íë¦„ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?\n",
    "   - ì–´ë–¤ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì•¼ í• ê¹Œ?\n",
    "\n",
    "2. **ì–´ë–¤ í”„ë¡¬í”„íŠ¸ê°€ ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë‚˜ìš”?**\n",
    "   - ê¸°ë³¸ vs ë°©ë²•ë¡  ì¤‘ì‹¬ vs ë¹„íŒì \n",
    "   - ì˜ì–´ vs í•œê¸€\n",
    "\n",
    "3. **ì‹¤ì œ ë…¼ë¬¸ ì‘ì„±ì— ì–´ë–»ê²Œ í™œìš©í•  ìˆ˜ ìˆì„ê¹Œ?**\n",
    "   - ì´ˆì•ˆìœ¼ë¡œ ì‹œì‘í•´ì„œ ìˆ˜ì •?\n",
    "   - ë¹ ì§„ ë…¼ë¬¸ ì¶”ê°€ ë°©ë²•?\n",
    "   - ì¸ìš© í˜•ì‹ ìë™ ë³€í™˜?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì–´ì„œ ì‹¤ìŠµí•  ë‚´ìš©:\n",
    "- **Part 4**: AgentReviewë¡œ ì‘ì„±í•œ ë…¼ë¬¸ì— AI í”¼ë“œë°± ë°›ê¸°\n",
    "\n",
    "### ê³¼ì œ ì•„ì´ë””ì–´\n",
    "```python\n",
    "# PubMed ê²€ìƒ‰ ì¶”ê°€ (ì‹¬ë¦¬í•™ ë…¼ë¬¸ìš©)\n",
    "def retrieve_from_pubmed(abstract):\n",
    "    # E-utilities API ì‚¬ìš©\n",
    "    pass\n",
    "\n",
    "# ë©”íƒ€ë¶„ì„ìš© ìš”ì•½ í…œí”Œë¦¿\n",
    "META_ANALYSIS_PROMPT = \"\"\"\n",
    "íš¨ê³¼í¬ê¸°(d ë˜ëŠ” r), ìƒ˜í”Œ ìˆ˜, ì‹¤í—˜ ì¡°ê±´ì„ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# BibTeX ìë™ ìƒì„±\n",
    "def generate_bibtex(papers):\n",
    "    pass\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
