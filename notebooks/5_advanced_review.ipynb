{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Advanced - Few-Shot Learningìœ¼ë¡œ Review í’ˆì§ˆ í–¥ìƒ\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. PeerRead ë°ì´í„°ì…‹ í™œìš©ë²• ì´í•´\n",
    "2. Few-shot learningìœ¼ë¡œ ë¦¬ë·° í’ˆì§ˆ ê°œì„ \n",
    "3. ê¸°ë³¸ AgentReview vs Few-shot enhanced ë¹„êµ\n",
    "\n",
    "âš ï¸ **ì„ íƒ ë…¸íŠ¸ë¶**: Part 4 ì™„ë£Œ í›„ ì‹œê°„ì´ ìˆì„ ë•Œ ì‹¤ìŠµí•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: í™˜ê²½ ì„¤ì • (Colab/ë¡œì»¬ ìë™ ê°ì§€)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Colab í™˜ê²½ ê°ì§€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "    os.chdir(WORKSHOP_DIR)\n",
    "    IN_COLAB = True\n",
    "    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "except ImportError:\n",
    "    # ë¡œì»¬ í™˜ê²½\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n",
    "\n",
    "print(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# Colab: ìë™ ì„¤ì¹˜\n",
    "# ë¡œì»¬: requirements.txtë¡œ ë¯¸ë¦¬ ì„¤ì¹˜ í•„ìš” (pip install -e .)\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
    "    !pip install datasets google-generativeai python-dotenv -q\n",
    "    print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"âœ… ë¡œì»¬ í™˜ê²½: pyproject.tomlë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©\")\n",
    "    print(\"   (ë¯¸ì„¤ì¹˜ ì‹œ: uv pip install -e . ë˜ëŠ” pip install -e .)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: API Key ë¡œë”©\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab í™˜ê²½ ì²´í¬\n",
    "if IN_COLAB:\n",
    "    # Colab userdataì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "        print(\"âœ… Colab Secretsì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Colab Secretsì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n",
    "        print(\"   ì¢Œì¸¡ ğŸ”‘ ì•„ì´ì½˜ > Add new secret\")\n",
    "        GEMINI_API_KEY = None\n",
    "else:\n",
    "    # ë¡œì»¬ í™˜ê²½: dotenv ì‚¬ìš©\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "        \n",
    "        if GEMINI_API_KEY:\n",
    "            print(\"âœ… .env íŒŒì¼ì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n",
    "        else:\n",
    "            print(\"âš ï¸ .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n",
    "        GEMINI_API_KEY = None\n",
    "\n",
    "# API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "if GEMINI_API_KEY:\n",
    "    print(f\"ğŸ”‘ API Key: {GEMINI_API_KEY[:10]}...\")\n",
    "else:\n",
    "    print(\"âŒ API Keyë¥¼ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ LLM ê¸°ëŠ¥ì´ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: PeerRead ë°ì´í„°ì…‹ì´ë€?\n",
    "\n",
    "### ë°ì´í„°ì…‹ ê°œìš”\n",
    "\n",
    "**PeerRead**ëŠ” ìµœì´ˆì˜ ê³µê°œ peer review ë°ì´í„°ì…‹ì…ë‹ˆë‹¤ (NAACL 2018).\n",
    "\n",
    "| í•­ëª© | ë‚´ìš© |\n",
    "|------|------|\n",
    "| **ê·œëª¨** | 14K+ ë…¼ë¬¸, 10K+ expert reviews |\n",
    "| **ì¶œì²˜** | ACL, NeurIPS, ICLR (top-tier venues) |\n",
    "| **í¬í•¨ ì •ë³´** | ë…¼ë¬¸ ì´ˆì•ˆ, ë¦¬ë·° ì½”ë©˜íŠ¸, accept/reject ê²°ì • |\n",
    "| **ì ‘ê·¼ì„±** | Hugging Faceì—ì„œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥ |\n",
    "\n",
    "### Why PeerRead?\n",
    "\n",
    "Review-CoT ë°ì´í„°ì…‹(142k reviews)ì€ ê³µê°œë˜ì§€ ì•Šì•˜ì§€ë§Œ, PeerReadëŠ”:\n",
    "- âœ… Hugging Faceì—ì„œ 3ì¤„ ì½”ë“œë¡œ ë¡œë”©\n",
    "- âœ… ì‹¤ì œ top-tier conference reviews\n",
    "- âœ… Accept/reject decisions í¬í•¨\n",
    "- âœ… Few-shot learningì— ì¶©ë¶„í•œ í’ˆì§ˆ\n",
    "\n",
    "**GitHub**: [allenai/PeerRead](https://github.com/allenai/PeerRead)  \n",
    "**Paper**: [arXiv:1804.09635](https://arxiv.org/abs/1804.09635)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ì¨ë³´ê¸°: PeerRead ë°ì´í„°ì…‹ ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: ë°ì´í„°ì…‹ ë¡œë”©\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"ğŸ“¦ PeerRead ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...\")\n",
    "print(\"   (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œì— 1-2ë¶„ ì†Œìš”ë©ë‹ˆë‹¤)\\n\")\n",
    "\n",
    "# PeerRead ì „ì²´ ë°ì´í„°ì…‹ ë¡œë”©\n",
    "peerread = load_dataset(\"allenai/peer_read\", \"full\", split=\"train\")\n",
    "\n",
    "print(f\"âœ… ë¡œë”© ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“Š ì´ {len(peerread)}ê°œ ë¦¬ë·°\")\n",
    "print(f\"\\në°ì´í„°ì…‹ ì»¬ëŸ¼: {peerread.column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ë°ì´í„°ì…‹ íƒìƒ‰\n",
    "import pandas as pd\n",
    "\n",
    "# Accept/Reject ë¶„í¬\n",
    "decisions = pd.Series([r['RECOMMENDATION'] for r in peerread if 'RECOMMENDATION' in r])\n",
    "print(\"ğŸ“Š Accept/Reject ë¶„í¬:\")\n",
    "print(decisions.value_counts())\n",
    "print()\n",
    "\n",
    "# ë¦¬ë·° ê¸¸ì´ ë¶„í¬\n",
    "review_lengths = [len(r.get('COMMENTS', '')) for r in peerread]\n",
    "print(f\"ğŸ“ ë¦¬ë·° ê¸¸ì´ í†µê³„:\")\n",
    "print(f\"   í‰ê· : {pd.Series(review_lengths).mean():.0f} ê¸€ì\")\n",
    "print(f\"   ì¤‘ì•™ê°’: {pd.Series(review_lengths).median():.0f} ê¸€ì\")\n",
    "print(f\"   ìµœëŒ€: {max(review_lengths)} ê¸€ì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ìƒ˜í”Œ ë¦¬ë·° í™•ì¸\n",
    "# Acceptëœ ë…¼ë¬¸ ì¤‘ ì²« ë²ˆì§¸ ë¦¬ë·° í™•ì¸\n",
    "\n",
    "sample = None\n",
    "for review in peerread:\n",
    "    if review.get('RECOMMENDATION') == 'accept' and review.get('COMMENTS'):\n",
    "        sample = review\n",
    "        break\n",
    "\n",
    "if sample:\n",
    "    print(\"ğŸ“„ ìƒ˜í”Œ ë¦¬ë·° (Accept)\\n\")\n",
    "    print(f\"ë…¼ë¬¸ ì œëª©: {sample.get('TITLE', 'N/A')}\")\n",
    "    print(f\"ê²°ì •: {sample.get('RECOMMENDATION', 'N/A')}\")\n",
    "    print(f\"\\në¦¬ë·° ì½”ë©˜íŠ¸ (ì²˜ìŒ 500ì):\\n\")\n",
    "    print(sample.get('COMMENTS', 'N/A')[:500])\n",
    "    print(\"\\n...\")\n",
    "else:\n",
    "    print(\"âš ï¸ Accept ë¦¬ë·° ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°”ê¿”ë³´ê¸°: Few-Shot Learning êµ¬í˜„\n",
    "\n",
    "### Few-Shot Learningì´ë€?\n",
    "\n",
    "LLMì—ê²Œ **ëª‡ ê°œì˜ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤€ í›„** ê°™ì€ ìŠ¤íƒ€ì¼ë¡œ ìƒì„±í•˜ë„ë¡ í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "í”„ë¡¬í”„íŠ¸:\n",
    "\"ë‹¤ìŒì€ ê³ í’ˆì§ˆ ë¦¬ë·°ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
    "\n",
    "Example 1: [acceptëœ ë…¼ë¬¸ì˜ ë¦¬ë·° 1]\n",
    "Example 2: [acceptëœ ë…¼ë¬¸ì˜ ë¦¬ë·° 2]\n",
    "...\n",
    "\n",
    "ì´ì œ ì´ ë…¼ë¬¸ì„ ê°™ì€ ìŠ¤íƒ€ì¼ë¡œ ë¦¬ë·°í•˜ì„¸ìš”:\n",
    "[ë³¸ì¸ ë…¼ë¬¸]\n",
    "\"\n",
    "```\n",
    "\n",
    "### íš¨ê³¼\n",
    "- âœ… ë¦¬ë·° í˜•ì‹ê³¼ í†¤ì„ í•™ìŠµ\n",
    "- âœ… êµ¬ì²´ì ì¸ í”¼ë“œë°± ì¦ê°€\n",
    "- âœ… Top-tier conference ìˆ˜ì¤€ì˜ ê¹Šì´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: ê³ í’ˆì§ˆ ë¦¬ë·° ëª©ë¡ í‘œì‹œ\n\n# Acceptëœ ê³ í’ˆì§ˆ ë¦¬ë·° í•„í„°ë§ (ìµœì†Œ ê¸¸ì´ 500ì)\nhigh_quality_candidates = [\n    (i, r) for i, r in enumerate(peerread)\n    if r.get('RECOMMENDATION') == 'accept'\n    and len(r.get('COMMENTS', '')) >= 500\n]\n\nprint(f\"âœ… Acceptëœ ê³ í’ˆì§ˆ ë¦¬ë·°: {len(high_quality_candidates)}ê°œ\\n\")\nprint(\"ğŸ“‹ ë¦¬ë·° ëª©ë¡ (ì²˜ìŒ 20ê°œ):\")\nprint(\"=\" * 80)\n\nfor idx, (original_idx, review) in enumerate(high_quality_candidates[:20]):\n    title = review.get('TITLE', 'N/A')[:60]\n    length = len(review['COMMENTS'])\n    print(f\"[{idx:2d}] {title}... ({length:,}ì)\")\n\nprint(\"\\nğŸ’¡ ë³¸ì¸ ì—°êµ¬ ë¶„ì•¼ì™€ ìœ ì‚¬í•œ ë¦¬ë·°ë¥¼ 5ê°œ ê³¨ë¼ì£¼ì„¸ìš”!\")\nprint(\"   (ë‹¤ìŒ ì…€ì—ì„œ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¡œ ì„ íƒ)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DIY Cell 8: ì›í•˜ëŠ” ë¦¬ë·° ì„ íƒí•˜ê¸°\n\n# ìœ„ì˜ ëª©ë¡ì—ì„œ ë³¸ì¸ ë¶„ì•¼ì™€ ìœ ì‚¬í•œ ë¦¬ë·°ì˜ ì¸ë±ìŠ¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\nselected_indices = [0, 3, 7, 12, 15]  # <- ì´ ìˆ«ìë“¤ì„ ìˆ˜ì •í•˜ì„¸ìš”!\n\n# ì„ íƒëœ ë¦¬ë·° ì¶”ì¶œ\nfew_shot_examples = [high_quality_candidates[i][1] for i in selected_indices if i < len(high_quality_candidates)]\n\nprint(f\"âœ… {len(few_shot_examples)}ê°œ ë¦¬ë·° ì„ íƒ ì™„ë£Œ\\n\")\nprint(\"ì„ íƒëœ ë¦¬ë·°:\")\nfor i, ex in enumerate(few_shot_examples, 1):\n    print(f\"{i}. {ex.get('TITLE', 'N/A')[:60]}... (ê¸¸ì´: {len(ex['COMMENTS'])} ê¸€ì)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: Few-Shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n\ndef build_few_shot_prompt(examples, paper_abstract):\n    \"\"\"Few-shot learningì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n    \n    # Examples ì„¹ì…˜\n    examples_text = \"Here are examples of high-quality peer reviews from top-tier conferences (ACL, NeurIPS, ICLR):\\n\\n\"\n    \n    for i, ex in enumerate(examples, 1):\n        review = ex['COMMENTS'][:800]  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°\n        examples_text += f\"=== Example {i} ===\\n{review}\\n\\n\"\n    \n    # Task ì„¹ì…˜\n    task_text = f\"\"\"Now, write a peer review for the following paper in the same style and depth:\n\nPaper Abstract:\n{paper_abstract}\n\nProvide a thorough review covering:\n1. Summary of the paper's main contributions\n2. Strengths\n3. Weaknesses\n4. Questions for the authors\n5. Overall recommendation\n\"\"\"\n    \n    return examples_text + task_text\n\n# í…ŒìŠ¤íŠ¸ìš© ë…¼ë¬¸ ì´ˆë¡\ntest_abstract = \"\"\"\nWe propose a novel approach to depression detection using multimodal analysis of \nclinical interviews. Our method combines audio features (prosody, speech rate) with \ntext embeddings from transformer models to predict PHQ-8 scores. Experiments on the \nDAIC-WOZ dataset show 15% improvement over text-only baselines.\n\"\"\"\n\n# ì„ íƒëœ ë¦¬ë·°ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±\nfew_shot_prompt = build_few_shot_prompt(few_shot_examples, test_abstract)\n\nprint(\"âœ… Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ\")\nprint(f\"   ì´ ê¸¸ì´: {len(few_shot_prompt)} ê¸€ì\")\nprint(\"\\ní”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):\")\nprint(few_shot_prompt[:500])\nprint(\"\\n...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Cell 10: LLMìœ¼ë¡œ Few-Shot Review ìƒì„±\nimport google.generativeai as genai\n\nif not GEMINI_API_KEY:\n    print(\"âŒ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cell 3ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\nelse:\n    genai.configure(api_key=GEMINI_API_KEY)\n    model = genai.GenerativeModel('gemini-pro')\n    \n    print(\"ğŸ¤– Few-shot learningìœ¼ë¡œ ë¦¬ë·° ìƒì„± ì¤‘...\\n\")\n    \n    response = model.generate_content(few_shot_prompt)\n    few_shot_review = response.text\n    \n    print(\"=== Few-Shot Enhanced Review ===\\n\")\n    print(few_shot_review)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¦¬ë·° ìƒì„± (ë¹„êµìš©)\n",
    "\n",
    "basic_prompt = f\"\"\"You are a peer reviewer for a top-tier conference. \n",
    "Write a review for the following paper:\n",
    "\n",
    "{test_abstract}\n",
    "\n",
    "Provide:\n",
    "1. Summary\n",
    "2. Strengths\n",
    "3. Weaknesses\n",
    "4. Questions\n",
    "5. Recommendation\n",
    "\"\"\"\n",
    "\n",
    "if GEMINI_API_KEY:\n",
    "    print(\"ğŸ¤– ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¦¬ë·° ìƒì„± ì¤‘...\\n\")\n",
    "    \n",
    "    response_basic = model.generate_content(basic_prompt)\n",
    "    basic_review = response_basic.text\n",
    "    \n",
    "    print(\"=== Basic Review (Without Few-Shot) ===\\n\")\n",
    "    print(basic_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¦¬ë·° ìƒì„± (ë¹„êµìš©)\n\nbasic_prompt = f\"\"\"You are a peer reviewer for a top-tier conference. \nWrite a review for the following paper:\n\n{test_abstract}\n\nProvide:\n1. Summary\n2. Strengths\n3. Weaknesses\n4. Questions\n5. Recommendation\n\"\"\"\n\nif GEMINI_API_KEY:\n    print(\"ğŸ¤– ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ë¦¬ë·° ìƒì„± ì¤‘...\\n\")\n    \n    response_basic = model.generate_content(basic_prompt)\n    basic_review = response_basic.text\n    \n    print(\"=== Basic Review (Without Few-Shot) ===\\n\")\n    print(basic_review)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Cell 12: ì°¨ì´ì  ë¶„ì„\n\nprint(\"ğŸ“Š ê¸°ë³¸ vs Few-Shot ë¹„êµ\\n\")\n\nif GEMINI_API_KEY:\n    print(f\"ê¸°ë³¸ ë¦¬ë·° ê¸¸ì´: {len(basic_review)} ê¸€ì\")\n    print(f\"Few-shot ë¦¬ë·° ê¸¸ì´: {len(few_shot_review)} ê¸€ì\")\n    print()\n    \n    # êµ¬ì¡°í™” ì •ë„ (ì§ˆë¬¸ ê°œìˆ˜ë¡œ ê°„ë‹¨íˆ ì¸¡ì •)\n    basic_questions = basic_review.count('?')\n    fewshot_questions = few_shot_review.count('?')\n    \n    print(f\"ì§ˆë¬¸ ê°œìˆ˜ (êµ¬ì²´ì„±):\")\n    print(f\"  - ê¸°ë³¸: {basic_questions}ê°œ\")\n    print(f\"  - Few-shot: {fewshot_questions}ê°œ\")\n    print()\n    \n    print(\"ğŸ’¡ ê´€ì°° í¬ì¸íŠ¸:\")\n    print(\"  - Few-shot ë¦¬ë·°ê°€ ë” êµ¬ì²´ì ì¸ê°€?\")\n    print(\"  - PeerRead ì˜ˆì‹œì˜ í†¤ê³¼ í˜•ì‹ì„ ë”°ë¥´ëŠ”ê°€?\")\n    print(\"  - ê¸°ìˆ ì  ê¹Šì´ê°€ ë” ìˆëŠ”ê°€?\")\nelse:\n    print(\"âš ï¸ API Key ì—†ì´ëŠ” ë¹„êµ ë¶ˆê°€\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 12: ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ ì…ë ¥\n",
    "\n",
    "my_paper_abstract = \"\"\"\n",
    "[ì—¬ê¸°ì— ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ì„ ì…ë ¥í•˜ì„¸ìš”]\n",
    "\n",
    "ì˜ˆ:\n",
    "This study investigates...\n",
    "\"\"\"\n",
    "\n",
    "# Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "my_few_shot_prompt = build_few_shot_prompt(few_shot_examples, my_paper_abstract)\n",
    "\n",
    "print(f\"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(my_few_shot_prompt)} ê¸€ì)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# DIY Cell 13: ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ ì…ë ¥\n\nmy_paper_abstract = \"\"\"\n[ì—¬ê¸°ì— ë³¸ì¸ ë…¼ë¬¸ ì´ˆë¡ì„ ì…ë ¥í•˜ì„¸ìš”]\n\nì˜ˆ:\nThis study investigates...\n\"\"\"\n\n# Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„± (Cell 8ì—ì„œ ì„ íƒí•œ ë¦¬ë·° ì‚¬ìš©)\nmy_few_shot_prompt = build_few_shot_prompt(few_shot_examples, my_paper_abstract)\n\nprint(f\"âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(my_few_shot_prompt)} ê¸€ì)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DIY Cell 14: ë³¸ì¸ ë…¼ë¬¸ ë¦¬ë·° ìƒì„±\n\nif not GEMINI_API_KEY:\n    print(\"âŒ API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤\")\nelif \"[ì—¬ê¸°ì—\" in my_paper_abstract:\n    print(\"âš ï¸ ìœ„ ì…€ì—ì„œ ë³¸ì¸ì˜ ë…¼ë¬¸ ì´ˆë¡ì„ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”\")\nelse:\n    print(\"ğŸ¤– ë³¸ì¸ ë…¼ë¬¸ ë¦¬ë·° ìƒì„± ì¤‘...\\n\")\n    \n    response_my = model.generate_content(my_few_shot_prompt)\n    my_review = response_my.text\n    \n    print(\"=== Your Paper Review (Few-Shot Enhanced) ===\\n\")\n    print(my_review)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: ë¶„ì•¼ë³„ í•„í„°ë§\n",
    "\n",
    "def filter_by_field(dataset, keywords):\n",
    "    \"\"\"íŠ¹ì • ë¶„ì•¼ì˜ ë¦¬ë·°ë§Œ í•„í„°ë§\"\"\"\n",
    "    filtered = [\n",
    "        r for r in dataset\n",
    "        if any(kw.lower() in r.get('TITLE', '').lower() for kw in keywords)\n",
    "    ]\n",
    "    return filtered\n",
    "\n",
    "# ì˜ˆ: ì‹¬ë¦¬í•™/ì¸ì§€ê³¼í•™ ê´€ë ¨ ë¦¬ë·°ë§Œ\n",
    "psych_keywords = ['psychology', 'cognitive', 'mental', 'depression', 'emotion']\n",
    "psych_reviews = filter_by_field(peerread, psych_keywords)\n",
    "\n",
    "print(f\"ì‹¬ë¦¬í•™ ê´€ë ¨ ë¦¬ë·°: {len(psych_reviews)}ê°œ\")\n",
    "\n",
    "if psych_reviews:\n",
    "    print(\"\\nìƒ˜í”Œ ë…¼ë¬¸ ì œëª©:\")\n",
    "    for r in psych_reviews[:5]:\n",
    "        print(f\"- {r.get('TITLE', 'N/A')[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 15: ë¶„ì•¼ë³„ í•„í„°ë§\n\ndef filter_by_field(dataset, keywords):\n    \"\"\"íŠ¹ì • ë¶„ì•¼ì˜ ë¦¬ë·°ë§Œ í•„í„°ë§\"\"\"\n    filtered = [\n        r for r in dataset\n        if any(kw.lower() in r.get('TITLE', '').lower() for kw in keywords)\n    ]\n    return filtered\n\n# ì˜ˆ: ì‹¬ë¦¬í•™/ì¸ì§€ê³¼í•™ ê´€ë ¨ ë¦¬ë·°ë§Œ\npsych_keywords = ['psychology', 'cognitive', 'mental', 'depression', 'emotion']\npsych_reviews = filter_by_field(peerread, psych_keywords)\n\nprint(f\"ì‹¬ë¦¬í•™ ê´€ë ¨ ë¦¬ë·°: {len(psych_reviews)}ê°œ\")\n\nif psych_reviews:\n    print(\"\\nìƒ˜í”Œ ë…¼ë¬¸ ì œëª©:\")\n    for i, r in enumerate(psych_reviews[:10]):\n        print(f\"[{i}] {r.get('TITLE', 'N/A')[:60]}...\")\n    \n    print(\"\\nğŸ’¡ ë¶„ì•¼ë³„ë¡œ í•„í„°ë§í•œ í›„ Cell 7-8ì²˜ëŸ¼ ì„ íƒí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# DIY Cell 16: ë³¸ì¸ ë¶„ì•¼ í‚¤ì›Œë“œë¡œ ì»¤ìŠ¤í…€\n\nmy_keywords = ['your', 'field', 'keywords']  # <- ìˆ˜ì •!\n\nmy_field_reviews = filter_by_field(peerread, my_keywords)\nprint(f\"ë³¸ì¸ ë¶„ì•¼ ë¦¬ë·°: {len(my_field_reviews)}ê°œ\")\n\nif my_field_reviews:\n    print(\"\\nìƒ˜í”Œ ë…¼ë¬¸ ì œëª©:\")\n    for i, r in enumerate(my_field_reviews[:10]):\n        print(f\"[{i}] {r.get('TITLE', 'N/A')[:60]}...\")\n    \n    # ì´ ë¦¬ë·°ë“¤ë¡œ few-shot ì¬êµ¬ì„±\n    if len(my_field_reviews) >= 5:\n        print(f\"\\nâœ… ì¶©ë¶„í•œ ë¦¬ë·°ê°€ ìˆìŠµë‹ˆë‹¤!\")\n        print(\"   ì´ ëª©ë¡ì—ì„œ 5ê°œë¥¼ ì„ íƒí•´ few-shot examplesë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ì°¸ê³  ìë£Œ\n",
    "\n",
    "### PeerRead\n",
    "- **GitHub**: https://github.com/allenai/PeerRead\n",
    "- **Paper**: https://arxiv.org/abs/1804.09635\n",
    "- **Hugging Face**: https://huggingface.co/datasets/allenai/peer_read\n",
    "\n",
    "### OpenReview\n",
    "- **Platform**: https://openreview.net/\n",
    "- NeurIPS, ICLR, ICML ë“±ì˜ ë¦¬ë·° ê³µê°œ\n",
    "\n",
    "### Few-Shot Learning\n",
    "- OpenAI: [Best practices for prompt engineering](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)\n",
    "- Anthropic: [Prompt engineering guide](https://docs.anthropic.com/claude/docs/prompt-engineering)\n",
    "\n",
    "---\n",
    "\n",
    "**ì™„ë£Œ! ğŸ‰**\n",
    "\n",
    "Part 5ì—ì„œ ë°°ìš´ ë‚´ìš©:\n",
    "- PeerRead ë°ì´í„°ì…‹ í™œìš©\n",
    "- Few-shot learning êµ¬í˜„\n",
    "- ë¦¬ë·° í’ˆì§ˆ ë¹„êµ ë° ë¶„ì„\n",
    "- ë¶„ì•¼ë³„ ì»¤ìŠ¤í…€ ë°©ë²•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}