{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Deep Dive - ë¬¸í—Œ ê²€ìƒ‰ (Agent Laboratory / PaSa)\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. Agent Laboratoryì™€ PaSaì˜ ì½”ë“œ êµ¬ì¡° ì´í•´\n",
    "2. arXiv/Scholar ìë™ ê²€ìƒ‰ ì‹¤í–‰\n",
    "3. ê²€ìƒ‰ ë¡œì§ ì»¤ìŠ¤í…€ (ì¿¼ë¦¬, í•„í„°, ì •ë ¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Google Drive Mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "import os\n",
    "WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "os.makedirs(WORKSHOP_DIR, exist_ok=True)\n",
    "os.chdir(WORKSHOP_DIR)\n",
    "print(f\"ì‘ì—… í´ë”: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜ + ì €ì¥ì†Œ í´ë¡ \n",
    "!pip install arxiv openai python-dotenv -q\n",
    "\n",
    "# Agent Laboratory í´ë¡ \n",
    "!git clone https://github.com/SamuelSchmidgall/AgentLaboratory.git 2>/dev/null || echo \"Already cloned\"\n",
    "\n",
    "# PaSa í´ë¡   \n",
    "!git clone https://github.com/bytedance/pasa.git 2>/dev/null || echo \"Already cloned\"\n",
    "\n",
    "print(\"ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: API Key ë¡œë”©\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "except:\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY or ''\n",
    "print(\"API Key ì„¤ì • ì™„ë£Œ!\" if OPENAI_API_KEY else \"API Key ì—†ìŒ - ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: Agent Laboratory ì½”ë“œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Laboratory êµ¬ì¡°\n",
    "\n",
    "```\n",
    "AgentLaboratory/\n",
    "â”œâ”€â”€ agents/\n",
    "â”‚   â”œâ”€â”€ literature_agent.py   # ë¬¸í—Œ ê²€ìƒ‰ ì—ì´ì „íŠ¸ â­\n",
    "â”‚   â”œâ”€â”€ experiment_agent.py   # ì‹¤í—˜ ì—ì´ì „íŠ¸\n",
    "â”‚   â””â”€â”€ report_agent.py       # ë³´ê³ ì„œ ì—ì´ì „íŠ¸\n",
    "â”œâ”€â”€ tools/\n",
    "â”‚   â””â”€â”€ arxiv_search.py       # arXiv API ë˜í¼ â­\n",
    "â””â”€â”€ run.py                    # ë©”ì¸ ì‹¤í–‰\n",
    "```\n",
    "\n",
    "**í•µì‹¬ íë¦„:**\n",
    "1. ì—°êµ¬ ì£¼ì œ ì…ë ¥\n",
    "2. `literature_agent`ê°€ arXivì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\n",
    "3. ë…¼ë¬¸ ìš”ì•½ + ì‹¤í—˜ ì œì•ˆ\n",
    "4. ë³´ê³ ì„œ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Agent Laboratory í•µì‹¬ ëª¨ë“ˆ í™•ì¸\n",
    "import os\n",
    "\n",
    "# í´ë” êµ¬ì¡° í™•ì¸\n",
    "agent_lab_path = \"AgentLaboratory\"\n",
    "if os.path.exists(agent_lab_path):\n",
    "    print(\"ğŸ“ AgentLaboratory êµ¬ì¡°:\")\n",
    "    for root, dirs, files in os.walk(agent_lab_path):\n",
    "        level = root.replace(agent_lab_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # ì²˜ìŒ 5ê°œ íŒŒì¼ë§Œ\n",
    "            if file.endswith('.py'):\n",
    "                print(f\"{subindent}{file}\")\n",
    "else:\n",
    "    print(\"AgentLaboratoryê°€ í´ë¡ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cell 2ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: arXiv ê²€ìƒ‰ ëª¨ë“ˆ ì§ì ‘ ì‚´í´ë³´ê¸°\n",
    "import arxiv\n",
    "\n",
    "# arXiv ê²€ìƒ‰ í•¨ìˆ˜ (Agent Laboratory ìŠ¤íƒ€ì¼)\n",
    "def search_arxiv_papers(query, max_results=10, sort_by=\"relevance\"):\n",
    "    \"\"\"\n",
    "    Agent Laboratoryì˜ arxiv_search.py í•µì‹¬ ë¡œì§\n",
    "    \"\"\"\n",
    "    sort_criterion = {\n",
    "        \"relevance\": arxiv.SortCriterion.Relevance,\n",
    "        \"date\": arxiv.SortCriterion.SubmittedDate,\n",
    "    }.get(sort_by, arxiv.SortCriterion.Relevance)\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=sort_criterion\n",
    "    )\n",
    "    \n",
    "    papers = []\n",
    "    for result in search.results():\n",
    "        papers.append({\n",
    "            \"title\": result.title,\n",
    "            \"authors\": [a.name for a in result.authors],\n",
    "            \"abstract\": result.summary,\n",
    "            \"published\": result.published.strftime(\"%Y-%m-%d\"),\n",
    "            \"pdf_url\": result.pdf_url,\n",
    "            \"arxiv_id\": result.entry_id.split('/')[-1]\n",
    "        })\n",
    "    return papers\n",
    "\n",
    "print(\"search_arxiv_papers í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(f\"ì‹œê·¸ë‹ˆì²˜: search_arxiv_papers(query, max_results=10, sort_by='relevance')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaSa (Paper Search Agent) êµ¬ì¡°\n",
    "\n",
    "```\n",
    "pasa/\n",
    "â”œâ”€â”€ agents/\n",
    "â”‚   â”œâ”€â”€ crawler.py     # ë…¼ë¬¸ í¬ë¡¤ë§ ì—ì´ì „íŠ¸ â­\n",
    "â”‚   â””â”€â”€ selector.py    # ê´€ë ¨ì„± í‰ê°€ (PPO í•™ìŠµë¨) â­\n",
    "â”œâ”€â”€ search/\n",
    "â”‚   â”œâ”€â”€ arxiv.py       # arXiv ê²€ìƒ‰\n",
    "â”‚   â””â”€â”€ scholar.py     # Google Scholar ê²€ìƒ‰\n",
    "â””â”€â”€ run_search.py\n",
    "```\n",
    "\n",
    "**í•µì‹¬ ì°¨ì´ì :**\n",
    "- PaSaëŠ” **PPOë¡œ í•™ìŠµëœ Selector**ê°€ ê´€ë ¨ì„± í‰ê°€\n",
    "- Agent Laboratoryë³´ë‹¤ ë” ì •êµí•œ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì§ˆë¬¸\n\në‘ ë„êµ¬ì˜ êµ¬ì¡°ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”:\n- Agent Laboratory: ë¬¸í—Œ â†’ ì‹¤í—˜ â†’ ë³´ê³ ì„œ (E2E íŒŒì´í”„ë¼ì¸)\n- PaSa: ê²€ìƒ‰ íŠ¹í™” (PPO ê¸°ë°˜ ì„ íƒ)\n\në³¸ì¸ ì—°êµ¬ì—ëŠ” ì–´ë–¤ ì ‘ê·¼ì´ ë” ë§ì„ê¹Œìš”?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ì¨ë³´ê¸°: arXiv ë…¼ë¬¸ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìƒ˜í”Œ ë°ì´í„°\n",
    "\n",
    "í…ŒìŠ¤íŠ¸í•  ì—°êµ¬ ì£¼ì œ:\n",
    "- \"LLM reasoning and cognitive psychology\"\n",
    "- \"AI agent for scientific discovery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ìƒ˜í”Œ ê²€ìƒ‰ ì‹¤í–‰ (ë°œí‘œì ë°ëª¨)\n",
    "sample_query = \"LLM reasoning cognitive psychology\"\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ì–´: {sample_query}\\n\")\n",
    "results = search_arxiv_papers(sample_query, max_results=5)\n",
    "\n",
    "print(f\"ğŸ“š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë…¼ë¬¸\\n\")\n",
    "for i, paper in enumerate(results, 1):\n",
    "    print(f\"{i}. {paper['title']}\")\n",
    "    print(f\"   ì €ì: {', '.join(paper['authors'][:3])}...\")\n",
    "    print(f\"   ë‚ ì§œ: {paper['published']}\")\n",
    "    print(f\"   ID: {paper['arxiv_id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: ê²°ê³¼ ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(results)\n",
    "df['abstract_preview'] = df['abstract'].str[:100] + '...'\n",
    "df['author_count'] = df['authors'].apply(len)\n",
    "\n",
    "print(\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½\")\n",
    "display(df[['title', 'published', 'author_count']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: ë³¸ì¸ ì—°êµ¬ ì£¼ì œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 13: ë³¸ì¸ ì—°êµ¬ ì£¼ì œ ê²€ìƒ‰\n",
    "# íŒíŠ¸: my_query ë³€ìˆ˜ë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤\n",
    "\n",
    "my_query = \"your research topic here\"  # <- ì´ ë¶€ë¶„ ìˆ˜ì •!\n",
    "\n",
    "my_results = search_arxiv_papers(my_query, max_results=10)\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ì–´: {my_query}\")\n",
    "print(f\"ğŸ“š ê²°ê³¼: {len(my_results)}ê°œ ë…¼ë¬¸\\n\")\n",
    "\n",
    "for i, paper in enumerate(my_results, 1):\n",
    "    print(f\"{i}. {paper['title']}\")\n",
    "    print(f\"   {paper['published']} | {paper['arxiv_id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 14: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n",
    "# ì§ˆë¬¸: ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ê´€ë ¨ì„± ë†’ì€ ë…¼ë¬¸ì€ ëª‡ ê°œì¸ê°€ìš”?\n",
    "\n",
    "# ê´€ë ¨ì„± í‰ê°€ (1-5ì )\n",
    "# ë©”ëª¨:\n",
    "# ë…¼ë¬¸ 1: \n",
    "# ë…¼ë¬¸ 2:\n",
    "# ë…¼ë¬¸ 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°”ê¿”ë³´ê¸°: ê²€ìƒ‰ ë¡œì§ ì»¤ìŠ¤í…€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìˆ˜ì • í¬ì¸íŠ¸\n",
    "\n",
    "| í•­ëª© | ê¸°ë³¸ê°’ | ì»¤ìŠ¤í…€ ì•„ì´ë””ì–´ |\n",
    "|------|--------|----------------|\n",
    "| ê²€ìƒ‰ í•„ë“œ | ì „ì²´ | ì œëª©ë§Œ, ì´ˆë¡ë§Œ |\n",
    "| ì¹´í…Œê³ ë¦¬ | ì „ì²´ | cs.CL, cs.AI, q-bio |\n",
    "| ë‚ ì§œ ë²”ìœ„ | ì „ì²´ | ìµœê·¼ 2ë…„ë§Œ |\n",
    "| ì •ë ¬ | relevance | ìµœì‹ ìˆœ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: ì»¤ìŠ¤í…€ ê²€ìƒ‰ í•¨ìˆ˜ (Before/After)\n",
    "\n",
    "# Before: ê¸°ë³¸ ê²€ìƒ‰\n",
    "def search_basic(query):\n",
    "    return search_arxiv_papers(query, max_results=10)\n",
    "\n",
    "# After: ì‹¬ë¦¬í•™ íŠ¹í™” ê²€ìƒ‰\n",
    "def search_psychology_papers(query, max_results=10, years_back=2):\n",
    "    \"\"\"\n",
    "    ì‹¬ë¦¬í•™ ì—°êµ¬ìš© ì»¤ìŠ¤í…€ ê²€ìƒ‰\n",
    "    - q-bio.NC (Neurons and Cognition) ì¹´í…Œê³ ë¦¬ ìš°ì„ \n",
    "    - ìµœê·¼ Në…„ ë…¼ë¬¸ë§Œ\n",
    "    - ì œëª©+ì´ˆë¡ì—ì„œ ê²€ìƒ‰\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    # ë‚ ì§œ í•„í„° ê³„ì‚°\n",
    "    cutoff_date = datetime.now() - timedelta(days=years_back*365)\n",
    "    \n",
    "    # arXiv ì¿¼ë¦¬ ë¬¸ë²•: cat:ì¹´í…Œê³ ë¦¬ AND (ti:ì œëª© OR abs:ì´ˆë¡)\n",
    "    enhanced_query = f\"(ti:{query} OR abs:{query})\"\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=enhanced_query,\n",
    "        max_results=max_results * 2,  # í•„í„°ë§ ìœ„í•´ ë” ë§ì´ ê²€ìƒ‰\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    papers = []\n",
    "    for result in search.results():\n",
    "        # ë‚ ì§œ í•„í„°\n",
    "        if result.published.replace(tzinfo=None) < cutoff_date:\n",
    "            continue\n",
    "        \n",
    "        papers.append({\n",
    "            \"title\": result.title,\n",
    "            \"authors\": [a.name for a in result.authors],\n",
    "            \"abstract\": result.summary,\n",
    "            \"published\": result.published.strftime(\"%Y-%m-%d\"),\n",
    "            \"categories\": result.categories,\n",
    "            \"pdf_url\": result.pdf_url\n",
    "        })\n",
    "        \n",
    "        if len(papers) >= max_results:\n",
    "            break\n",
    "    \n",
    "    return papers\n",
    "\n",
    "# ë¹„êµ ì‹¤í–‰\n",
    "query = \"cognitive load working memory\"\n",
    "print(\"=== ê¸°ë³¸ ê²€ìƒ‰ ===\")\n",
    "basic = search_basic(query)\n",
    "print(f\"ê²°ê³¼: {len(basic)}ê°œ\")\n",
    "\n",
    "print(\"\\n=== ì‹¬ë¦¬í•™ íŠ¹í™” ê²€ìƒ‰ (ìµœê·¼ 2ë…„) ===\")\n",
    "psych = search_psychology_papers(query, years_back=2)\n",
    "print(f\"ê²°ê³¼: {len(psych)}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 17: ë³¸ì¸ë§Œì˜ í•„í„° ì¶”ê°€í•˜ê¸°\n",
    "\n",
    "def my_custom_search(query, max_results=10):\n",
    "    \"\"\"\n",
    "    TODO: ë³¸ì¸ ì—°êµ¬ì— ë§ê²Œ ì»¤ìŠ¤í…€í•˜ì„¸ìš”\n",
    "    \n",
    "    ì•„ì´ë””ì–´:\n",
    "    - íŠ¹ì • ì €ì í•„í„°: if 'Author Name' in authors\n",
    "    - í‚¤ì›Œë“œ í•„í„°: if 'keyword' in abstract.lower()\n",
    "    - ì¹´í…Œê³ ë¦¬ í•„í„°: if 'cs.CL' in categories\n",
    "    \"\"\"\n",
    "    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n",
    "    pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "# results = my_custom_search(\"your query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: LLMìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„±\n",
    "from openai import OpenAI\n",
    "\n",
    "def generate_search_queries(research_topic, num_queries=3):\n",
    "    \"\"\"\n",
    "    ì—°êµ¬ ì£¼ì œì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„±\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    prompt = f\"\"\"Generate {num_queries} different arXiv search queries for the following research topic.\n",
    "Each query should focus on a different aspect of the topic.\n",
    "Return only the queries, one per line.\n",
    "\n",
    "Research topic: {research_topic}\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    queries = response.choices[0].message.content.strip().split('\\n')\n",
    "    return [q.strip() for q in queries if q.strip()]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ (API key ìˆì„ ë•Œë§Œ)\n",
    "if OPENAI_API_KEY:\n",
    "    topic = \"AI agents for psychological research\"\n",
    "    queries = generate_search_queries(topic)\n",
    "    print(f\"ìƒì„±ëœ ì¿¼ë¦¬:\")\n",
    "    for i, q in enumerate(queries, 1):\n",
    "        print(f\"{i}. {q}\")\n",
    "else:\n",
    "    print(\"API key ì—†ìŒ - ì´ ê¸°ëŠ¥ì€ ê±´ë„ˆëœë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 19: ìë™ ìƒì„±ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰\n",
    "\n",
    "my_topic = \"your research topic\"  # <- ìˆ˜ì •\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    # ì¿¼ë¦¬ ìƒì„±\n",
    "    auto_queries = generate_search_queries(my_topic, num_queries=3)\n",
    "    \n",
    "    # ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰\n",
    "    all_results = {}\n",
    "    for query in auto_queries:\n",
    "        results = search_arxiv_papers(query, max_results=3)\n",
    "        all_results[query] = results\n",
    "        print(f\"\\nğŸ” '{query}' â†’ {len(results)}ê°œ\")\n",
    "        for p in results:\n",
    "            print(f\"   - {p['title'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ (ì›ë³¸ vs ìˆ˜ì •ë³¸)\n",
    "query = \"cognitive psychology LLM\"\n",
    "\n",
    "# ê¸°ë³¸ ê²€ìƒ‰\n",
    "basic_results = search_arxiv_papers(query, max_results=5)\n",
    "\n",
    "# ì‹¬ë¦¬í•™ íŠ¹í™” ê²€ìƒ‰\n",
    "psych_results = search_psychology_papers(query, max_results=5, years_back=2)\n",
    "\n",
    "print(\"ğŸ“Š ê²€ìƒ‰ ë°©ë²• ë¹„êµ\\n\")\n",
    "print(f\"ê¸°ë³¸ ê²€ìƒ‰: {len(basic_results)}ê°œ\")\n",
    "for p in basic_results[:3]:\n",
    "    print(f\"  - {p['title'][:50]}... ({p['published']})\")\n",
    "\n",
    "print(f\"\\nì‹¬ë¦¬í•™ íŠ¹í™” (2ë…„): {len(psych_results)}ê°œ\")\n",
    "for p in psych_results[:3]:\n",
    "    print(f\"  - {p['title'][:50]}... ({p['published']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í† ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í† ë¡  ì§ˆë¬¸\n",
    "\n",
    "1. **ê²€ìƒ‰ ê²°ê³¼ì˜ ì§ˆì„ ì–´ë–»ê²Œ í‰ê°€í•  ìˆ˜ ìˆì„ê¹Œ?**\n",
    "   - precision vs recall\n",
    "   - ê´€ë ¨ì„± ì ìˆ˜?\n",
    "\n",
    "2. **Agent Laboratory vs PaSa ì¤‘ ì–´ë–¤ ê²ƒì„ ë² ì´ìŠ¤ë¡œ ì“¸ê¹Œ?**\n",
    "   - Agent Lab: E2E íŒŒì´í”„ë¼ì¸ (ë¬¸í—Œâ†’ì‹¤í—˜â†’ë³´ê³ ì„œ)\n",
    "   - PaSa: ê²€ìƒ‰ íŠ¹í™” (PPO ê¸°ë°˜ ì„ íƒ)\n",
    "\n",
    "3. **ì¶”ê°€í•˜ê³  ì‹¶ì€ ê¸°ëŠ¥ì€?**\n",
    "   - PubMed í†µí•©?\n",
    "   - í•œê¸€ ë…¼ë¬¸ (DBpia, RISS)?\n",
    "   - ìë™ PDF ë‹¤ìš´ë¡œë“œ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì–´ì„œ ì‹¤ìŠµí•  ë‚´ìš©:\n",
    "- **Part 3**: LitLLMìœ¼ë¡œ ê²€ìƒ‰ëœ ë…¼ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ Related Work ì´ˆì•ˆ ìƒì„±\n",
    "- **Part 4**: AgentReviewë¡œ ì‘ì„±í•œ ë…¼ë¬¸ì— í”¼ë“œë°± ë°›ê¸°\n",
    "\n",
    "### ê³¼ì œ ì•„ì´ë””ì–´\n",
    "```python\n",
    "# PubMed API ëª¨ë“ˆ ì¶”ê°€í•˜ê¸°\n",
    "def search_pubmed(query):\n",
    "    # E-utilities API ì‚¬ìš©\n",
    "    pass\n",
    "\n",
    "# ì—¬ëŸ¬ DB ê²°ê³¼ í†µí•©í•˜ê¸°\n",
    "def search_all(query):\n",
    "    arxiv = search_arxiv_papers(query)\n",
    "    pubmed = search_pubmed(query)\n",
    "    return merge_and_dedupe(arxiv, pubmed)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}