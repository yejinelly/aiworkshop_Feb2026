{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Deep Dive - ë¬¸í—Œ ê²€ìƒ‰ (Agent Laboratory / PaSa)\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "1. Agent Laboratoryì™€ PaSaì˜ ì½”ë“œ êµ¬ì¡° ì´í•´\n",
    "2. arXiv/Scholar ìë™ ê²€ìƒ‰ ì‹¤í–‰\n",
    "3. ê²€ìƒ‰ ë¡œì§ ì»¤ìŠ¤í…€ (ì¿¼ë¦¬, í•„í„°, ì •ë ¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: í™˜ê²½ ì„¤ì • (Colab/ë¡œì»¬ ìë™ ê°ì§€)\nimport os\nimport sys\n\n# Colab í™˜ê²½ ê°ì§€\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive/')\n    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n    os.makedirs(WORKSHOP_DIR, exist_ok=True)\n    os.chdir(WORKSHOP_DIR)\n    IN_COLAB = True\n    print(\"ğŸŒ Colab í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\nexcept ImportError:\n    # ë¡œì»¬ í™˜ê²½: í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì´ë™\n    current_dir = os.getcwd()\n    if current_dir.endswith('notebooks'):\n        os.chdir('..')\n    WORKSHOP_DIR = os.getcwd()\n    IN_COLAB = False\n    print(\"ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘\")\n\nprint(f\"ì‘ì—… í´ë”: {WORKSHOP_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: íŒ¨í‚¤ì§€ ì„¤ì¹˜ + ì €ì¥ì†Œ í´ë¡ \n# Colab: ìë™ ì„¤ì¹˜\n# ë¡œì»¬: pyproject.tomlë¡œ ë¯¸ë¦¬ ì„¤ì¹˜ í•„ìš” (uv pip install -e . ë˜ëŠ” pip install -e .)\n\nif IN_COLAB:\n    print(\"ğŸ“¦ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n    %pip install arxiv openai python-dotenv pandas -q\n    \n    # Agent Laboratory í´ë¡ \n    !git clone https://github.com/SamuelSchmidgall/AgentLaboratory.git 2>/dev/null || echo \"  âœ“ AgentLaboratory already cloned\"\n    \n    # PaSa í´ë¡   \n    !git clone https://github.com/bytedance/pasa.git 2>/dev/null || echo \"  âœ“ PaSa already cloned\"\n    \n    print(\"âœ… ì„¤ì¹˜ ì™„ë£Œ!\")\nelse:\n    print(\"âœ… ë¡œì»¬ í™˜ê²½: pyproject.tomlë¡œ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ì‚¬ìš©\")\n    print(\"   (ë¯¸ì„¤ì¹˜ ì‹œ: uv pip install -e . ë˜ëŠ” pip install -e .)\")\n    \n    # ë¡œì»¬ì—ì„œ ì €ì¥ì†Œ í´ë¡  (WORKSHOP_DIR ê¸°ì¤€, ìˆìœ¼ë©´ ê±´ë„ˆëœ€)\n    import subprocess\n    repos = [\n        (\"AgentLaboratory\", \"https://github.com/SamuelSchmidgall/AgentLaboratory.git\"),\n        (\"pasa\", \"https://github.com/bytedance/pasa.git\")\n    ]\n    \n    for name, url in repos:\n        repo_path = os.path.join(WORKSHOP_DIR, name)\n        if not os.path.exists(repo_path):\n            print(f\"   ğŸ“¥ {name} í´ë¡  ì¤‘...\")\n            subprocess.run([\"git\", \"clone\", url, repo_path], capture_output=True)\n            print(f\"   âœ… {name} í´ë¡  ì™„ë£Œ\")\n        else:\n            print(f\"   âœ“ {name} already exists\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: API Key ë¡œë”©\nimport os\nfrom pathlib import Path\n\n# Colab í™˜ê²½ ì²´í¬\nif IN_COLAB:\n    # Colab userdataì—ì„œ í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°\n    try:\n        from google.colab import userdata\n        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n        GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n        print(\"âœ… Colab Secretsì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n    except:\n        print(\"âš ï¸ Colab Secretsì— API KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n        OPENAI_API_KEY = None\n        GEMINI_API_KEY = None\nelse:\n    # ë¡œì»¬ í™˜ê²½: dotenv ì‚¬ìš©\n    try:\n        from dotenv import load_dotenv\n        load_dotenv()\n        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n        GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n        \n        if OPENAI_API_KEY or GEMINI_API_KEY:\n            print(\"âœ… .env íŒŒì¼ì—ì„œ API Key ë¡œë”© ì™„ë£Œ\")\n        else:\n            print(\"âš ï¸ .env íŒŒì¼ì— API KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”\")\n    except ImportError:\n        print(\"âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤\")\n        OPENAI_API_KEY = None\n        GEMINI_API_KEY = None\n\n# í™˜ê²½ë³€ìˆ˜ ì„¤ì •\nos.environ['OPENAI_API_KEY'] = OPENAI_API_KEY or ''\nos.environ['GEMINI_API_KEY'] = GEMINI_API_KEY or ''\n\n# í™•ì¸\nprint(f\"\\nğŸ”‘ OpenAI: {'ì„¤ì •ë¨' if OPENAI_API_KEY else 'ì—†ìŒ (LLM ê¸°ëŠ¥ ì œí•œ)'}\")\nprint(f\"ğŸ”‘ Gemini: {'ì„¤ì •ë¨' if GEMINI_API_KEY else 'ì—†ìŒ (LLM ê¸°ëŠ¥ ì œí•œ)'}\")\nprint(\"ğŸ’¡ arXiv ê²€ìƒ‰ì€ API key ì—†ì´ë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. íŒŒì•…í•˜ê¸°: Agent Laboratory ì½”ë“œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Agent Laboratory êµ¬ì¡°\n\n```\nAgentLaboratory/\nâ”œâ”€â”€ agents/\nâ”‚   â””â”€â”€ literature_agent.py   # ë¬¸í—Œ ê²€ìƒ‰ ì—ì´ì „íŠ¸ â­\nâ”œâ”€â”€ tools/\nâ”‚   â””â”€â”€ arxiv_search.py       # arXiv API ë˜í¼ â­\nâ””â”€â”€ run.py                    # ë©”ì¸ ì‹¤í–‰\n```\nğŸ’¡ ì‹¤í—˜ ì„¤ê³„/ë³´ê³ ì„œ ê¸°ëŠ¥ë„ ìˆì§€ë§Œ, ì›Œí¬ìƒµì—ì„œëŠ” **ë¬¸í—Œ ê²€ìƒ‰**ë§Œ ì‚¬ìš©\n\n**í•µì‹¬ íë¦„:**\n1. ì—°êµ¬ ì£¼ì œ ì…ë ¥\n2. `literature_agent`ê°€ arXivì—ì„œ ê´€ë ¨ ë…¼ë¬¸ ê²€ìƒ‰\n3. ë…¼ë¬¸ ìš”ì•½ ë° ê´€ë ¨ì„± í‰ê°€"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Agent Laboratory í•µì‹¬ ëª¨ë“ˆ í™•ì¸\n",
    "import os\n",
    "\n",
    "# í´ë” êµ¬ì¡° í™•ì¸\n",
    "agent_lab_path = \"AgentLaboratory\"\n",
    "if os.path.exists(agent_lab_path):\n",
    "    print(\"ğŸ“ AgentLaboratory êµ¬ì¡°:\")\n",
    "    for root, dirs, files in os.walk(agent_lab_path):\n",
    "        level = root.replace(agent_lab_path, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:5]:  # ì²˜ìŒ 5ê°œ íŒŒì¼ë§Œ\n",
    "            if file.endswith('.py'):\n",
    "                print(f\"{subindent}{file}\")\n",
    "else:\n",
    "    print(\"AgentLaboratoryê°€ í´ë¡ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Cell 2ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: arXiv ê²€ìƒ‰ ëª¨ë“ˆ ì§ì ‘ ì‚´í´ë³´ê¸°\nimport arxiv\n\n# arXiv ê²€ìƒ‰ í•¨ìˆ˜ (Agent Laboratory ìŠ¤íƒ€ì¼)\ndef search_arxiv_papers(query, max_results=10, sort_by=\"relevance\"):\n    \"\"\"\n    Agent Laboratoryì˜ arxiv_search.py í•µì‹¬ ë¡œì§\n    \"\"\"\n    sort_criterion = {\n        \"relevance\": arxiv.SortCriterion.Relevance,\n        \"date\": arxiv.SortCriterion.SubmittedDate,\n    }.get(sort_by, arxiv.SortCriterion.Relevance)\n    \n    client = arxiv.Client()\n    search = arxiv.Search(\n        query=query,\n        max_results=max_results,\n        sort_by=sort_criterion\n    )\n    \n    papers = []\n    for result in client.results(search):\n        papers.append({\n            \"title\": result.title,\n            \"authors\": [a.name for a in result.authors],\n            \"abstract\": result.summary,\n            \"published\": result.published.strftime(\"%Y-%m-%d\"),\n            \"pdf_url\": result.pdf_url,\n            \"arxiv_id\": result.entry_id.split('/')[-1]\n        })\n    return papers\n\nprint(\"search_arxiv_papers í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\nprint(f\"ì‹œê·¸ë‹ˆì²˜: search_arxiv_papers(query, max_results=10, sort_by='relevance')\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaSa (Paper Search Agent) êµ¬ì¡°\n",
    "\n",
    "```\n",
    "pasa/\n",
    "â”œâ”€â”€ agents/\n",
    "â”‚   â”œâ”€â”€ crawler.py     # ë…¼ë¬¸ í¬ë¡¤ë§ ì—ì´ì „íŠ¸ â­\n",
    "â”‚   â””â”€â”€ selector.py    # ê´€ë ¨ì„± í‰ê°€ (PPO í•™ìŠµë¨) â­\n",
    "â”œâ”€â”€ search/\n",
    "â”‚   â”œâ”€â”€ arxiv.py       # arXiv ê²€ìƒ‰\n",
    "â”‚   â””â”€â”€ scholar.py     # Google Scholar ê²€ìƒ‰\n",
    "â””â”€â”€ run_search.py\n",
    "```\n",
    "\n",
    "**í•µì‹¬ ì°¨ì´ì :**\n",
    "- PaSaëŠ” **PPOë¡œ í•™ìŠµëœ Selector**ê°€ ê´€ë ¨ì„± í‰ê°€\n",
    "- Agent Laboratoryë³´ë‹¤ ë” ì •êµí•œ í•„í„°ë§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ì§ˆë¬¸\n\në‘ ë„êµ¬ì˜ êµ¬ì¡°ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”:\n- Agent Laboratory: ë¬¸í—Œ ê²€ìƒ‰ ìë™í™” (ì›Œí¬ìƒµì—ì„œëŠ” ì´ ë¶€ë¶„ë§Œ ì‚¬ìš©)\n- PaSa: ê²€ìƒ‰ íŠ¹í™” (PPO ê¸°ë°˜ ê´€ë ¨ì„± í‰ê°€)\n\në³¸ì¸ ì—°êµ¬ì—ëŠ” ì–´ë–¤ ì ‘ê·¼ì´ ë” ë§ì„ê¹Œìš”?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ì¨ë³´ê¸°: arXiv ë…¼ë¬¸ ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìƒ˜í”Œ ë°ì´í„°\n",
    "\n",
    "í…ŒìŠ¤íŠ¸í•  ì—°êµ¬ ì£¼ì œ:\n",
    "- \"LLM reasoning and cognitive psychology\"\n",
    "- \"AI agent for scientific discovery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: ìƒ˜í”Œ ê²€ìƒ‰ ì‹¤í–‰ (ë°œí‘œì ë°ëª¨)\n",
    "sample_query = \"LLM reasoning cognitive psychology\"\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ì–´: {sample_query}\\n\")\n",
    "results = search_arxiv_papers(sample_query, max_results=5)\n",
    "\n",
    "print(f\"ğŸ“š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë…¼ë¬¸\\n\")\n",
    "for i, paper in enumerate(results, 1):\n",
    "    print(f\"{i}. {paper['title']}\")\n",
    "    print(f\"   ì €ì: {', '.join(paper['authors'][:3])}...\")\n",
    "    print(f\"   ë‚ ì§œ: {paper['published']}\")\n",
    "    print(f\"   ID: {paper['arxiv_id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: ê²°ê³¼ ì‹œê°í™”\n",
    "import pandas as pd\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(results)\n",
    "df['abstract_preview'] = df['abstract'].str[:100] + '...'\n",
    "df['author_count'] = df['authors'].apply(len)\n",
    "\n",
    "print(\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½\")\n",
    "display(df[['title', 'published', 'author_count']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIY: ë³¸ì¸ ì—°êµ¬ ì£¼ì œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 13: ë³¸ì¸ ì—°êµ¬ ì£¼ì œ ê²€ìƒ‰\n",
    "# íŒíŠ¸: my_query ë³€ìˆ˜ë§Œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤\n",
    "\n",
    "my_query = \"your research topic here\"  # <- ì´ ë¶€ë¶„ ìˆ˜ì •!\n",
    "\n",
    "my_results = search_arxiv_papers(my_query, max_results=10)\n",
    "\n",
    "print(f\"ğŸ” ê²€ìƒ‰ì–´: {my_query}\")\n",
    "print(f\"ğŸ“š ê²°ê³¼: {len(my_results)}ê°œ ë…¼ë¬¸\\n\")\n",
    "\n",
    "for i, paper in enumerate(my_results, 1):\n",
    "    print(f\"{i}. {paper['title']}\")\n",
    "    print(f\"   {paper['published']} | {paper['arxiv_id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 14: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„\n",
    "# ì§ˆë¬¸: ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ê´€ë ¨ì„± ë†’ì€ ë…¼ë¬¸ì€ ëª‡ ê°œì¸ê°€ìš”?\n",
    "\n",
    "# ê´€ë ¨ì„± í‰ê°€ (1-5ì )\n",
    "# ë©”ëª¨:\n",
    "# ë…¼ë¬¸ 1: \n",
    "# ë…¼ë¬¸ 2:\n",
    "# ë…¼ë¬¸ 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ë°”ê¿”ë³´ê¸°: ê²€ìƒ‰ ë¡œì§ ì»¤ìŠ¤í…€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìˆ˜ì • í¬ì¸íŠ¸\n",
    "\n",
    "| í•­ëª© | ê¸°ë³¸ê°’ | ì»¤ìŠ¤í…€ ì•„ì´ë””ì–´ |\n",
    "|------|--------|----------------|\n",
    "| ê²€ìƒ‰ í•„ë“œ | ì „ì²´ | ì œëª©ë§Œ, ì´ˆë¡ë§Œ |\n",
    "| ì¹´í…Œê³ ë¦¬ | ì „ì²´ | cs.CL, cs.AI, q-bio |\n",
    "| ë‚ ì§œ ë²”ìœ„ | ì „ì²´ | ìµœê·¼ 2ë…„ë§Œ |\n",
    "| ì •ë ¬ | relevance | ìµœì‹ ìˆœ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 16: ì»¤ìŠ¤í…€ ê²€ìƒ‰ í•¨ìˆ˜ (Before/After)\n\n# Before: ê¸°ë³¸ ê²€ìƒ‰\ndef search_basic(query):\n    return search_arxiv_papers(query, max_results=10)\n\n# After: ì‹¬ë¦¬í•™ íŠ¹í™” ê²€ìƒ‰\ndef search_psychology_papers(query, max_results=10, years_back=2):\n    \"\"\"\n    ì‹¬ë¦¬í•™ ì—°êµ¬ìš© ì»¤ìŠ¤í…€ ê²€ìƒ‰\n    - q-bio.NC (Neurons and Cognition) ì¹´í…Œê³ ë¦¬ ìš°ì„ \n    - ìµœê·¼ Në…„ ë…¼ë¬¸ë§Œ\n    - ì œëª©+ì´ˆë¡ì—ì„œ ê²€ìƒ‰\n    \"\"\"\n    from datetime import datetime, timedelta\n    \n    # ë‚ ì§œ í•„í„° ê³„ì‚°\n    cutoff_date = datetime.now() - timedelta(days=years_back*365)\n    \n    # arXiv ì¿¼ë¦¬ ë¬¸ë²•: cat:ì¹´í…Œê³ ë¦¬ AND (ti:ì œëª© OR abs:ì´ˆë¡)\n    enhanced_query = f\"(ti:{query} OR abs:{query})\"\n    \n    client = arxiv.Client()\n    search = arxiv.Search(\n        query=enhanced_query,\n        max_results=max_results * 2,  # í•„í„°ë§ ìœ„í•´ ë” ë§ì´ ê²€ìƒ‰\n        sort_by=arxiv.SortCriterion.SubmittedDate\n    )\n    \n    papers = []\n    for result in client.results(search):\n        # ë‚ ì§œ í•„í„°\n        if result.published.replace(tzinfo=None) < cutoff_date:\n            continue\n        \n        papers.append({\n            \"title\": result.title,\n            \"authors\": [a.name for a in result.authors],\n            \"abstract\": result.summary,\n            \"published\": result.published.strftime(\"%Y-%m-%d\"),\n            \"categories\": result.categories,\n            \"pdf_url\": result.pdf_url\n        })\n        \n        if len(papers) >= max_results:\n            break\n    \n    return papers\n\n# ë¹„êµ ì‹¤í–‰\nquery = \"cognitive load working memory\"\nprint(\"=== ê¸°ë³¸ ê²€ìƒ‰ ===\")\nbasic = search_basic(query)\nprint(f\"ê²°ê³¼: {len(basic)}ê°œ\")\n\nprint(\"\\n=== ì‹¬ë¦¬í•™ íŠ¹í™” ê²€ìƒ‰ (ìµœê·¼ 2ë…„) ===\")\npsych = search_psychology_papers(query, years_back=2)\nprint(f\"ê²°ê³¼: {len(psych)}ê°œ\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 17: ë³¸ì¸ë§Œì˜ í•„í„° ì¶”ê°€í•˜ê¸°\n",
    "\n",
    "def my_custom_search(query, max_results=10):\n",
    "    \"\"\"\n",
    "    TODO: ë³¸ì¸ ì—°êµ¬ì— ë§ê²Œ ì»¤ìŠ¤í…€í•˜ì„¸ìš”\n",
    "    \n",
    "    ì•„ì´ë””ì–´:\n",
    "    - íŠ¹ì • ì €ì í•„í„°: if 'Author Name' in authors\n",
    "    - í‚¤ì›Œë“œ í•„í„°: if 'keyword' in abstract.lower()\n",
    "    - ì¹´í…Œê³ ë¦¬ í•„í„°: if 'cs.CL' in categories\n",
    "    \"\"\"\n",
    "    # ì—¬ê¸°ì— ì½”ë“œ ì‘ì„±\n",
    "    pass\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "# results = my_custom_search(\"your query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: LLMìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„±\n",
    "from openai import OpenAI\n",
    "\n",
    "def generate_search_queries(research_topic, num_queries=3):\n",
    "    \"\"\"\n",
    "    ì—°êµ¬ ì£¼ì œì—ì„œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„±\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    \n",
    "    prompt = f\"\"\"Generate {num_queries} different arXiv search queries for the following research topic.\n",
    "Each query should focus on a different aspect of the topic.\n",
    "Return only the queries, one per line.\n",
    "\n",
    "Research topic: {research_topic}\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    queries = response.choices[0].message.content.strip().split('\\n')\n",
    "    return [q.strip() for q in queries if q.strip()]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ (API key ìˆì„ ë•Œë§Œ)\n",
    "if OPENAI_API_KEY:\n",
    "    topic = \"AI agents for psychological research\"\n",
    "    queries = generate_search_queries(topic)\n",
    "    print(f\"ìƒì„±ëœ ì¿¼ë¦¬:\")\n",
    "    for i, q in enumerate(queries, 1):\n",
    "        print(f\"{i}. {q}\")\n",
    "else:\n",
    "    print(\"API key ì—†ìŒ - ì´ ê¸°ëŠ¥ì€ ê±´ë„ˆëœë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIY Cell 19: ìë™ ìƒì„±ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰\n",
    "\n",
    "my_topic = \"your research topic\"  # <- ìˆ˜ì •\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    # ì¿¼ë¦¬ ìƒì„±\n",
    "    auto_queries = generate_search_queries(my_topic, num_queries=3)\n",
    "    \n",
    "    # ê° ì¿¼ë¦¬ë¡œ ê²€ìƒ‰\n",
    "    all_results = {}\n",
    "    for query in auto_queries:\n",
    "        results = search_arxiv_papers(query, max_results=3)\n",
    "        all_results[query] = results\n",
    "        print(f\"\\nğŸ” '{query}' â†’ {len(results)}ê°œ\")\n",
    "        for p in results:\n",
    "            print(f\"   - {p['title'][:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ (ì›ë³¸ vs ìˆ˜ì •ë³¸)\n",
    "query = \"cognitive psychology LLM\"\n",
    "\n",
    "# ê¸°ë³¸ ê²€ìƒ‰\n",
    "basic_results = search_arxiv_papers(query, max_results=5)\n",
    "\n",
    "# ì‹¬ë¦¬í•™ íŠ¹í™” ê²€ìƒ‰\n",
    "psych_results = search_psychology_papers(query, max_results=5, years_back=2)\n",
    "\n",
    "print(\"ğŸ“Š ê²€ìƒ‰ ë°©ë²• ë¹„êµ\\n\")\n",
    "print(f\"ê¸°ë³¸ ê²€ìƒ‰: {len(basic_results)}ê°œ\")\n",
    "for p in basic_results[:3]:\n",
    "    print(f\"  - {p['title'][:50]}... ({p['published']})\")\n",
    "\n",
    "print(f\"\\nì‹¬ë¦¬í•™ íŠ¹í™” (2ë…„): {len(psych_results)}ê°œ\")\n",
    "for p in psych_results[:3]:\n",
    "    print(f\"  - {p['title'][:50]}... ({p['published']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. í† ë¡ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### í† ë¡  ì§ˆë¬¸\n\n1. **ê²€ìƒ‰ ê²°ê³¼ì˜ ì§ˆì„ ì–´ë–»ê²Œ í‰ê°€í•  ìˆ˜ ìˆì„ê¹Œ?**\n   - precision vs recall\n   - ê´€ë ¨ì„± ì ìˆ˜?\n\n2. **Agent Laboratory vs PaSa ì¤‘ ì–´ë–¤ ê²ƒì„ ë² ì´ìŠ¤ë¡œ ì“¸ê¹Œ?**\n   - Agent Lab: ë¬¸í—Œ ê²€ìƒ‰ ìë™í™” (ì›Œí¬ìƒµì—ì„œëŠ” ì´ ë¶€ë¶„ë§Œ)\n   - PaSa: ê²€ìƒ‰ íŠ¹í™” (PPO ê¸°ë°˜ ì„ íƒ)\n\n3. **ì¶”ê°€í•˜ê³  ì‹¶ì€ ê¸°ëŠ¥ì€?**\n   - PubMed í†µí•©?\n   - í•œê¸€ ë…¼ë¬¸ (DBpia, RISS)?\n   - ìë™ PDF ë‹¤ìš´ë¡œë“œ?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ì–´ì„œ ì‹¤ìŠµí•  ë‚´ìš©:\n",
    "- **Part 3**: LitLLMìœ¼ë¡œ ê²€ìƒ‰ëœ ë…¼ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ Related Work ì´ˆì•ˆ ìƒì„±\n",
    "- **Part 4**: AgentReviewë¡œ ì‘ì„±í•œ ë…¼ë¬¸ì— í”¼ë“œë°± ë°›ê¸°\n",
    "\n",
    "### ê³¼ì œ ì•„ì´ë””ì–´\n",
    "```python\n",
    "# PubMed API ëª¨ë“ˆ ì¶”ê°€í•˜ê¸°\n",
    "def search_pubmed(query):\n",
    "    # E-utilities API ì‚¬ìš©\n",
    "    pass\n",
    "\n",
    "# ì—¬ëŸ¬ DB ê²°ê³¼ í†µí•©í•˜ê¸°\n",
    "def search_all(query):\n",
    "    arxiv = search_arxiv_papers(query)\n",
    "    pubmed = search_pubmed(query)\n",
    "    return merge_and_dedupe(arxiv, pubmed)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}