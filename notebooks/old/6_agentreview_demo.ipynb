{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: AgentReview - Multi-Agent Peer Review 시스템 분석\n",
    "\n",
    "**SNU AI Psychology Workshop - February 2026**\n",
    "\n",
    "---\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "이 노트북은 **API 비용 없이** AgentReview의 구조와 개념을 학습합니다:\n",
    "\n",
    "1. **Multi-Agent 시스템 아키텍처** 이해\n",
    "2. **5단계 Peer Review 파이프라인** 분석\n",
    "3. **리뷰어 페르소나** 설계 방법\n",
    "4. **나만의 Agent 환경** 만들기 준비\n",
    "\n",
    "---\n",
    "\n",
    "## AgentReview (EMNLP 2024)\n",
    "\n",
    "실제 **ICLR** peer review 프로세스를 LLM으로 시뮬레이션하는 프레임워크입니다.\n",
    "\n",
    "**참고 자료:**\n",
    "- [논문](https://arxiv.org/abs/2406.12708)\n",
    "- [GitHub](https://github.com/Ahren09/AgentReview)\n",
    "- [무료 데모 (HuggingFace)](https://huggingface.co/spaces/Ahren09/AgentReview) - 직접 실험해보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: 환경 설정 (API 키 불필요)\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 작업 디렉토리 설정\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    WORKSHOP_DIR = \"/content/drive/MyDrive/aiworkshop_Feb2026/\"\n",
    "    IN_COLAB = True\n",
    "    print(\"Colab 환경\")\n",
    "except ImportError:\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir.endswith('notebooks'):\n",
    "        os.chdir('..')\n",
    "    WORKSHOP_DIR = os.getcwd()\n",
    "    IN_COLAB = False\n",
    "    print(\"로컬 환경\")\n",
    "\n",
    "print(f\"작업 폴더: {WORKSHOP_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: AgentReview 클론 (코드 분석용)\n",
    "import subprocess\n",
    "\n",
    "agentreview_path = os.path.join(WORKSHOP_DIR, \"agentreview\")\n",
    "\n",
    "if not os.path.exists(agentreview_path):\n",
    "    print(\"AgentReview 클론 중...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/ahren09/agentreview.git\", agentreview_path], capture_output=True)\n",
    "    print(\"AgentReview 클론 완료\")\n",
    "else:\n",
    "    print(\"AgentReview 이미 존재\")\n",
    "\n",
    "# 모듈 경로 추가\n",
    "sys.path.insert(0, agentreview_path)\n",
    "print(f\"\\n코드 분석 준비 완료: {agentreview_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Multi-Agent 아키텍처 이해하기\n",
    "\n",
    "AgentReview는 다음 핵심 컴포넌트로 구성됩니다:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                        Arena                            │\n",
    "│  (게임 진행자: 턴 관리, 메시지 라우팅)                    │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│                     Environment                         │\n",
    "│  (규칙 정의: 5단계 파이프라인, 점수 체계)                 │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│     Player 1      │     Player 2      │    Player 3     │\n",
    "│   (Reviewer 1)    │   (Reviewer 2)    │   (Author)      │\n",
    "│   ┌─────────┐     │   ┌─────────┐     │  ┌─────────┐    │\n",
    "│   │ Backend │     │   │ Backend │     │  │ Backend │    │\n",
    "│   │ (LLM)   │     │   │ (LLM)   │     │  │ (LLM)   │    │\n",
    "│   └─────────┘     │   └─────────┘     │  └─────────┘    │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "- **Arena**: 전체 시뮬레이션을 orchestrate\n",
    "- **Environment**: 게임 규칙과 상태 관리\n",
    "- **Player**: 각 역할(리뷰어, 저자, AC)을 담당\n",
    "- **Backend**: 실제 LLM API 호출 (OpenAI, HuggingFace 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: 핵심 클래스 구조 분석\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AgentReview 핵심 클래스 구조\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Agent 클래스\n",
    "print(\"\\n[1] Agent 클래스 (agentreview/agent.py)\")\n",
    "print(\"-\"*50)\n",
    "print(\"\"\"\n",
    "class Agent:\n",
    "    '''기본 에이전트 - 이름과 역할 설명을 가짐'''\n",
    "    \n",
    "    def __init__(self, name, role_desc, ...):\n",
    "        self.name = name           # 예: \"Reviewer 1\"\n",
    "        self.role_desc = role_desc # 역할 설명 (시스템 프롬프트)\n",
    "        self.backend = backend     # LLM 백엔드\n",
    "\"\"\")\n",
    "\n",
    "# 2. Player 클래스\n",
    "print(\"\\n[2] Player 클래스 (Agent 상속)\")\n",
    "print(\"-\"*50)\n",
    "print(\"\"\"\n",
    "class Player(Agent):\n",
    "    '''게임에 참여하는 플레이어'''\n",
    "    \n",
    "    def act(self, observation):\n",
    "        '''관찰을 받아 행동(텍스트) 생성'''\n",
    "        # 1. 프롬프트 구성\n",
    "        # 2. LLM 호출\n",
    "        # 3. 응답 반환\n",
    "        return self.backend.query(...)\n",
    "\"\"\")\n",
    "\n",
    "# 3. Environment 클래스\n",
    "print(\"\\n[3] Environment 클래스 (agentreview/environments/)\")\n",
    "print(\"-\"*50)\n",
    "print(\"\"\"\n",
    "class Environment:\n",
    "    '''게임 환경 - 규칙과 상태 관리'''\n",
    "    \n",
    "    def step(self, player_name, action):\n",
    "        '''한 턴 진행'''\n",
    "        # 1. 행동 검증\n",
    "        # 2. 상태 업데이트\n",
    "        # 3. 다음 플레이어 결정\n",
    "        return observations, rewards, done\n",
    "\"\"\")\n",
    "\n",
    "# 4. Arena 클래스\n",
    "print(\"\\n[4] Arena 클래스 (전체 진행)\")\n",
    "print(\"-\"*50)\n",
    "print(\"\"\"\n",
    "class Arena:\n",
    "    '''시뮬레이션 진행자'''\n",
    "    \n",
    "    def run(self):\n",
    "        while not done:\n",
    "            # 1. 현재 플레이어 확인\n",
    "            # 2. 관찰 제공\n",
    "            # 3. 행동 요청\n",
    "            # 4. 환경 업데이트\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. 5단계 Peer Review 파이프라인\n",
    "\n",
    "AgentReview의 핵심은 실제 학술 peer review 과정을 모방한 5단계 파이프라인입니다:\n",
    "\n",
    "```\n",
    "Phase 1          Phase 2              Phase 3           Phase 4         Phase 5\n",
    "┌─────────┐     ┌─────────────┐      ┌───────────┐     ┌─────────┐    ┌──────────┐\n",
    "│ Initial │ --> │   Author    │ -->  │ Reviewer- │ --> │  Meta-  │ -->│  Final   │\n",
    "│ Review  │     │  Rebuttal   │      │AC Discuss │     │ Review  │    │ Decision │\n",
    "└─────────┘     └─────────────┘      └───────────┘     └─────────┘    └──────────┘\n",
    "  3 Reviewers     Author responds     Score updates      AC summary    Accept/Reject\n",
    "  give scores     to each review      after discussion   + recommend\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 5단계 파이프라인 상세 분석\n",
    "\n",
    "pipeline_phases = {\n",
    "    \"Phase 1: Reviewer Assessment\": {\n",
    "        \"참여자\": [\"Reviewer 1\", \"Reviewer 2\", \"Reviewer 3\"],\n",
    "        \"목표\": \"각 리뷰어가 독립적으로 논문 평가\",\n",
    "        \"출력\": \"초기 점수 (1-10) + 상세 리뷰\",\n",
    "        \"특징\": \"리뷰어끼리 서로의 평가를 볼 수 없음\"\n",
    "    },\n",
    "    \"Phase 2: Author-Reviewer Discussion\": {\n",
    "        \"참여자\": [\"Author\", \"Reviewers\"],\n",
    "        \"목표\": \"저자가 리뷰에 대해 rebuttal 작성\",\n",
    "        \"출력\": \"Rebuttal 문서\",\n",
    "        \"특징\": \"저자는 모든 리뷰를 볼 수 있음\"\n",
    "    },\n",
    "    \"Phase 3: Reviewer-AC Discussion\": {\n",
    "        \"참여자\": [\"Reviewers\", \"Area Chair (AC)\"],\n",
    "        \"목표\": \"Rebuttal 기반으로 점수 재평가\",\n",
    "        \"출력\": \"업데이트된 점수 + 의견\",\n",
    "        \"특징\": \"리뷰어들이 서로의 리뷰와 점수를 볼 수 있음\"\n",
    "    },\n",
    "    \"Phase 4: Meta-Review\": {\n",
    "        \"참여자\": [\"Area Chair (AC)\"],\n",
    "        \"목표\": \"전체 리뷰 종합\",\n",
    "        \"출력\": \"Meta-review + 추천 결정\",\n",
    "        \"특징\": \"AC가 모든 정보를 종합하여 판단\"\n",
    "    },\n",
    "    \"Phase 5: Paper Decision\": {\n",
    "        \"참여자\": [\"Area Chair (AC)\"],\n",
    "        \"목표\": \"최종 Accept/Reject 결정\",\n",
    "        \"출력\": \"Accept 또는 Reject\",\n",
    "        \"특징\": \"점수, 리뷰, meta-review 모두 고려\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"5단계 Peer Review 파이프라인 상세\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for phase, details in pipeline_phases.items():\n",
    "    print(f\"\\n{phase}\")\n",
    "    print(\"-\"*50)\n",
    "    for key, value in details.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"  {key}: {', '.join(value)}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 리뷰어 페르소나 시스템\n",
    "\n",
    "AgentReview의 핵심 연구 질문: **리뷰어의 성향이 리뷰 결과에 어떤 영향을 미치는가?**\n",
    "\n",
    "이를 위해 다양한 리뷰어 페르소나를 정의합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 리뷰어 페르소나 속성 분석\n",
    "\n",
    "persona_attributes = {\n",
    "    \"Intention (의도)\": {\n",
    "        \"benign\": \"호의적 - 논문의 장점에 초점, 높은 점수 경향\",\n",
    "        \"malicious\": \"악의적 - 논문의 단점에 초점, 낮은 점수 경향\",\n",
    "        \"BASELINE\": \"중립 - 객관적 평가 시도\"\n",
    "    },\n",
    "    \"Knowledgeability (전문성)\": {\n",
    "        \"knowledgeable\": \"전문가 - 해당 분야 깊은 이해, 기술적 세부사항 평가\",\n",
    "        \"unknowledgeable\": \"비전문가 - 표면적 평가, 기술적 오류 가능\",\n",
    "        \"BASELINE\": \"보통 수준의 전문성\"\n",
    "    },\n",
    "    \"Commitment (책임감)\": {\n",
    "        \"responsible\": \"성실 - 꼼꼼한 리뷰, 건설적 피드백\",\n",
    "        \"irresponsible\": \"불성실 - 짧은 리뷰, 피상적 코멘트\",\n",
    "        \"BASELINE\": \"보통 수준의 성실성\"\n",
    "    },\n",
    "    \"Author Awareness (저자 인지)\": {\n",
    "        \"authors_are_famous\": \"유명 저자로 인식 - 후광 효과 가능\",\n",
    "        \"authors_are_unfamous\": \"무명 저자로 인식 - 편견 가능\",\n",
    "        \"(기본)\": \"저자 정보 모름 (블라인드 리뷰)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"리뷰어 페르소나 속성\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for category, attributes in persona_attributes.items():\n",
    "    print(f\"\\n{category}\")\n",
    "    print(\"-\"*50)\n",
    "    for attr, desc in attributes.items():\n",
    "        print(f\"  {attr:25} : {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: 실제 페르소나 프롬프트 분석\n",
    "\n",
    "# AgentReview의 role_descriptions.py에서 가져온 실제 프롬프트 예시\n",
    "persona_prompts = {\n",
    "    \"benign\": \"\"\"\n",
    "You are a benevolent reviewer who wants to help authors improve their work.\n",
    "You tend to focus on the positive aspects of papers and give constructive feedback.\n",
    "You are more likely to give higher scores to papers that show potential.\n",
    "\"\"\",\n",
    "    \"malicious\": \"\"\"\n",
    "You are a harsh reviewer who is very critical of submitted papers.\n",
    "You tend to focus on the negative aspects and potential flaws.\n",
    "You set very high standards and are more likely to reject papers.\n",
    "\"\"\",\n",
    "    \"knowledgeable\": \"\"\"\n",
    "You are an expert in this field with deep understanding of the technical details.\n",
    "You can evaluate the novelty, correctness, and significance of the contributions.\n",
    "You provide detailed technical feedback based on your expertise.\n",
    "\"\"\",\n",
    "    \"unknowledgeable\": \"\"\"\n",
    "You are not very familiar with this specific research area.\n",
    "You may miss some technical nuances and focus more on presentation quality.\n",
    "Your evaluation may be more surface-level.\n",
    "\"\"\",\n",
    "    \"responsible\": \"\"\"\n",
    "You are a dedicated reviewer who takes the review process seriously.\n",
    "You provide thorough, detailed feedback with specific examples.\n",
    "You suggest concrete improvements and are open to discussion.\n",
    "\"\"\",\n",
    "    \"irresponsible\": \"\"\"\n",
    "You are a busy reviewer who doesn't have much time for this paper.\n",
    "Your reviews tend to be brief and lack specific details.\n",
    "You may not engage deeply with the technical content.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"페르소나별 시스템 프롬프트 예시\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for persona, prompt in persona_prompts.items():\n",
    "    print(f\"\\n[{persona}]\")\n",
    "    print(\"-\"*40)\n",
    "    print(prompt.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: 페르소나 조합 실습\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"페르소나 조합 예시\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 조합 방법: 언더스코어(_)로 연결\n",
    "example_combinations = [\n",
    "    (\"knowledgeable_responsible\", \"전문가이면서 성실한 리뷰어 (이상적)\"),\n",
    "    (\"malicious_unknowledgeable\", \"악의적이면서 비전문가 (최악)\"),\n",
    "    (\"benign_irresponsible\", \"호의적이지만 불성실 (짧은 긍정 리뷰)\"),\n",
    "    (\"knowledgeable_malicious\", \"전문가이지만 악의적 (날카로운 비판)\"),\n",
    "    (\"authors_are_famous\", \"유명 저자라고 인식 (후광 효과)\"),\n",
    "]\n",
    "\n",
    "print(\"\\n조합 방법: 속성들을 '_'로 연결\")\n",
    "print(\"-\"*50)\n",
    "for combo, desc in example_combinations:\n",
    "    print(f\"  '{combo}'\")\n",
    "    print(f\"     -> {desc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. 실험 설정 구성하기\n",
    "\n",
    "AgentReview 실험을 위한 설정 구조를 이해합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: 실험 설정 템플릿\n",
    "\n",
    "# 기본 설정 템플릿\n",
    "experiment_settings = {\n",
    "    \"baseline\": {\n",
    "        \"name\": \"BASELINE\",\n",
    "        \"description\": \"모든 참여자가 중립적\",\n",
    "        \"reviewer\": [\"BASELINE\", \"BASELINE\", \"BASELINE\"],\n",
    "        \"AC\": [\"BASELINE\"],\n",
    "        \"author\": [\"BASELINE\"],\n",
    "        \"global_settings\": {\n",
    "            \"provides_numeric_rating\": [\"reviewer\", \"ac\"],\n",
    "            \"persons_aware_of_authors_identities\": []\n",
    "        }\n",
    "    },\n",
    "    \"malicious_reviewer\": {\n",
    "        \"name\": \"MALICIOUS\",\n",
    "        \"description\": \"악의적 리뷰어 1명 포함\",\n",
    "        \"reviewer\": [\"malicious\", \"BASELINE\", \"BASELINE\"],\n",
    "        \"AC\": [\"BASELINE\"],\n",
    "        \"author\": [\"BASELINE\"],\n",
    "        \"global_settings\": {\n",
    "            \"provides_numeric_rating\": [\"reviewer\", \"ac\"],\n",
    "            \"persons_aware_of_authors_identities\": []\n",
    "        }\n",
    "    },\n",
    "    \"expert_panel\": {\n",
    "        \"name\": \"EXPERT\",\n",
    "        \"description\": \"전문가 패널\",\n",
    "        \"reviewer\": [\"knowledgeable_responsible\", \"knowledgeable\", \"knowledgeable_benign\"],\n",
    "        \"AC\": [\"knowledgeable\"],\n",
    "        \"author\": [\"BASELINE\"],\n",
    "        \"global_settings\": {\n",
    "            \"provides_numeric_rating\": [\"reviewer\", \"ac\"],\n",
    "            \"persons_aware_of_authors_identities\": []\n",
    "        }\n",
    "    },\n",
    "    \"fame_bias_test\": {\n",
    "        \"name\": \"FAME_BIAS\",\n",
    "        \"description\": \"저자 유명도 편향 테스트\",\n",
    "        \"reviewer\": [\"authors_are_famous\", \"authors_are_unfamous\", \"BASELINE\"],\n",
    "        \"AC\": [\"BASELINE\"],\n",
    "        \"author\": [\"BASELINE\"],\n",
    "        \"global_settings\": {\n",
    "            \"provides_numeric_rating\": [\"reviewer\", \"ac\"],\n",
    "            \"persons_aware_of_authors_identities\": [\"Reviewer 1\", \"Reviewer 2\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"실험 설정 템플릿\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for key, setting in experiment_settings.items():\n",
    "    print(f\"\\n[{setting['name']}] {setting['description']}\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"  Reviewers: {setting['reviewer']}\")\n",
    "    print(f\"  AC: {setting['AC']}\")\n",
    "    print(f\"  Author: {setting['author']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. DIY: 나만의 리뷰어 조합 만들기\n",
    "\n",
    "이제 직접 리뷰어 설정을 만들어봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: DIY - 나만의 실험 설정\n",
    "\n",
    "# TODO: 아래 설정을 수정해보세요!\n",
    "\n",
    "my_experiment = {\n",
    "    \"name\": \"MY_EXPERIMENT\",  # <- 실험 이름\n",
    "    \"description\": \"나만의 실험 설정\",  # <- 설명\n",
    "    \n",
    "    # 3명의 리뷰어 설정\n",
    "    # 사용 가능한 속성: benign, malicious, knowledgeable, unknowledgeable,\n",
    "    #                  responsible, irresponsible, authors_are_famous, authors_are_unfamous\n",
    "    # 조합: \"knowledgeable_responsible\", \"malicious_unknowledgeable\" 등\n",
    "    \"reviewer\": [\n",
    "        \"BASELINE\",      # Reviewer 1 - 수정해보세요!\n",
    "        \"BASELINE\",      # Reviewer 2 - 수정해보세요!\n",
    "        \"BASELINE\",      # Reviewer 3 - 수정해보세요!\n",
    "    ],\n",
    "    \n",
    "    \"AC\": [\"BASELINE\"],\n",
    "    \"author\": [\"BASELINE\"],\n",
    "    \n",
    "    \"global_settings\": {\n",
    "        \"provides_numeric_rating\": [\"reviewer\", \"ac\"],\n",
    "        \"persons_aware_of_authors_identities\": []  # 블라인드 리뷰\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"나의 실험 설정\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n실험명: {my_experiment['name']}\")\n",
    "print(f\"설명: {my_experiment['description']}\")\n",
    "print(f\"\\nReviewers:\")\n",
    "for i, r in enumerate(my_experiment['reviewer'], 1):\n",
    "    print(f\"  Reviewer {i}: {r}\")\n",
    "print(f\"\\nAC: {my_experiment['AC'][0]}\")\n",
    "print(f\"Author: {my_experiment['author'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: 실험 아이디어\n",
    "\n",
    "research_questions = [\n",
    "    {\n",
    "        \"question\": \"악의적 리뷰어가 1명 있으면 결과가 얼마나 달라질까?\",\n",
    "        \"setting\": [\"malicious\", \"BASELINE\", \"BASELINE\"],\n",
    "        \"comparison\": [\"BASELINE\", \"BASELINE\", \"BASELINE\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"전문가 리뷰어가 비전문가보다 더 공정할까?\",\n",
    "        \"setting\": [\"knowledgeable_responsible\", \"knowledgeable_responsible\", \"knowledgeable_responsible\"],\n",
    "        \"comparison\": [\"unknowledgeable\", \"unknowledgeable\", \"unknowledgeable\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"유명 저자 효과는 얼마나 클까?\",\n",
    "        \"setting\": [\"authors_are_famous\", \"authors_are_famous\", \"authors_are_famous\"],\n",
    "        \"comparison\": [\"authors_are_unfamous\", \"authors_are_unfamous\", \"authors_are_unfamous\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"불성실한 리뷰어도 rebuttal 후 점수를 바꿀까?\",\n",
    "        \"setting\": [\"irresponsible\", \"irresponsible\", \"irresponsible\"],\n",
    "        \"comparison\": [\"responsible\", \"responsible\", \"responsible\"]\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"실험 아이디어 (연구 질문)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, rq in enumerate(research_questions, 1):\n",
    "    print(f\"\\n{i}. {rq['question']}\")\n",
    "    print(f\"   실험군: {rq['setting']}\")\n",
    "    print(f\"   대조군: {rq['comparison']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. 커스텀 Environment 만들기\n",
    "\n",
    "AgentReview의 구조를 응용하여 나만의 Multi-Agent 환경을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: 커스텀 Environment 템플릿\n",
    "\n",
    "custom_env_template = '''\n",
    "# my_custom_environment.py\n",
    "\n",
    "from agentreview.environments import Environment\n",
    "\n",
    "class MyCustomEnvironment(Environment):\n",
    "    \"\"\"나만의 Multi-Agent 환경\"\"\"\n",
    "    \n",
    "    type_name = \"my_custom_env\"\n",
    "    \n",
    "    def __init__(self, player_names, **kwargs):\n",
    "        super().__init__(player_names=player_names, **kwargs)\n",
    "        \n",
    "        # 환경 상태 초기화\n",
    "        self.current_phase = 0\n",
    "        self.phases = [\"Phase 1\", \"Phase 2\", \"Phase 3\"]\n",
    "        self.message_history = []\n",
    "    \n",
    "    def get_next_player(self):\n",
    "        \"\"\"다음 행동할 플레이어 결정\"\"\"\n",
    "        # 현재 phase에 따라 플레이어 결정\n",
    "        if self.current_phase == 0:\n",
    "            return self.player_names[0]  # 첫 번째 플레이어\n",
    "        elif self.current_phase == 1:\n",
    "            return self.player_names[1]  # 두 번째 플레이어\n",
    "        else:\n",
    "            return None  # 종료\n",
    "    \n",
    "    def step(self, player_name, action):\n",
    "        \"\"\"한 턴 진행\"\"\"\n",
    "        # 1. 메시지 저장\n",
    "        self.message_history.append({\n",
    "            \"player\": player_name,\n",
    "            \"action\": action,\n",
    "            \"phase\": self.phases[self.current_phase]\n",
    "        })\n",
    "        \n",
    "        # 2. 다음 phase로 이동\n",
    "        self.current_phase += 1\n",
    "        \n",
    "        # 3. 종료 조건 확인\n",
    "        done = self.current_phase >= len(self.phases)\n",
    "        \n",
    "        # 4. 다음 플레이어에게 전달할 관찰\n",
    "        observations = {\n",
    "            p: self._get_observation_for_player(p)\n",
    "            for p in self.player_names\n",
    "        }\n",
    "        \n",
    "        return observations, {}, done\n",
    "    \n",
    "    def _get_observation_for_player(self, player_name):\n",
    "        \"\"\"플레이어별 관찰 생성\"\"\"\n",
    "        # 각 플레이어가 볼 수 있는 정보 결정\n",
    "        return f\"Current phase: {self.phases[min(self.current_phase, len(self.phases)-1)]}\"\n",
    "'''\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"커스텀 Environment 템플릿\")\n",
    "print(\"=\"*70)\n",
    "print(custom_env_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: 응용 아이디어\n",
    "\n",
    "application_ideas = [\n",
    "    {\n",
    "        \"name\": \"논문 작성 도우미\",\n",
    "        \"players\": [\"Writer\", \"Critic\", \"Editor\"],\n",
    "        \"phases\": [\"초안 작성\", \"비평\", \"수정\", \"최종 검토\"],\n",
    "        \"description\": \"여러 관점에서 논문을 개선하는 시스템\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"면접 시뮬레이터\",\n",
    "        \"players\": [\"Interviewer\", \"Candidate\", \"Observer\"],\n",
    "        \"phases\": [\"자기소개\", \"기술질문\", \"행동질문\", \"피드백\"],\n",
    "        \"description\": \"면접 연습 및 피드백 시스템\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"디버깅 팀\",\n",
    "        \"players\": [\"Developer\", \"Tester\", \"Reviewer\"],\n",
    "        \"phases\": [\"코드 작성\", \"테스트\", \"리뷰\", \"수정\"],\n",
    "        \"description\": \"코드 품질 개선 시스템\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"연구 아이디어 평가\",\n",
    "        \"players\": [\"Proposer\", \"Devil's Advocate\", \"Supporter\", \"Judge\"],\n",
    "        \"phases\": [\"아이디어 제안\", \"반론\", \"옹호\", \"평가\"],\n",
    "        \"description\": \"연구 아이디어의 강점과 약점 분석\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Multi-Agent 시스템 응용 아이디어\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for idea in application_ideas:\n",
    "    print(f\"\\n[{idea['name']}]\")\n",
    "    print(f\"  설명: {idea['description']}\")\n",
    "    print(f\"  참여자: {' -> '.join(idea['players'])}\")\n",
    "    print(f\"  단계: {' -> '.join(idea['phases'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 실제 실행 (선택사항)\n",
    "\n",
    "**주의: API 비용이 발생합니다!**\n",
    "\n",
    "실제로 AgentReview를 실행하려면:\n",
    "1. OpenAI API 키가 필요합니다\n",
    "2. 각 실행당 약 $0.5-2 정도의 비용이 발생합니다\n",
    "3. 실행 시간은 5-15분 정도 소요됩니다\n",
    "\n",
    "**무료 대안:**\n",
    "- [HuggingFace Demo](https://huggingface.co/spaces/Ahren09/AgentReview)에서 무료로 실험해볼 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: [선택사항] 실제 실행 코드\n",
    "# \n",
    "# 아래 코드는 주석 처리되어 있습니다.\n",
    "# 실행하려면 주석을 해제하고 OpenAI API 키를 설정하세요.\n",
    "# \n",
    "# 비용: 약 $0.5-2 per run\n",
    "# 시간: 약 5-15분\n",
    "\n",
    "'''\n",
    "# 1. API 키 설정\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OpenAI API 키가 필요합니다!\")\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# 2. AgentReview 모듈 로딩\n",
    "import sys\n",
    "sys.path.insert(0, \"agentreview\")\n",
    "\n",
    "from agentreview.environments import PaperReview\n",
    "from agentreview.paper_review_arena import PaperReviewArena\n",
    "from agentreview.paper_review_settings import get_experiment_settings\n",
    "from agentreview.utility.experiment_utils import initialize_players\n",
    "from agentreview.utility.utils import get_paper_decision_mapping\n",
    "from agentreview.arguments import parse_args\n",
    "\n",
    "# 3. 설정\n",
    "sys.argv = [\n",
    "    'notebook',\n",
    "    '--conference', 'ICLR2022',\n",
    "    '--model_name', 'gpt-4o',\n",
    "    '--data_dir', './data',\n",
    "    '--experiment_name', my_experiment['name']\n",
    "]\n",
    "\n",
    "args = parse_args()\n",
    "args.task = \"paper_review\"\n",
    "\n",
    "# 4. 실행\n",
    "paper_id2decision, _ = get_paper_decision_mapping(args.data_dir, args.conference)\n",
    "paper_id = 284  # 샘플 논문 ID\n",
    "\n",
    "experiment_setting = get_experiment_settings(\n",
    "    paper_id=paper_id,\n",
    "    paper_decision=paper_id2decision[paper_id],\n",
    "    setting=my_experiment\n",
    ")\n",
    "\n",
    "players = initialize_players(experiment_setting=experiment_setting, args=args)\n",
    "env = PaperReview(\n",
    "    player_names=[p.name for p in players],\n",
    "    paper_decision=paper_id2decision[paper_id],\n",
    "    paper_id=paper_id,\n",
    "    args=args,\n",
    "    experiment_setting=experiment_setting\n",
    ")\n",
    "\n",
    "arena = PaperReviewArena(players=players, environment=env, args=args)\n",
    "arena.launch_cli(interactive=False)\n",
    "\n",
    "print(\"실행 완료!\")\n",
    "'''\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"실제 실행 코드 (주석 처리됨)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n위 코드의 주석을 해제하면 AgentReview를 실행할 수 있습니다.\")\n",
    "print(\"\\n무료 대안: HuggingFace Demo\")\n",
    "print(\"https://huggingface.co/spaces/Ahren09/AgentReview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. 토론 주제\n",
    "\n",
    "### 연구 질문\n",
    "\n",
    "1. **리뷰어 편향의 영향**\n",
    "   - 악의적 리뷰어 1명이 전체 결과에 미치는 영향은?\n",
    "   - 유명 저자 효과는 얼마나 클까?\n",
    "\n",
    "2. **5단계 파이프라인의 가치**\n",
    "   - Rebuttal이 점수 변화에 얼마나 효과적인가?\n",
    "   - AC 토론이 편향을 줄이는가?\n",
    "\n",
    "3. **실제 활용**\n",
    "   - 논문 투고 전 사전 테스트로 사용할 수 있을까?\n",
    "   - 리뷰어 배정 최적화에 활용할 수 있을까?\n",
    "\n",
    "### 나만의 Agent 만들기\n",
    "\n",
    "1. **어떤 분야에 Multi-Agent 시스템을 적용하고 싶은가?**\n",
    "   - 논문 작성? 코드 리뷰? 면접 연습?\n",
    "\n",
    "2. **어떤 역할(페르소나)이 필요한가?**\n",
    "   - 비평가? 지지자? 중재자?\n",
    "\n",
    "3. **어떤 단계(파이프라인)가 필요한가?**\n",
    "   - 몇 단계? 각 단계에서 무슨 일이 일어나는가?\n",
    "\n",
    "---\n",
    "\n",
    "## 다음 단계\n",
    "\n",
    "1. **HuggingFace Demo 체험**: [AgentReview Demo](https://huggingface.co/spaces/Ahren09/AgentReview)\n",
    "2. **코드 분석**: `agentreview/` 폴더의 소스코드 탐색\n",
    "3. **커스텀 환경 설계**: 위의 템플릿을 기반으로 나만의 환경 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: 워크숍 완료!\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Part 6 완료!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n학습한 내용:\")\n",
    "print(\"  1. Multi-Agent 시스템 아키텍처 (Arena, Environment, Player, Backend)\")\n",
    "print(\"  2. 5단계 Peer Review 파이프라인\")\n",
    "print(\"  3. 리뷰어 페르소나 설계 방법\")\n",
    "print(\"  4. 커스텀 Environment 만들기\")\n",
    "print(\"\\n다음 단계:\")\n",
    "print(\"  - HuggingFace Demo에서 직접 실험해보기\")\n",
    "print(\"  - 나만의 Multi-Agent 시스템 설계하기\")\n",
    "print(\"\\n무료 데모: https://huggingface.co/spaces/Ahren09/AgentReview\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "yejin-venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
