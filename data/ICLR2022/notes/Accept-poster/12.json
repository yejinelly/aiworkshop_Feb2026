{
  "id": "kezNJydWvE",
  "original": "ssOM_oeFhux",
  "number": 12,
  "cdate": 1632875422323,
  "pdate": 1643407560000,
  "odate": 1633539600000,
  "mdate": null,
  "tcdate": 1632875422323,
  "tmdate": 1676330692550,
  "ddate": null,
  "content": {
    "title": "Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring",
    "authorids": [
      "~Seungjun_Nah1",
      "~Sanghyun_Son1",
      "~Jaerin_Lee1",
      "~Kyoung_Mu_Lee2"
    ],
    "authors": [
      "Seungjun Nah",
      "Sanghyun Son",
      "Jaerin Lee",
      "Kyoung Mu Lee"
    ],
    "keywords": [
      "Deblur",
      "Reblur",
      "Loss",
      "Test-time adaptation",
      "Self-supervised"
    ],
    "abstract": "The goal of dynamic scene deblurring is to remove the motion blur in a given image. Typical learning-based approaches implement their solutions by minimizing the L1 or L2 distance between the output and the reference sharp image. Recent attempts adopt visual recognition features in training to improve the perceptual quality. However, those features are primarily designed to capture high-level contexts rather than low-level structures such as blurriness. Instead, we propose a more direct way to make images sharper by exploiting the inverse task of deblurring, namely, reblurring. Reblurring amplifies the remaining blur to rebuild the original blur, however, a well-deblurred clean image with zero-magnitude blur is hard to reblur. Thus, we design two types of reblurring loss functions for better deblurring. The supervised reblurring loss at training stage compares the amplified blur between the deblurred and the sharp images. The self-supervised reblurring loss at inference stage inspects if noticeable blur remains in the deblurred. Our experimental results on large-scale benchmarks and real images demonstrate the effectiveness of the reblurring losses in improving the perceptual quality of the deblurred images in terms of NIQE and LPIPS scores as well as visual sharpness.",
    "one-sentence_summary": "Reblurring, the inverse task of deblurring, is used for supervised/self-supervised learning of deblurring and improves the image sharpness.",
    "code_of_ethics": "",
    "submission_guidelines": "",
    "resubmission": "",
    "student_author": "",
    "serve_as_reviewer": "",
    "paperhash": "nah|clean_images_are_hard_to_reblur_exploiting_the_illposed_inverse_task_for_dynamic_scene_deblurring",
    "pdf": "/pdf/1636f146bd4ebc888881dafbf13129a2072ba805.pdf",
    "supplementary_material": "/attachment/a879a11996948496162b67206db66b6fc0c6357f.zip",
    "data": "",
    "_bibtex": "@inproceedings{\nnah2022clean,\ntitle={Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring},\nauthor={Seungjun Nah and Sanghyun Son and Jaerin Lee and Kyoung Mu Lee},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=kezNJydWvE}\n}",
    "venue": "ICLR 2022 Poster",
    "venueid": "ICLR.cc/2022/Conference"
  },
  "forum": "kezNJydWvE",
  "referent": null,
  "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission",
  "replyto": null,
  "readers": [
    "everyone"
  ],
  "nonreaders": [],
  "signatures": [
    "ICLR.cc/2022/Conference"
  ],
  "writers": [
    "ICLR.cc/2022/Conference"
  ],
  "details": {
    "overwriting": [],
    "tags": [],
    "writable": false,
    "replyCount": 12,
    "directReplyCount": 4,
    "revisions": true,
    "replies": [
      {
        "id": "cFyM46PyPL",
        "original": null,
        "number": 1,
        "cdate": 1635801882709,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635801882709,
        "tmdate": 1635801882709,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This work addresses the problem of image deblurring by training a deep model in an end-to-end fashion. Similar to recent work, the method makes use of large paired (blurry,sharp) training datasets to train the deblurring network.\n\nThe main idea of the work is that a correctly deblurred image should not contain any information about the original blur. The method exploits this observation by using an auxiliary network that tries to re-blur the deblurred image so it has the same blur as the original one. If the deblurred image was perfectly deblurred this shouldn't be possible.\n\nThese two networks end up having a \"similar\" role as a generator-discriminator on a GAN set-up. But even if there's this superficial connection with GANs the formalism is completely different. Here the reblurring network outputs an image that is compared to another image (i.e., reference-based).\n\nThe work introduces three different loss terms: L_blur, L_sharp and L_reblur as long as the typical regression loss L1 between deblurred and sharp images.\n\n- L_blur: is mainly used to train the re-blurring module;\n- L_sharp: is used to avoid the re-blurring module to just apply the average blurring;\n- L_reblur: is used as a regression loss on the space of re-blurred images.\n\nAdditionally, the paper proposes a test time adaptation where the reblurring network is used to boost the deblurring results on a given image. This is done by approximately inverting the re-blurring network using gradient descent. \n\nThe work presents several experiments including ablation studies with two of the popular (synthetic) datasets used in image/video deblurring (GoPro and REDS). Several comparisons with SOTA methods and some results on a real image dataset (Lai et al. 2016). Different quantitative metrics are given (PSNR,SSIM, LPIPS, NIQE) as well as several figures showing visual comparisons.",
          "main_review": "The main idea of the paper is based on an interesting observation. The proposed formulation/implementation seems to take advantage of the observation.\n\nStrengths:\n- The main idea of the paper is interesting and the proposed formulation seems to take advantage of the observation.\n- Empirical results show that the method produces better results than the compared methods\nThe idea of using the re-blurring network to mitigate the out-of-distribution problems seems interesting.\n\nWeaknesses:\n- To implement the idea, the method introduces several loss terms that seem to be needed to avoid degenerate cases and other issues. In this sense, it feels that the formulation could be a little more elegant. The overall idea is that a deblurred image should be close to the target and also shouldn't have information about the original blur. In the end, the whole system seems to be doing this but I wonder if all the components are needed.\n\n- The paper idea seems to be limited to deblurring. But in many parts the paper claims that the ideas are \"applicable to general learning-based approaches\" If this is one of the claims, there needs to be evidence supporting this.\n\n- Analysis. There are many experiments but there's not too much analysis. From the exposition it is hard to claim that the method is actually improving over more classical losses like content loss (vgg loss, as shown in Table 4). So the question is more like if this method is better than simpler approaches? Also, if the issue is remaining blur, can't we just re-iterate the deblurring model till we reach a fixed-point?\n\n\nOther comments:\n\n- \"inherent limitation of PSNR-oriented solutions\" Do you mean the \"regression-to-mean\" problem that happens when we train with reference-based losses? This needs to be better discussed. \n\nThere are other reference based perceptual losses and relevant work that could be added to the overall discussion (not asking for more experiments but this could help improving the related work section):\n\nMechrez, R., Talmi, I., Shama, F. and Zelnik-Manor, L., 2018, December. Maintaining natural image statistics with the contextual loss. In Asian Conference on Computer Vision (pp. 427-443). Springer, Cham.\n\nM. Delbracio, H. Talebei and P. Milanfar,  \"Projected Distribution Loss for Image Enhancement,\" in 2021 IEEE International Conference on Computational Photography (ICCP), Haifa, Israel, 2021\n\nTariq, T., Tursun, O.T., Kim, M. and Didyk, P., 2020, August. Why Are Deep Representations Good Perceptual Quality Features?. In European Conference on Computer Vision (pp. 445-461). Springer, Cham.\n\nCzolbe, S., Krause, O., Cox, I. and Igel, C., 2020. A Loss Function for Generative Neural Networks Based on Watson\u2019s Perceptual Model. Advances in Neural Information Processing Systems, 33.\n\n- Figure 1. This figure is unclear, please include an explanation for what is given on the top and bottom rows for each of the methods.\n\n- \"From a deblurred output, the reblurring module tries to make the reblurred image close to the original\" So in practice this reblurring network is the inverse of the deblurring module. Why not present this module in this way?\n\n- Writing is a little disorganized. For example in the introduction when referring to the \"reblurring loss\" it is unclear what is \"the difference\" that is mentioned. One of the listed contribution depends on this \"reblurring loss\" so this needs to be better explained in the introduction.\n\n- The need for the pseudo-sharp image \\hat{S}. The argument for using \\hat{S} and not S seems to be rather empirical so this should be supported by evidence. In the current presentation there's a lot of emphasis on measuring sharpness but not realism, but then later for evaluating the quality perceptual metrics such as LPIPS and NIQE are used. So, there seems to be a mismatch between what is claimed and what is actually happening. \n\n- The test-time adaptation inverts the re-blurring network. This needs more analysis in terms of: \nWhat happens if we minimize this loss (gradient descent till convergence)? How many gradient descent steps are needed. This is not discussed much in the paper and I found it to be an interesting contribution. It will be also helpful to show cross-datasets performances (trained with GoPro and evaluated with a different dataset, e.g. HIDE, Real-Blur or REDS).\n\n- Perceptual Distortion tradeoff. The perceptual distortion trade-off balances a reference based metric against a non-reference metric (e.g., distance to the natural image manifold). PSNR and LPIPS are both reference based metrics so it doesn't make sense (formally) to refer to this type of plot as a distortion-perception trade-off. Maybe the plot should be made with NIQE instead of LPIPS.\n",
          "summary_of_the_review": "This paper introduces an interesting idea for improving image deblurring models: the deblurred image should not contain information/traces about the original blur.  This is a bold statement. The paper crystalizes this idea using two networks (deblurring and re-blurring network) that are co-trained with different loss terms. The implementation seems (a little) too complex with many terms that try to avoid different types of artifacts/degenerative cases. But in the end this seems like a valid implementation of the initial idea. The current analysis didn't convince me that the method is doing much better or better than other methods that just compare the restored and sharp images on a pre-computed feature space (is this a matter of tuning the contributions of each loss term?). I think the paper needs to better discuss and analyze this. Additionally, the idea seems to be specific for dealing with blur. Can the same idea apply to other (restoration) tasks?",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_oSPE"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_oSPE"
        ]
      },
      {
        "id": "4HmAhN7fbtS",
        "original": null,
        "number": 2,
        "cdate": 1635841243433,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635841243433,
        "tmdate": 1635841243433,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Review",
        "content": {
          "summary_of_the_paper": "A novel deblurring method is proposed by introducing the concept of reblurring loss. Conventional techniques deblur blurry images to some extent however there are some unremoved blur contents, where it can be used to reconstruct (reblur) blurry images. On the other hand, cleanly deblurred images have only sharp contents and it is difficult to reblur the images since no blurry cues are left. By using such observation, a reblurring module and a deblurring module with reblurring loss are proposed. Experimental results show that the proposed framework outperforms SOTA quantitatively and qualitatively on the GOPRO and REDS dataset. ",
          "main_review": "1. Technical novelty\nThe observation that the \"clean images are hard to reblur\" is quite novel. \nFollowing the observation, the proposed reblurring loss is logical and experimental results are consistent. \nI'm concerned that the concept of deblur-reblur is similar to the GANs, but the authors well addressed the issue in the introduction. \n\n2. Writing\nOverall it is well-written and easy to read. However, more proofreading and re-arranging figures are needed before publication. \nIn Figure 1, the sharp image (supposed to be ground truth) and deblurred images are located in the top row. It may be a reasonable arrangement since they are seemingly similar. However since they have different meanings, there should be a better arrangement for easier understanding. \nReaders may be familiar with the blurry and deblurred image, but not the reblurred image since it is quite a new concept. So additional figures explaining and emphasizing such concepts would help the understanding. \nIn Figure 2, there are B and S in both of Figure 2 (a) and (b), where the arrangement is somewhat confusing. \nTable 1 is mentioned just below the equation (1) but there is no explanation about M_D before Table 1. \n\n3. Experimental results\nExperimental results improve SOTA in perceptual measures such as LPIPS and NIQE. However, it did not improve PSNR and SSIM, which gives the impression that the deblurred image may distort the original image and obtain better perceptual measures by sharpening. ",
          "summary_of_the_review": "The paper introduces an interesting observation and proposes novel modules based on the observation where the development is very logical. Overall, the paper is easy to read, however more proofreading is required. Experimental results improve the SOTA but there should be justification for some results. ",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_M9xc"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_M9xc"
        ]
      },
      {
        "id": "Rezub_FSUIe",
        "original": null,
        "number": 3,
        "cdate": 1635970192165,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635970192165,
        "tmdate": 1638211971241,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposes a novel approach to using deep networks for image deblurring. Since training with simply reconstruction losses usually leads to oversmoothed results, recent works have looked at using perceptual and adversarial losses.\n\nThe paper proposes an approach similar to an adversarial loss. If an image is not de-blurred entirely, it leaves within itself some tell-tale signs of the original blur. The paper proposes learning a \u201creblurring\u201d network that given a \u201cdeblurred\u201d image should yield the original \u201cblurry\u201d image, while given a true sharp image should output the image itself. The deblurring network is then trained in a sense to fool the re-blurring network, by generating images that would be left untouched by the reblurring network. The paper also proposes a \u201ctest time adaptation\u201d approach.",
          "main_review": "This is an interesting idea. For the task of deblurring, it represents a logical and novel formulation of the \u201cadversary\u201d: rather than just saying whether the input is truly sharp or the output of a deblurring network, the reblurring network has to reproduce the original blurry image in the latter case.\n\nWhile the results are encouraging, there are a number of issues with the paper:\n\nThe paper needs to do a much better job in clearly and systematically establishing the benefit of the proposed method against a standard adversarial loss and other perceptual losses (which are much simpler and more straightforward than the proposed reblurring loss). In particular, the efficacy of the network WITHOUT test-time adaptation should be established. This is because TTA is expensive, and it is not clear whether other methods couldn\u2019t also be improved with TTA (for example, those based on standard adversarial losses) or by just having slower but deeper networks.\n\nTable 4 seems to suggest minimal additional benefit of the reblur loss (without TTA). There is some benefit in NIQE, none in LPIPS, and PSNR and SSIM get worse. This comparison is also to a specific weight on the adversarial loss. Did the authors sweep for different loss weights to find the optimal one for training only with an adversarial (+ VGG) loss? This is what I mean by a systematic evaluation: the paper should find the optimal hyperparameters for training with only a regular adversarial loss and compare to the optimal setting for the proposed method \u2014 without TTA and using a comparable architecture for the discriminator as the proposed MR.\n\n\nThe paper also needs more comprehensive results reported for comparisons to state-of-the-art. There are no quantitative results, and the qualitative results are only with TTA. Visually, the improvement of the proposed method with TTA over DeblurGAN is relatively small. It would be natural to wonder if that improvement disappears without TTA, and if infact, the proposed method does worse than DeblurGAN. As noted, TTA is expensive, and an orthogonal approach that could potentially be applied to other adversarially trained deblurring networks.\n\nThe paper, especially the introduction, could be a lot clearer in explaining the basic idea. Figure 1 is great in terms of layout, but the captions / legend is not informative making it very unintuitive.  The caption should at the very least explain what L, S, \\hat{S}, and B are without having readers to dig through the text in section 3. The \u201cshared\u201d is confusing \u2014 one would anyway assume that all M_R\u2019s are the same, but the fact there\u2019s shared lines only among pairs on the left and right makes us question if the two pairs are different from each other. Having (a) and (b) in Figure 1 with the corresponding headings is also confusing. They each respectively describe the training loss for M_R and M_D, and if I understand correctly, each iteration involves doing an update step of each. This does not come across from the figure. And finally, some more details of the test-time adaptation should be included in the main paper. Most of the text in the main paper in that section gives \u201cintuition\u201d \u2014 but is very confusing to read since the reader doesn\u2019t know exactly what is being optimized and what is being updated (image or network weights).\n\n\nA lot of the explanations in the paper are very hand-wavy, and not at all clear to the reader. This is especially true about the use of a pseudo sharp image instead of a sharp image: for example, I don\u2019t understand what the authors mean by \u201cIn contrast to S that differ from the deblurred image L by the realness, \\hat{S} can avoid being MR distracted by such an unintentional difference, focusing on image sharpness.\u201d I\u2019m actually not sure why using S-hat doesn\u2019t just cause a degenerate solution where MD produces oversmoothed outputs all the time to prevent MR from figuring out if the original image was blurry or not.",
          "summary_of_the_review": "Given the issues with the experiments and presentation above, I don't think the paper is ready for publication.\n\n### Post-rebuttal\n\nIncreasing score from reject to borderline/marginal  reject. I think the paper still needs a bit more work, but would not object to it being accepted. Please see detailed comment in response to rebuttal below.",
          "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "Not applicable",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_Gxxe"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_Gxxe"
        ]
      },
      {
        "id": "BSfFp-I-79X",
        "original": null,
        "number": 2,
        "cdate": 1636881303038,
        "mdate": 1636881303038,
        "ddate": null,
        "tcdate": 1636881303038,
        "tmdate": 1636881303038,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "cFyM46PyPL",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer oSPE",
          "comment": "We thank reviewer **oSPE** for the detailed comments and suggestions.\nPlease find our answers below.\n\n- The need for all components\n\nOur method indeed can work without sharpness the preservation loss term, too.\nHowever, as shown in Table 3, LPIPS and NIQE are better with sharpness preservation.\n\n- Applicability to general tasks\n\nWe originally meant that our method is \"applicable to general learning-based approaches **for deblurring**.\"\nWe added 'for deblurring' for clarification.\n\nIn principle, our method works as **blurring a clean image** is an ill-posed problem with many possible motion trajectories.\nSimilarly, **noising a clean image** is another ill-posed problem as finding a specific noise is difficult.\nFor example, there are many noise realizations under a white Gaussian noise assumption. (In practice, noise distribution has to be found, too.)\nThus, we expect this method could be applied in denoising problems, too (clean images are hard to renoise) and considering it as future work.\n\n- Benefits of reblurring loss over other losses & iterative deblurring\n\nIn Table 4, we show the effect of our *supervised reblurring loss without TTA* and other losses when PSNR and SSIM are at similar levels.\n\nCompared with VGG loss, *supervised reblurring loss* improves NIQE by -0.058 while having a decreased PSNR by -0.03 dB which is small considering the scales between NIQE and PSNR.\nCompared with adversarial loss, *supervised reblurring loss* improves all 4 metrics, LPIPS, NIQE, PSNR, SSIM.\n\nAlso, in contrast to VGG loss and adversarial loss, our reblurring module enables self-supervised test-time adaptation.\nWhile GAN frameworks can try a similar approach with the discriminator, we didn't find good results in our experiments.\nOptimizing the deblurring module to fool discriminators at test-time caused several artifacts and content distortion.\n\nAlso, iterative deblurring is also a valid idea as studied in (Park et al., 2020) by proposing a recurrent model architecture.\nOn the other hand, in this work, we proposed loss functions to optimize a model rather than proposing a specific architecture.\nLoss function is an independent component of deep learning as well as the model architecture.\nComparing the effect of a loss function and a model architecture is beyond the scope of this paper.\nStill, it is possible to use our reblurring loss to the iterative deblurring framework, too.\n\n- The expression, \"inherent limitation of PSNR-oriented solutions\"\n\nYes, we mean the \"regression-to-mean\" problem and we thank **oSPE** for suggesting a simple and clear expression to improve the exposition.\nWe changed the sentence as:  \n\"Still, most methods tend to suffer from the blurry predictions due to the regression-to-mean behavior often witnessed in ill-posed problems with large solution space.\"\n\n- Additional references\n\nWe thank **oSPE** for the suggestion to make the related works section richer.\nWe included the papers in our related works section.\n\n- Figure 1 clarity\n\nWe changed captions and added arrows to clarify Figure 1.\n\n- Presenting reblurring as the inverse of deblurring\n\nWe changed the sentence to:  \n\"From a deblurred output, the reblurring module performs the inverse operation of deblurring, trying to reconstruct the original blurry image.\"\n\n- Clarifying \"the difference\"\n\nWe changed the sentence as:  \n\"We propose to use the difference between non-ideally deblurred image and the ideal sharp image in terms of reblurring feasibility \nas the new optimization objective, \\emph{reblurring loss} for the image deblurring problem.\"\n\n- Need for pseudo-sharp image\n\nWe used \\hat{S} for training purposes, not for evaluation.\nAs \\hat{S} is an output from M_D that is trained by ourselves, measuring the fidelity of the deblurred results with \\hat{S} is not very desirable.\nEspecially, \\hat{S} from every different experiment would be different as M_D is trained with different loss functions.\nAlso, we would like to note that NIQE is a no-reference metric that does not use ground truth for evaluation.\n\nInstead, to provide clearer explanation, in Section 4.2, we added the following sentences:  \nFor neural networks, it is very easy to discriminate real and fake images (Wang et al., 2020).\nBy using a fake image \\hat{S} instead of a real image S, we let M_R focus on the sharpness of an image and avoid being distracted by a more obvious difference between real and fake images.\n\n- Test-time adaptation analysis\n\nIn Figures 6, 11 and 12, we show the effect of test-time adaptation at each step.\nEach step improves LPIPS and NIQE while PSNR and SSIM is sacrificed, showing a typical trade-off between perception-distortion metrics. (Blau & Michaeli, 2018; Blau et al., 2018)\n\nWe will show additional cross-dataset experiments later.\n\n- Perception-Distortion tradeoff\n\nIn Figure 6, the dashed lines indicate NIQE, the corresponding y-axis shown on the right.\nIn Appendix section F, the relation between NIQE with respect to PSNR and SSIM are shown.\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ]
      },
      {
        "id": "OEvlgAy_8Ie",
        "original": null,
        "number": 3,
        "cdate": 1636881338555,
        "mdate": 1636881338555,
        "ddate": null,
        "tcdate": 1636881338555,
        "tmdate": 1636881338555,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "4HmAhN7fbtS",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer M9xc",
          "comment": "We thank **M9xc** for the valuable comments to improve the paper and exposition.\nHere are our answers.\n\n- Figure 1.\n\nWe changed Figure 1 for clarification.\n\nWe marked the blur and sharp images with bold text with the word 'True.'\nWe changed the label of our deblurred image from 'Ours' to 'Ours (Deblurred)'\nWe added arrows between the deblurred and the reblurred images to show that reblurring is generated from the deblurred images.\n\n- Figure 2.\n\nTo avoid confusion, we put a vertical line between (a) and (b).\nWe also put a more detailed description in the caption.\n\n- Table 1.\n\nWe now refer to the deblurring module as: deblurring module $\\mathcal{M}_{\\text{D}}$\n\n- Perception-distortion trade-off\n\nOur method focuses on image sharpness by proposing a new type of perceptual loss.\nIt is typical that applying perceptual losses essentially brings the gains in the perceptual metrics at the cost of PSNR.\nSuch perception-distortion trade-off relation has been witnessed in general image restoration literature (Blau & Michaeli, 2018; Blau et al., 2018).  \n\nThus, our goal is to improve the trade-off between perception and distortion.\nIn Table 4, we show that LPIPS and NIQE is better than other perceptual losses when PSNR and SSIM are in similar levels.\n\nAlso, in Appendix Table 8, we show that for SRN and DHN, when the reblurring module is small (1 ResBlock), PSNR and SSIM remain at a similar level or improve.\nIt means that while the trade-off relation essentially cannot be avoided, however, our trade-off itself is improved from the baseline.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ]
      },
      {
        "id": "w1Ly_o18yS-",
        "original": null,
        "number": 4,
        "cdate": 1636881371418,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636881371418,
        "tmdate": 1636956041650,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "Rezub_FSUIe",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer Gxxe",
          "comment": "We thank **Gxxe** for finding our idea to be interesting and providing valuable comments.\nWe tried our best to answer the questions.\n\n- Benefits and efficacy of reblurring loss without test-time adaptation\n\nWhile we show and compare the effect on the quantitative metrics **without test-time adaptation** in Table 4, we note that the **different perceptual losses (VGG loss, adversarial loss, and our reblurring loss) play different roles and do not compete with each other**.\nFor example, adversarial loss makes image realistic, and our reblurring loss focuses on reducing motion blur.\nThus, we propose our reblurring loss as a new perceptual loss with different behavior from the others.\nReblurring loss can work together with the other loss terms rather than replacing them.  \nIn Appendix Tables 9 and 10, we show the effect of the joint perceptual loss terms further improves LPIPS and NIQE.\n\nWe would like to note that test-time adaptation is possible from our reblurring module, but not very easily with adversarial loss.\nWe tried TTA with adversarial loss in a similar manner as ours (by optimizing the deblurring module to fool discriminator).\nIn our experiments, we did not find any good results.\nTest-time adaptation with discriminator caused various artifacts, content distortion, etc.\nWe believe test-time adaptation with adversarial loss is another research topic to be studied but beyond the scope of this work.\n\nDeblurring quality improves with deeper networks, however, if optimized with L1, VGG, or adversarial loss terms, they essentially leave the blur footprint behind.\nIn Figure 1, we show that heavier network (SE-Sharing) or the model trained with VGG and adversarial loss (DeblurGANv2) do not remove blur completely.\n\n- Table 4 results\n\nIn Table 4, we compared the reblurring loss with VGG loss and adversarial loss.\nWe chose the loss weights so that the PSNR and SSIM are in a similar level to compare the effect on LPIPS and NIQE.\nCompared with VGG loss, reblurring loss improves NIQE by -0.058 while having a decreased PSNR by -0.03 dB which is small considering the scales between NIQE and PSNR.\nCompared with adversarial loss, reblurring loss improves all 4 metrics, LPIPS, NIQE, PSNR, SSIM.\n\nWe will report additional results with different loss weights.\n\nHere are the number of parameters used to construct each perceptual loss:\n\ntype | #params\n:--- | ---:\nVGG | 20,024,384\nDiscriminator | 1,616,224\nReblurring module (2 Resblocks) | 419,200\n\n- Comparisons\n\nAs our contribution is the way to optimize deblurring networks, we do not intend to directly compare our result with the other architecture's results.\nWe presented quantitative comparisons on various architectures (UNet, SRN, DHN) by applying our loss function to them.\nIn Figure 7, we show that our 1) the car plate numbers are much cleaner and 2) the pinkle and the ring fingers are better separated than the deblurred image of DeblurGAN-v2.\n\nWe primarily compare the effect of the adversarial loss (major loss function of DeblurGAN-v2) and the **reblurring loss without TTA** in Figure 4. It shows that c-pillar of the car and the red bar is better recovered by reblurring loss without TTA.\n\n- Introduction\n\nWe changed the captions of Figure 1 and added arrows.\nIn Figure 2, we included explanation of each term and the overall behavior.\nWe removed the 'shared' mark and the dashed lines.\n\n- Test-time adaptation explanation\n\nIn Section 3.3 page 4, we put a new sentence to clarify that the model weights are being updated:  \nWe optimize the weights of M_D with fixed M_R.\n\nWe added the pointer to Algorithm 1 in the Appendix by changing the sentence:\nplease refer to the Appendix -> please refer to the Appendix Algorithm 1.\n\n- Pseudo-sharp image\n\nFor neural networks, **discriminating a fake image from a real image is very easy** (Wang et al., 2020).  \nIn blur reconstruction loss (eq 1), we used L=M_D(B), **a fake image** generated by M_D, as an input to M_R.  \nIn sharpness preservation loss (eq 2), we use a pseudo-sharp image \\hat{S}=M_D(S), **another fake image**, as an input to M_R.  \nWe intend to use both loss terms to let M_R learn to behave differently **by finding the blurriness of an image, not by discriminating real and sharp images**.  \nIf we use a real image S in (eq 2), M_R could learn to discriminate L and S as a fake and a real image without having to check the blurriness.\n\nTherefore, we updated Section 4.2 in our main manuscript as follows, for clarification:  \nFor neural networks, it is very easy to discriminate real and fake images (Wang et al., 2020).\nBy using a fake image \\hat{S} instead of a real image S, we let M_R focus on the sharpness of an image and avoid being distracted by a more obvious difference between real and fake images.\n\n\\hat{S} does not cause a degenerate solution as M_D learns to deblur a blurry image.\nIf \\hat{S} is oversmoothed (blurry), then L would be even more blurrier than B and that will be penalized by the L1 loss function, |L - S|.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ]
      },
      {
        "id": "Ivj-h3Is7CM",
        "original": null,
        "number": 5,
        "cdate": 1637475858421,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637475858421,
        "tmdate": 1637478291012,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "w1Ly_o18yS-",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Perceptual loss weight sweep experiment (extending Table 4)",
          "comment": "We further report the extended results for Table 4 with additional loss weight experiments.\nAs we remarked before, we compared the effects on LPIPS and NIQE of each perceptual loss when PSNR and SSIM are at similar levels.\n\n**Bold** numbers are the original numbers reported in Table 4, **_bold italic_** numbers are for the adversarial loss with a higher PSNR and SSIM.\nAs shown below, reblurring loss provides better LPIPS and NIQE than VGG loss or adversarial loss.\nStill, we would like to note that different loss terms are not essentially competing with each other and could be used jointly.\nPlease refer to Tables 9 and 10 in the Appendix for the effect of combined loss terms.\n\nmodel architecture: SRN\n\nloss | loss weight ($\\lambda$) | LPIPS | NIQE | PSNR | SSIM\n--- | :---: | --- | --- | --- | --- |\nL1 | - | **0.1246** | **5.252** | **30.62** | **0.9078**\nL1 + $\\lambda$ VGG | 0.1 | 0.1133 | 5.151 | 30.55 | 0.9070\nL1 + $\\lambda$ VGG | 0.3 | **0.1037** | **4.945** | **30.60** | **0.9074**\nL1 + $\\lambda$ VGG | 0.5 | 0.1030 | 4.903 | 30.56 | 0.9066\nL1 + $\\lambda$ VGG | 1.0 | 0.1000 | 4.819 | 30.45 | 0.9044\nL1 + $\\lambda$ Adv | 0.0001 | 0.1239 | 5.264 | 30.62 | 0.9078\nL1 + $\\lambda$ Adv | 0.0003 | **_0.1183_** | **_5.146_** | **_30.60_** | **_0.9079_**\nL1 + $\\lambda$ Adv | 0.001 | **0.1141** | **4.960** | **30.53** | **0.9068**\nL1 + $\\lambda$ Adv | 0.003 | 0.1123 | 4.877 | 30.52 | 0.9066\nL1 + $\\lambda$ Adv | 0.01 | 0.1040 | 4.605 | 30.50 | 0.9052\nL1 + $\\lambda$ Reblur (n1) | 1.0 | 0.1140 | 5.136 | 30.74 | 0.9104\nL1 + $\\lambda$ Reblur (n1) | 0.5 | 0.1138 | 5.158 | 30.68 | 0.9094\nL1 + $\\lambda$ Reblur (n2) | 1.0 | **0.1037** | **4.887** | **30.57** | **0.9074**\nL1 + $\\lambda$ Reblur (n2) | 0.5 | *0.1034* | *4.772* | *30.55* | *0.9075*\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ]
      },
      {
        "id": "rC6dU1ABiu",
        "original": null,
        "number": 6,
        "cdate": 1637605536063,
        "mdate": 1637605536063,
        "ddate": null,
        "tcdate": 1637605536063,
        "tmdate": 1637605536063,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "BSfFp-I-79X",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Test-Time Adaptation Analysis (more steps & cross-dataset experiments)",
          "comment": "We thank **oSPE** for suggesting valuable analysis.  \n\n* Further TTA iterations\n\nWe performed experiments with TTA for up to 30 steps on GOPRO dataset with SRN model.  \nFor both reblurring module size 1 and 2, LPIPS, a reference-based metric, did not improve beyond a certain limit.\nOn the other hand, NIQE, a no-reference metric, continued to improve.  \nWe witnessed oversharpening artifacts after many TTA steps which lead to deviation from the soft texture in GT scenes, however, with clearer edges.\nThis is due to our self-supervised reblurring loss (that enables TTA) focusing on the sharpness of an image without referring to GT.\n\nWe visually show the effect of TTA at more steps in the Appendix, Figures 13 and 14.\n\nloss | TTA steps | LPIPS | NIQE | PSNR | SSIM | loss | TTA steps | LPIPS | NIQE | PSNR | SSIM\n--- | :---: | --- | --- | --- | --- | --- | :---: | --- | --- | --- | --- \nL1 (baseline) | - | **0.1246** | **5.252** | 30.62 | 0.9078 | L1 (baseline) | - | **0.1246** | **5.252** | 30.62 | 0.9078\nL1 + Reblur (n1) | 0 | 0.1140 | 5.136 | 30.74 | 0.9104 | L1 + Reblur (n2) | 0 | 0.1037 | 4.887 | 30.57 | 0.9074\nL1 + Reblur (n1) | 5 | **0.1101** | 5.079 | 30.60 | 0.9100 | L1 + Reblur (n2) | 5 | 0.0983 | 4.730 | 30.44 | 0.9067\nL1 + Reblur (n1) | 10 | 0.1103 | 5.036 | 30.11 | 0.9048 | L1 + Reblur (n2) | 10 | **0.0962** | 4.569 | 30.07 | 0.9024\nL1 + Reblur (n1) | 20 | 0.1223 | 4.968 | 28.44 | 0.8806 | L1 + Reblur (n2) | 20 | 0.1021 | 4.274 | 28.83 | 0.8836\nL1 + Reblur (n1) | 30 | 0.1470 | **4.924** | 26.42 | 0.8411 | L1 + Reblur (n2) | 30 | 0.1199 | **4.045** | 27.26 | 0.8529\n\n* Cross-dataset adaptation\n\nWe performed cross-dataset adaptation experiments with the SRN model by training on REDS and testing on GOPRO.  \nSimilar to single-dataset experiments, LPIPS stopped improving after a certain point while NIQE consistently improved.\n\nloss | TTA steps | LPIPS | NIQE | PSNR | SSIM | loss | TTA steps | LPIPS | NIQE | PSNR | SSIM\n--- | :---: | --- | --- | --- | --- | --- | :---: | --- | --- | --- | --- \nL1 (baseline) | - | **0.1442** | **5.059** | 28.37 | 0.8796 | L1 (baseline) | - | **0.1442** | **5.059** | 28.37 | 0.8796\nL1 + Reblur (n1) | 0 | **0.1386** | **4.991** | 28.48 | 0.8834 | L1 + Reblur (n2) | 0 | **0.1296** | **4.105** | 27.95 | 0.8763\nL1 + Reblur (n1) | 1 | 0.1376 | 4.981 | 28.46 | 0.8843 | L1 + Reblur (n2) | 1 | 0.1291 | 4.074 | 27.91 | 0.8766\nL1 + Reblur (n1) | 2 | 0.1369 | 4.967 | 28.42 | 0.8842 | L1 + Reblur (n2) | 2 | 0.1289 | 4.041 | 27.84 | 0.8759\nL1 + Reblur (n1) | 3 | 0.1364 | 4.954 | 28.35 | 0.8837 | L1 + Reblur (n2) | 3 | **0.1290** | 4.009 | 27.76 | 0.8749\nL1 + Reblur (n1) | 4 | 0.1359 | 4.943 | 28.29 | 0.8835 | L1 + Reblur (n2) | 4 | 0.1291 | 3.977 | 27.68 | 0.8740\nL1 + Reblur (n1) | 5 | **0.1356** | **4.932** | 28.23 | 0.8833 | L1 + Reblur (n2) | 5 | 0.1295 | **3.946** | 27.60 | 0.8731\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ]
      },
      {
        "id": "_Uj4hsq-OB",
        "original": null,
        "number": 8,
        "cdate": 1637783881695,
        "mdate": 1637783881695,
        "ddate": null,
        "tcdate": 1637783881695,
        "tmdate": 1637783881695,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "rC6dU1ABiu",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Final comments.",
          "comment": "Thank you for the response. \n\nThe authors' responses and the updated version of the manuscript helped to address some of the raised issues. I think this paper introduces and exploits a valid and interesting idea. Presentation and analysis has been improved in the revised version. Nonetheless, there's still room for improvement: there are multiple things presented: multiple loss terms, test-time adaptation, etc; and it's hard to make a consistent/full analysis with a clear understanding of all the pieces. I also tend to agree with reviewer Gxxe  observation *\"A lot of the explanations in the paper are very hand-wavy, and not at all clear to the reader.\"*. \n\nTo summarize. This work introduces an interesting idea exemplified (implemented) in a *reasonable* way. There could be other/better ways of exploiting this idea, but the idea itself (no remaining blur on restored image) is interesting. I'm advocating for acceptance of this paper.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_oSPE"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_oSPE"
        ]
      },
      {
        "id": "1cDjStl8DTy",
        "original": null,
        "number": 9,
        "cdate": 1638154330004,
        "mdate": 1638154330004,
        "ddate": null,
        "tcdate": 1638154330004,
        "tmdate": 1638154330004,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "_Uj4hsq-OB",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Final response to oSPE",
          "comment": "We thank **oSPE** for the thoughtful comments throughout the review and for acknowledging our idea to be valid and interesting.  \nWe will do our best to further improve the exposition and provide better analysis and clarification on the role of each component.\n\nBest,  \nAuthors"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Authors"
        ]
      },
      {
        "id": "oRrmV75cYus",
        "original": null,
        "number": 12,
        "cdate": 1638246913850,
        "mdate": 1638246913850,
        "ddate": null,
        "tcdate": 1638246913850,
        "tmdate": 1638246913850,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "OEvlgAy_8Ie",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Comment",
        "content": {
          "title": "Thanks for the rebuttal",
          "comment": "All concerns in the review are well-address in the revised version, including adjusting figures and proofreading!"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_M9xc"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_M9xc"
        ]
      },
      {
        "id": "Ba1h0ZlPAZ0",
        "original": null,
        "number": 1,
        "cdate": 1642696833201,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696833201,
        "tmdate": 1642696833201,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Accept (Poster)",
          "comment": "The paper introduces an idea that was found interesting by all reviewers (including Gxxe who recommends a marginal reject). A majority of the reviewers also point out a few weaknesses of the paper, notably in terms of clarity of several statements that were found to be hand-wavy (see the reviews of Gxxe and oSPE for more precise details). The area chair agrees with those statements, but overall, the originality of the idea introduced in this paper outweighs these weaknesses, and the experimental study is conducted in a reasonably convincing manner.\n\nEven though there is room for improvements, the area chair is happy to recommend an accept, but encourages the authors to follow the constructive feedback provided by the reviewers for the camera-ready version."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "directReplies": [
      {
        "id": "cFyM46PyPL",
        "original": null,
        "number": 1,
        "cdate": 1635801882709,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635801882709,
        "tmdate": 1635801882709,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This work addresses the problem of image deblurring by training a deep model in an end-to-end fashion. Similar to recent work, the method makes use of large paired (blurry,sharp) training datasets to train the deblurring network.\n\nThe main idea of the work is that a correctly deblurred image should not contain any information about the original blur. The method exploits this observation by using an auxiliary network that tries to re-blur the deblurred image so it has the same blur as the original one. If the deblurred image was perfectly deblurred this shouldn't be possible.\n\nThese two networks end up having a \"similar\" role as a generator-discriminator on a GAN set-up. But even if there's this superficial connection with GANs the formalism is completely different. Here the reblurring network outputs an image that is compared to another image (i.e., reference-based).\n\nThe work introduces three different loss terms: L_blur, L_sharp and L_reblur as long as the typical regression loss L1 between deblurred and sharp images.\n\n- L_blur: is mainly used to train the re-blurring module;\n- L_sharp: is used to avoid the re-blurring module to just apply the average blurring;\n- L_reblur: is used as a regression loss on the space of re-blurred images.\n\nAdditionally, the paper proposes a test time adaptation where the reblurring network is used to boost the deblurring results on a given image. This is done by approximately inverting the re-blurring network using gradient descent. \n\nThe work presents several experiments including ablation studies with two of the popular (synthetic) datasets used in image/video deblurring (GoPro and REDS). Several comparisons with SOTA methods and some results on a real image dataset (Lai et al. 2016). Different quantitative metrics are given (PSNR,SSIM, LPIPS, NIQE) as well as several figures showing visual comparisons.",
          "main_review": "The main idea of the paper is based on an interesting observation. The proposed formulation/implementation seems to take advantage of the observation.\n\nStrengths:\n- The main idea of the paper is interesting and the proposed formulation seems to take advantage of the observation.\n- Empirical results show that the method produces better results than the compared methods\nThe idea of using the re-blurring network to mitigate the out-of-distribution problems seems interesting.\n\nWeaknesses:\n- To implement the idea, the method introduces several loss terms that seem to be needed to avoid degenerate cases and other issues. In this sense, it feels that the formulation could be a little more elegant. The overall idea is that a deblurred image should be close to the target and also shouldn't have information about the original blur. In the end, the whole system seems to be doing this but I wonder if all the components are needed.\n\n- The paper idea seems to be limited to deblurring. But in many parts the paper claims that the ideas are \"applicable to general learning-based approaches\" If this is one of the claims, there needs to be evidence supporting this.\n\n- Analysis. There are many experiments but there's not too much analysis. From the exposition it is hard to claim that the method is actually improving over more classical losses like content loss (vgg loss, as shown in Table 4). So the question is more like if this method is better than simpler approaches? Also, if the issue is remaining blur, can't we just re-iterate the deblurring model till we reach a fixed-point?\n\n\nOther comments:\n\n- \"inherent limitation of PSNR-oriented solutions\" Do you mean the \"regression-to-mean\" problem that happens when we train with reference-based losses? This needs to be better discussed. \n\nThere are other reference based perceptual losses and relevant work that could be added to the overall discussion (not asking for more experiments but this could help improving the related work section):\n\nMechrez, R., Talmi, I., Shama, F. and Zelnik-Manor, L., 2018, December. Maintaining natural image statistics with the contextual loss. In Asian Conference on Computer Vision (pp. 427-443). Springer, Cham.\n\nM. Delbracio, H. Talebei and P. Milanfar,  \"Projected Distribution Loss for Image Enhancement,\" in 2021 IEEE International Conference on Computational Photography (ICCP), Haifa, Israel, 2021\n\nTariq, T., Tursun, O.T., Kim, M. and Didyk, P., 2020, August. Why Are Deep Representations Good Perceptual Quality Features?. In European Conference on Computer Vision (pp. 445-461). Springer, Cham.\n\nCzolbe, S., Krause, O., Cox, I. and Igel, C., 2020. A Loss Function for Generative Neural Networks Based on Watson\u2019s Perceptual Model. Advances in Neural Information Processing Systems, 33.\n\n- Figure 1. This figure is unclear, please include an explanation for what is given on the top and bottom rows for each of the methods.\n\n- \"From a deblurred output, the reblurring module tries to make the reblurred image close to the original\" So in practice this reblurring network is the inverse of the deblurring module. Why not present this module in this way?\n\n- Writing is a little disorganized. For example in the introduction when referring to the \"reblurring loss\" it is unclear what is \"the difference\" that is mentioned. One of the listed contribution depends on this \"reblurring loss\" so this needs to be better explained in the introduction.\n\n- The need for the pseudo-sharp image \\hat{S}. The argument for using \\hat{S} and not S seems to be rather empirical so this should be supported by evidence. In the current presentation there's a lot of emphasis on measuring sharpness but not realism, but then later for evaluating the quality perceptual metrics such as LPIPS and NIQE are used. So, there seems to be a mismatch between what is claimed and what is actually happening. \n\n- The test-time adaptation inverts the re-blurring network. This needs more analysis in terms of: \nWhat happens if we minimize this loss (gradient descent till convergence)? How many gradient descent steps are needed. This is not discussed much in the paper and I found it to be an interesting contribution. It will be also helpful to show cross-datasets performances (trained with GoPro and evaluated with a different dataset, e.g. HIDE, Real-Blur or REDS).\n\n- Perceptual Distortion tradeoff. The perceptual distortion trade-off balances a reference based metric against a non-reference metric (e.g., distance to the natural image manifold). PSNR and LPIPS are both reference based metrics so it doesn't make sense (formally) to refer to this type of plot as a distortion-perception trade-off. Maybe the plot should be made with NIQE instead of LPIPS.\n",
          "summary_of_the_review": "This paper introduces an interesting idea for improving image deblurring models: the deblurred image should not contain information/traces about the original blur.  This is a bold statement. The paper crystalizes this idea using two networks (deblurring and re-blurring network) that are co-trained with different loss terms. The implementation seems (a little) too complex with many terms that try to avoid different types of artifacts/degenerative cases. But in the end this seems like a valid implementation of the initial idea. The current analysis didn't convince me that the method is doing much better or better than other methods that just compare the restored and sharp images on a pre-computed feature space (is this a matter of tuning the contributions of each loss term?). I think the paper needs to better discuss and analyze this. Additionally, the idea seems to be specific for dealing with blur. Can the same idea apply to other (restoration) tasks?",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_oSPE"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_oSPE"
        ]
      },
      {
        "id": "4HmAhN7fbtS",
        "original": null,
        "number": 2,
        "cdate": 1635841243433,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635841243433,
        "tmdate": 1635841243433,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Review",
        "content": {
          "summary_of_the_paper": "A novel deblurring method is proposed by introducing the concept of reblurring loss. Conventional techniques deblur blurry images to some extent however there are some unremoved blur contents, where it can be used to reconstruct (reblur) blurry images. On the other hand, cleanly deblurred images have only sharp contents and it is difficult to reblur the images since no blurry cues are left. By using such observation, a reblurring module and a deblurring module with reblurring loss are proposed. Experimental results show that the proposed framework outperforms SOTA quantitatively and qualitatively on the GOPRO and REDS dataset. ",
          "main_review": "1. Technical novelty\nThe observation that the \"clean images are hard to reblur\" is quite novel. \nFollowing the observation, the proposed reblurring loss is logical and experimental results are consistent. \nI'm concerned that the concept of deblur-reblur is similar to the GANs, but the authors well addressed the issue in the introduction. \n\n2. Writing\nOverall it is well-written and easy to read. However, more proofreading and re-arranging figures are needed before publication. \nIn Figure 1, the sharp image (supposed to be ground truth) and deblurred images are located in the top row. It may be a reasonable arrangement since they are seemingly similar. However since they have different meanings, there should be a better arrangement for easier understanding. \nReaders may be familiar with the blurry and deblurred image, but not the reblurred image since it is quite a new concept. So additional figures explaining and emphasizing such concepts would help the understanding. \nIn Figure 2, there are B and S in both of Figure 2 (a) and (b), where the arrangement is somewhat confusing. \nTable 1 is mentioned just below the equation (1) but there is no explanation about M_D before Table 1. \n\n3. Experimental results\nExperimental results improve SOTA in perceptual measures such as LPIPS and NIQE. However, it did not improve PSNR and SSIM, which gives the impression that the deblurred image may distort the original image and obtain better perceptual measures by sharpening. ",
          "summary_of_the_review": "The paper introduces an interesting observation and proposes novel modules based on the observation where the development is very logical. Overall, the paper is easy to read, however more proofreading is required. Experimental results improve the SOTA but there should be justification for some results. ",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_M9xc"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_M9xc"
        ]
      },
      {
        "id": "Rezub_FSUIe",
        "original": null,
        "number": 3,
        "cdate": 1635970192165,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635970192165,
        "tmdate": 1638211971241,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposes a novel approach to using deep networks for image deblurring. Since training with simply reconstruction losses usually leads to oversmoothed results, recent works have looked at using perceptual and adversarial losses.\n\nThe paper proposes an approach similar to an adversarial loss. If an image is not de-blurred entirely, it leaves within itself some tell-tale signs of the original blur. The paper proposes learning a \u201creblurring\u201d network that given a \u201cdeblurred\u201d image should yield the original \u201cblurry\u201d image, while given a true sharp image should output the image itself. The deblurring network is then trained in a sense to fool the re-blurring network, by generating images that would be left untouched by the reblurring network. The paper also proposes a \u201ctest time adaptation\u201d approach.",
          "main_review": "This is an interesting idea. For the task of deblurring, it represents a logical and novel formulation of the \u201cadversary\u201d: rather than just saying whether the input is truly sharp or the output of a deblurring network, the reblurring network has to reproduce the original blurry image in the latter case.\n\nWhile the results are encouraging, there are a number of issues with the paper:\n\nThe paper needs to do a much better job in clearly and systematically establishing the benefit of the proposed method against a standard adversarial loss and other perceptual losses (which are much simpler and more straightforward than the proposed reblurring loss). In particular, the efficacy of the network WITHOUT test-time adaptation should be established. This is because TTA is expensive, and it is not clear whether other methods couldn\u2019t also be improved with TTA (for example, those based on standard adversarial losses) or by just having slower but deeper networks.\n\nTable 4 seems to suggest minimal additional benefit of the reblur loss (without TTA). There is some benefit in NIQE, none in LPIPS, and PSNR and SSIM get worse. This comparison is also to a specific weight on the adversarial loss. Did the authors sweep for different loss weights to find the optimal one for training only with an adversarial (+ VGG) loss? This is what I mean by a systematic evaluation: the paper should find the optimal hyperparameters for training with only a regular adversarial loss and compare to the optimal setting for the proposed method \u2014 without TTA and using a comparable architecture for the discriminator as the proposed MR.\n\n\nThe paper also needs more comprehensive results reported for comparisons to state-of-the-art. There are no quantitative results, and the qualitative results are only with TTA. Visually, the improvement of the proposed method with TTA over DeblurGAN is relatively small. It would be natural to wonder if that improvement disappears without TTA, and if infact, the proposed method does worse than DeblurGAN. As noted, TTA is expensive, and an orthogonal approach that could potentially be applied to other adversarially trained deblurring networks.\n\nThe paper, especially the introduction, could be a lot clearer in explaining the basic idea. Figure 1 is great in terms of layout, but the captions / legend is not informative making it very unintuitive.  The caption should at the very least explain what L, S, \\hat{S}, and B are without having readers to dig through the text in section 3. The \u201cshared\u201d is confusing \u2014 one would anyway assume that all M_R\u2019s are the same, but the fact there\u2019s shared lines only among pairs on the left and right makes us question if the two pairs are different from each other. Having (a) and (b) in Figure 1 with the corresponding headings is also confusing. They each respectively describe the training loss for M_R and M_D, and if I understand correctly, each iteration involves doing an update step of each. This does not come across from the figure. And finally, some more details of the test-time adaptation should be included in the main paper. Most of the text in the main paper in that section gives \u201cintuition\u201d \u2014 but is very confusing to read since the reader doesn\u2019t know exactly what is being optimized and what is being updated (image or network weights).\n\n\nA lot of the explanations in the paper are very hand-wavy, and not at all clear to the reader. This is especially true about the use of a pseudo sharp image instead of a sharp image: for example, I don\u2019t understand what the authors mean by \u201cIn contrast to S that differ from the deblurred image L by the realness, \\hat{S} can avoid being MR distracted by such an unintentional difference, focusing on image sharpness.\u201d I\u2019m actually not sure why using S-hat doesn\u2019t just cause a degenerate solution where MD produces oversmoothed outputs all the time to prevent MR from figuring out if the original image was blurry or not.",
          "summary_of_the_review": "Given the issues with the experiments and presentation above, I don't think the paper is ready for publication.\n\n### Post-rebuttal\n\nIncreasing score from reject to borderline/marginal  reject. I think the paper still needs a bit more work, but would not object to it being accepted. Please see detailed comment in response to rebuttal below.",
          "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "Not applicable",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper12/Reviewer_Gxxe"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper12/Reviewer_Gxxe"
        ]
      },
      {
        "id": "Ba1h0ZlPAZ0",
        "original": null,
        "number": 1,
        "cdate": 1642696833201,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696833201,
        "tmdate": 1642696833201,
        "tddate": null,
        "forum": "kezNJydWvE",
        "replyto": "kezNJydWvE",
        "invitation": "ICLR.cc/2022/Conference/Paper12/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Accept (Poster)",
          "comment": "The paper introduces an idea that was found interesting by all reviewers (including Gxxe who recommends a marginal reject). A majority of the reviewers also point out a few weaknesses of the paper, notably in terms of clarity of several statements that were found to be hand-wavy (see the reviews of Gxxe and oSPE for more precise details). The area chair agrees with those statements, but overall, the originality of the idea introduced in this paper outweighs these weaknesses, and the experimental study is conducted in a reasonably convincing manner.\n\nEven though there is room for improvements, the area chair is happy to recommend an accept, but encourages the authors to follow the constructive feedback provided by the reviewers for the camera-ready version."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "invitation": {
      "reply": {
        "writers": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "signatures": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "content": {
          "title": {
            "value-regex": ".*",
            "order": 1
          },
          "authors": {
            "values": [
              "Anonymous"
            ],
            "order": 2
          },
          "authorids": {
            "value-regex": ".*",
            "order": 3
          },
          "keywords": {
            "value-regex": ".*",
            "order": 6
          },
          "abstract": {
            "value-regex": ".*",
            "order": 8
          },
          "pdf": {
            "value-regex": ".*",
            "order": 9
          },
          "one-sentence_summary": {
            "value-regex": ".*",
            "order": 10
          },
          "supplementary_material": {
            "value-regex": ".*",
            "order": 11
          },
          "code_of_ethics": {
            "value-regex": ".*",
            "order": 12
          },
          "submission_guidelines": {
            "value-regex": ".*",
            "order": 13
          },
          "resubmission": {
            "value-regex": ".*",
            "order": 14
          },
          "student_author": {
            "value-regex": ".*",
            "order": 15
          },
          "serve_as_reviewer": {
            "value-regex": ".*",
            "order": 16
          },
          "community_implementations": {
            "required": false,
            "description": "Optional link to open source implementations",
            "value-regex": ".*",
            "markdown": true,
            "order": 103
          }
        }
      },
      "replyForumViews": [],
      "expdate": 1682960118639,
      "signatures": [
        "ICLR.cc/2022/Conference"
      ],
      "readers": [
        "everyone"
      ],
      "writers": [
        "ICLR.cc/2022/Conference"
      ],
      "invitees": [
        "ICLR.cc/2022/Conference"
      ],
      "tcdate": 1632875419419,
      "tmdate": 1682960118686,
      "id": "ICLR.cc/2022/Conference/-/Blind_Submission",
      "type": "note"
    }
  },
  "tauthor": "OpenReview.net"
}