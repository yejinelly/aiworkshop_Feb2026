{
  "id": "0xiJLKH-ufZ",
  "original": "_LdAAf-69yi",
  "number": 222,
  "cdate": 1632875437587,
  "pdate": 1643407560000,
  "odate": 1633539600000,
  "mdate": null,
  "tcdate": 1632875437587,
  "tmdate": 1676330682692,
  "ddate": null,
  "content": {
    "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models",
    "authorids": [
      "~Fan_Bao1",
      "~Chongxuan_Li1",
      "~Jun_Zhu2",
      "~Bo_Zhang2"
    ],
    "authors": [
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "keywords": [
      "diffusion probabilistic models",
      "generative models"
    ],
    "abstract": "Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose \\textit{Analytic-DPM}, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a $20\\times$ to $80\\times$ speed up.",
    "one-sentence_summary": "We propose an analytic framework of estimating the optimal reverse variance in DPMs.",
    "code_of_ethics": "",
    "submission_guidelines": "",
    "resubmission": "",
    "student_author": "",
    "serve_as_reviewer": "",
    "paperhash": "bao|analyticdpm_an_analytic_estimate_of_the_optimal_reverse_variance_in_diffusion_probabilistic_models",
    "pdf": "/pdf/541cdc9e000367bb0bd3fc42201573ed434094c8.pdf",
    "supplementary_material": "/attachment/82cdf46f2e4104c5546cc812a2654ad6d79347f0.zip",
    "_bibtex": "@inproceedings{\nbao2022analyticdpm,\ntitle={Analytic-{DPM}: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models},\nauthor={Fan Bao and Chongxuan Li and Jun Zhu and Bo Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=0xiJLKH-ufZ}\n}",
    "venue": "ICLR 2022 Oral",
    "venueid": "ICLR.cc/2022/Conference"
  },
  "forum": "0xiJLKH-ufZ",
  "referent": null,
  "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission",
  "replyto": null,
  "readers": [
    "everyone"
  ],
  "nonreaders": [],
  "signatures": [
    "ICLR.cc/2022/Conference"
  ],
  "writers": [
    "ICLR.cc/2022/Conference"
  ],
  "details": {
    "overwriting": [],
    "tags": [],
    "writable": false,
    "replyCount": 21,
    "directReplyCount": 9,
    "revisions": true,
    "replies": [
      {
        "id": "Pm0oyznxmaz",
        "original": null,
        "number": 1,
        "cdate": 1635266291619,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635266291619,
        "tmdate": 1637332603753,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "In Sec. 2, the authors review the general framework of Diffusion Probabilistic Models~(DPMs) with non-Markovian forward processes from [1] which has DDPMs [2] and DDIMs [1] as special cases. They emphasize that the variance of the reverse process, such as in DDPM and DDIM, are generally hand-crafted.\n\nIn Sec. 3, the authors present their main theorem: the optimal variance of the reverse process at step $n$ is a linear function of the expected squared norm of the score at step $n$. As a post-processing scheme of learned models, they then propose to replace the commonly used hand-crafted variances by an estimator of their optimal variance: in particular, the score is replaced by the learned score model and the expectation is replaced by a Monte Carlo estimate (with $M$ samples) thereof. In the remainder of this section, the authors derive bounds for the optimal variance and state that in practice their estimator is clipped according to these bounds.\n\nIn Sec. 4, the authors repeat the derivation of an optimal variance and bounds thereof when only a subset (of size $K$) of the $N$ timesteps are used for inference as is very common in the literature [1, 3, 4]. Furthermore, they show how their estimator in this setting can be used to still compute the optimal subset according to the commonly used DP algorithm introduced in [4].\n\nIn Sec. 6, they apply their post-processing scheme to models trained on CIFAR-10, CelebA 64 and ImageNet 64 and show that it generally leads to improved likelihood and FID scores. They show that their post-procecssing scheme consistently outperforms suboptimal hand-crafted choices (such as in DDPM and DDIM).\n\nReferences:\n\n[1] Song et al. Denoising Diffusion Implicit Models. ICLR 2021.\n\n[2] Ho et al. Denoising Diffusion Probabilistic Models. NeurIPS 2020.\n\n[3] Dhariwal & Nichol. Diffusion Models Beat GANs on Image Synthesis. arXiv:2105.05233.\n\n[4] Watson et al. Learning to Efficiently Sample from Diffusion Probabilistic Models. arXiv:2106.03802.",
          "main_review": "Strengths:\n- Paper has single well-executed idea (optimal variance can be computed as a function of score) \n- Improvements over generally fair base lines are achieved by only post-processing; no additional training needed\n- Paper is generally well-written and straightforward to read\n- I did not check all Lemmas (appendix) in detail, however, it seems that their proofs are generally very rigorous and detailed.\n- The bounds in Theorem 2 are quite nice. Given that DPMs are often used for images, the specific bound for the data distributions supported in the $d$-dimensional cube are quite applicable.\n\nWeaknesses:\n- For $K<100$, FID scores of the proposed method greatly rely on a trick of clipping the variance of the step $n=2$ (can be seen in appendix G.4). This seems to be a crucial element and should be discussed more in the main paper. In particular, I would like to see how this clipping compares to the bounds (and the clipping) of the optimal score wrt Theorem 2.\n- The post-processing method can be quite expensive. For example, on ImageNet the best values are achieved using $MK= 400000$ additional ($M=100, K=N=4000$) function evaluations. For even trajectories (ET), the obvious solution would be to simply use $K \\ll N$ (results for this are shown in paper), however, if I am not mistaken, for the optimal trajectory (OT), computed using the DP algorithm from [4], $MN$ functions have to be evaluated for any $K$ (see appendix B and eq (14)). Therefore, in my opinion, the comparison of DDPM and Analytic=DDPM in the OT setting of Table 1 is unfair.\n\nSuggestions:\n- It would be helpful to understand how often the estimator is actually clipped. I suggest to compute $R$ (maybe $R=100$) estimators for, say $M=[1,10, 50, 100, 500, 1000]$, and plot he number of the ratio of estimators that was clipped over $M$. This could be done for a few different instantiations of $n$ (I guess there will be more clipping for $n$ being small).\n- the estimator $J$ in (14) is biased even when the correct score is known ($J$ is the log of an unbiased (Monte Carlo) estimator); it might be nice to mention this fact.\n- It would be nice to see even lower $M$ in the ablations in G.2. Instead of only indicating variance by plotting the estimator in Figure 3, it would be nice to see the estimated variance of the sampler directly.\n- Please state the number of Monte Carlo samples used for results in Tables 1,2,3.\n- To me it seems that the optimal variance could also be used for training, using for example only $M=1$. I would be curious to see how this performs compared to using the optimal variance only as a guide for post-processing. I greatly encourage the authors to try this (in case there are no major problems I am missing)",
          "summary_of_the_review": "Overall, I vote for accepting. The paper provides an important insight in DPMs and shows improved results for pretrained models by a simple post-processing technique. My major concern about the paper is that OT [4] does not work well in combination with their method, which in my opinion makes the work slightly less significant. I hope the authors can address this concern in the rebuttal period.\n\n**Post discussion period update:**\nI strongly vote for accepting (and also changed the correctness score from 3 to 4). All of my concerns, questions, and suggestions have been addressed by the authors in the discussion period. I thank the authors for this productive reviewing process.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ]
      },
      {
        "id": "BN1_YyCfcR-",
        "original": null,
        "number": 2,
        "cdate": 1635580753708,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635580753708,
        "tmdate": 1637381858710,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper studies an estimate of the reverse process of a diffusion probabilistic model (DPM). The reverse process is usually estimated by minimizing the KL divergence between the forward and the reverse process. Authors present that the optimal mean and variance of the reverse process have analytic forms w.r.t. the score function. The form of the optimal mean coincides with the parameterization in the previous work and justifies a reweighted variant of the variational bound proposed in the recent work. Different from the handcrafted strategies employed in other work, the authors propose a novel estimation for the variance and analyze its bias. To reduce the bias, bounds of the optimal reverse variance are analyzed and the estimate is clipped based on the bound. Furthermore, the KL divergence between the forward and the optimal reserve process also has an analytical form and as a result, the authors propose the optimal trajectory which has minimal KL value. Finally, the authors present the relationship between the score function and the data covariance matrix and assess the proposed approach in the experiments. The experiment results show that the analytic results improve the efficiency, likelihood, and sample quality.",
          "main_review": "Strengths:\n\n1. The paper is clearly written and well organized. Contents are easy to follow. There are many technical details for readers to understand the results, such as the derivation of Theorem 1.\n\n2. The analytic results are interesting and novel. According to the introduction and the related work sections, the optimal forms of the reverse process of DPM didn't appear in the previous DPM work and I believe it will help people in the field of DPM better understand this type of models. The bias analysis and the bound of the variance are helpful to understand the estimate and improve the estimate performance. The authors also make detailed discussions on these results, which are very helpful.\n\n3. The experiment results are strong. The authors not only validate their analytic forms but also present the outperformance of their methods. The experiment results show significant improvements in their methods.\n\nWeaknesses:\n\n1. The DPM is a Gaussian-distribution-based simple model and similar analytic results can exist in similar models. The Gaussian model considered in this paper has a simple Markov property, which as a result has decomposable probability. The optimization is via forward KL divergence. Therefore, for example, the classical result on the expectation propagation algorithm with the Gaussian process can simplify the derivation: the decomposable form of the probability guarantees the forward KL decomposable, and minimizing the forward KL is equivalent to moment matching. So, I am concerned that the contribution is not as much as what was introduced in the paper. I also believe that such kind of connection will be helpful to figure out the possible further directions along this line and also save energy to get new results. I suggest authors add some discussions on the connection to other Gaussian models and their results.",
          "summary_of_the_review": "The paper contributes interesting analytic results to the DPM models and the methods perform well in practice. However, the DPM is a simple Gaussian model and similar results can appear in other similar models.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_a5eg"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_a5eg"
        ]
      },
      {
        "id": "19df0k-PGMz",
        "original": null,
        "number": 3,
        "cdate": 1635920012833,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635920012833,
        "tmdate": 1635920012833,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed a modification of the diffusion probabilistic models (DPMs) called analytic-DPM that is based on an analytic estimate of the optimal reverse variance. Using this analytic estimate, the proposed method can achieve fast and performant inference through the Monte Carlo method and pre-trained score-based model. The derivation of the optimal reverse analytic mean and variance is proven to be associated with the score function. Upper bounds and lower bounds are provided for the optimal reverse variance, the relationship between the data covariance and the score function is shown. Experimental results are provided by comparing the proposed method with existing variants of DPMs, through both negative log-likelihood and FID as metrics. The experimental results suggest that the proposed method can potentially provide better performance more efficiently compared to alternatives.",
          "main_review": "Strength:\n1. the paper derives the optimal reverse variance for diffusion probabilistic models as well as its lower and upper bound. This leads to more efficient DPMs with better performance compared to existing DPM variants. It also leads to new insights into DPMs such as why the way the reversed variance is chosen by existing work is not ideal.\n\n2. The paper is clearly presented. The technical results reported in the paper are non-trivially obtained. The relationship between the paper and existing works is well discussed and well-motivated.\n\n3. Experimental results compared to other variants of DPM are well discussed. It also demonstrates the advantage of the proposed method compared to existing DPM variants.\n\nWeakness:\n1. Although proposition 1 establishes the relationship between data covariance and score function, it is unclear to me what is the practical implication of proposition 1.\n\n2. In the experiment, it is unclear to me whether timestep is a good metric to measure efficiency in Table 3. Does each method spend roughly the same time at each timestep?\n\n3. While the authors compare the proposed method with other existing variants of DPMs. Is there any reason why the comparison between the proposed method and other classes of generative models such as GAN should be conducted or not?\n\n",
          "summary_of_the_review": "Correctness: I think the paper is mostly correct. I am not sure if using timestep is a good metric to demonstrate the efficiency of the proposed method. Since efficiency is a major aspect of the proposed method, it would be desirable to make a clarification on this issue.\n\nNovelty and significance: I think the derivation of the optimal reverse variance is novel and insightful. The lower bound and upper bound of the optimal reverse variance is also useful in practice. While the proposed method is performant compared to existing DPM variants, these existing variants achieve better or comparable FID or negative log-likelihood with enough timesteps. These strong baselines suggest the (potentially limited) headroom left for improvement for the proposed method.\n\nOverall, I think the paper solves an interesting problem in DPM. ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "Yes, Potentially harmful insights, methodologies and applications"
          ],
          "details_of_ethics_concerns": "Performant generative models can be misused in situations such as deep fake. ",
          "recommendation": "8: accept, good paper",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Qdy8"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Qdy8"
        ]
      },
      {
        "id": "4Qh32Izg8a5",
        "original": null,
        "number": 4,
        "cdate": 1636121638776,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636121638776,
        "tmdate": 1636121638776,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposes a theoretically grounded method for estimating *optimal* reverse process variances for DDPMs and DDIMs. This method can be applied to a trained DDPM / DDIM after the fact and lead to improved likelihoods and faster sampling (when used together with optimal trajectory search). The proposed method and theoretical insights also perform strongly in practice across a range of models and datasets.",
          "main_review": "**Strengths**\n* Strong theoretical motivation and strong empirical results to support it.\n* Nicely written, does a great job putting prior work in the context of the new insights on optimal reverse mean and variance.\n* Despite the abundance of theory / derivations, the paper still remains accessible.\n\n**Weaknesses**\n\nI am convinced by the paper in its current form. But if I had to list something:\n* It would be great to see applications of this method to other data modalities, such as for example speech / sound generation.\n* The performance of Analytical-DPMs on methods that learn forward process variance schedules (e.g. VDMs) would also be great to see.",
          "summary_of_the_review": "The paper provides valuable insights into optimal reverse process variance of DDPMs and DDIMs, and makes connections between the proposed optimal variance and previous handcrafted choices, etc. The improved understanding of these model classes could have been sufficient to recommend acceptance. However, the empirical results, especially those around faster sampling are also strong and convincing. DDPMs / DDIMs achieve high sample quality and it's primarily their sampling speed that prevents practical application off this model class in real-world systems. This works makes a significant step towards enabling faster sampling for this model class.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Xtgn"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Xtgn"
        ]
      },
      {
        "id": "HVoY12Mc5YC",
        "original": null,
        "number": 5,
        "cdate": 1636179057869,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636179057869,
        "tmdate": 1636179971025,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper studies diffusion probabilistic models, and derives the optimal mean and variance (as functions of the expected data score) for the reverse process. Authors then propose to plug in a Monte Carlo estimate of the the variance for the reverse process and experimentally show how this leads to improved results with trained and/or pretrained models in terms of FID and NLL. In addition, authors combine their approach with recent work that optimizes for \"knot\" locations given a fixed number of knots for faster sampling. ",
          "main_review": "**novelty, significance**\n\nThe result on optimal variance is new, to the best of my knowledge. The authors also do a reasonable job in convincing me that a Monte Carlo estimate of it is useful for inference. Given the recent progress and interest on DPMs, I think this work will also have reasonable significance and influence. \n\n**presentation**\n\nAuthors do a reasonable job on the writing and presenting experimental results. Past works are adequately and appropriately cited, to the best of my knowledge. \n\n**Technical quality and correctness**\n\nOne thing I'll add here is that once the Monte Carlo estimate of $\\sigma_t^2$ is plugged into the bound computation, it seems we end up with a stochastic lower bound of the ELBO (assuming the loss is concave in $\\sigma_t^2$). The important thing here to note perhaps is that bias is introduced. To put it more concretely, say the quantity being estimated is $\\mathbb{E}[ f(\\sigma_t^2) ]$, where I've written the bound as the expectation of the loss $f$ as a function of $\\sigma_t^2$. The estimator $f(\\hat{\\sigma}_t^2)$ is now a stochastic lower bound on the original quantity by Jensen's, since \n$$\\mathbb{E} [f(\\hat{\\sigma}_t^2)] \\le \\mathbb{E} [f( \\mathbb{E} [ \\hat{\\sigma}_t^2 ] ) ]  = \\mathbb{E} [f( \\sigma_t^2)].$$\n\nI think there should be some discussion about this. I'm assuming $f$ is concave in $\\sigma_t^2$, mostly reasoning from past bounds, but authors should perhaps make parts of the discussion more precise. \n\n**Experimental results**\n\nAuthors do a reasonable job in evaluating their method. One particular point I didn't get is how $M$ (number of samples for estimating the expected score) is chosen. The are a couple of potential issues here.\n- Selecting $M$ requires additional hyperparameter tuning, potentially; the tuning procedure should be reported. \n- How results depend on $M$ isn't entirely clear just from reading the main text (maybe there's some discussion in the appendix, but I didn't have time to read all content in the appendix). Ideally, some discussions should appear in the main text.\n- Large $M$ incurs more compute cost during inference -- while this seems less an issue when inference is run on GPUs (since most scenarios, I'd guess, there's enough cores to parallelize the Monte Carlo samples), this could be an issue for CPU inference. How does the run-time in practice compare in this case? Note while practical systems don't tend to run training on CPUs, inference on CPUs is still quite common. ",
          "summary_of_the_review": "Authors study choosing the optimal variance for the reverse process in DPMs and propose to Monte Carlo estimate it for improved inference.  Technical quality, writing, and experiments are mostly good with the two minor caveats I described above. \n",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_FHw9"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_FHw9"
        ]
      },
      {
        "id": "o0QJ34P13kk",
        "original": null,
        "number": 9,
        "cdate": 1636978709495,
        "mdate": 1636978709495,
        "ddate": null,
        "tcdate": 1636978709495,
        "tmdate": 1636978709495,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Common concern 1",
          "comment": "We thank all the reviewers for their appreciation of our novel contributions as well as the valuable comments, which help to further improve. Below, we first address some common concerns. Then, we address the individual comments to each reviewer.\n\n## Common concern 1 (from reviewers FHw9, ejLx): The tuning procedure of $M$ and more experiments on varying $M$\n\nWe clarify how $M$ is selected in the original paper and add more experiments on varying $M$.\n\n### 1.1 The tuning procedure of $M$ in the original paper\n\nWe did not tune $M$ in the original paper. In fact, we used a maximal $M$ without introducing too much computation. Specifically, we set $M=50,000$ on CIFAR10, $M=10,000$ on CelebA 64x64 and ImageNet 64x64 and $M=1,000$ on LSUN Bedroom by default without a sweep. \nAll of the samples are from the training dataset. We used the default settings of $M$ for all results in Tables 1, 2 and 3. We have added the experimental details in Appendix F.3 in the revised version.\n\n\n### 1.2. How results depend on $M$\n\nIn Appendix G.2 of the original submission, we evaluated Analytic-DPM with $M=100$ and found that it has a small variance and achieves  almost the same NLL results as those of $M=50,000$.\n\nFollowing the reviewers' suggestion, we added the results of Analytic-DPM over a wide range of $M \\in \\\\{1,3,10,100,10000,50000\\\\}$.\nUnder both the NLL and FID metrics, $M=10$ achieves similar results as those of $M=50,000$ on CIFAR10 (LS) and those of $M=10,000$ on ImageNet 64x64. The results are presented in Table 1* below. \nWe have also added the results to Appendix G.2 in Table 5 in the revised version.\n\n\n| CIFAR10 (LS) | NLL $\\downarrow$ | FID $\\downarrow$ |  ImageNet 64x64 | NLL $\\downarrow$ | FID $\\downarrow$ |  \n|  ----        | ----        | ----        |  ----          | ----       | ----        |\n| $M=1$        | 6.220\u00b11.126 | 34.05\u00b14.97 | $M=1$          | 4.943\u00b10.162 | 31.59\u00b15.11 |\n| $M=3$        | 5.689\u00b10.424 | 34.29\u00b12.88 | $M=3$          | 4.821\u00b10.055 | 31.98\u00b11.19 |\n| $M=10$       | 5.469\u00b10.005 | 33.69\u00b12.10 | $M=10$         | 4.791\u00b10.017 | 31.93\u00b11.02 |\n| $M=100$      | 5.468\u00b10.004 | 34.63\u00b10.68 | $M=100$        | 4.785\u00b10.003 | 31.93\u00b10.69 |\n| $M=50000$    | 5.471       | 34.26      | $M=10000$      | 4.783       | 32.56      |\n\nTable 1*: FID and NLL results of Analytic-DPM with different $M$. We use $K=10$ for CIFAR10 (LS) and $K=25$ for ImageNet 64x64.\n\n\n### 1.3. The variance of the estimate $\\Gamma_n$ over different $M$\n\nWe plotted the standard deviations of the estimate $\\Gamma_n$ at different timesteps $n$ when $M\\in \\\\{1,10,100\\\\}$. \nIn all cases, the variance decays fast as $n$ increases. Further, $M=10$ is sufficient to achieve a small standard deviation relative to the mean (e.g. less than 10\\% of the mean) for all $n$. \nSee Figures 4\\&5 in Appendix G.2 of the revised version for the results.\n\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "jiVwWLSUOgh",
        "original": null,
        "number": 10,
        "cdate": 1636979464695,
        "mdate": 1636979464695,
        "ddate": null,
        "tcdate": 1636979464695,
        "tmdate": 1636979464695,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Common concern 2",
          "comment": "\n## Common concern 2 (from reviewers FHw9, ejLx): The extra cost of the Monte Carlo estimate $\\Gamma_n$\n\n* The extra cost of the Monte Carlo estimate is small compared to the whole inference cost.\nIn fact, the Monte Carlo estimate requires $M N$ additional function evaluations. \nDuring inference, suppose we generate $M_1$ samples or calculate the log-likelihood of $M_1$ samples with $K$ timesteps. Both DPMs and Analytic-DPMs need $M_1 K$ function evaluations. Employing the same score-based models, the relative additional cost of Analytic-DPM is $\\frac{M N}{M_1 K}$. In our experiments, we found that a very small $M$ (e.g., $M=10$ or $100$) is sufficient for Analytic-DPM (see our response to common concern 1 (1.2 and 1.3)), making the relative additional cost small if not negligible. For instance, on CIFAR10, let $M=10$, $N=1000$, $M_1=50000$ and $K\\ge 10$, we obtain $\\frac{M N}{M_1 K}\\le 0.02$ and  Analytic-DPM still consistently improves the baselines as presented in Table 2* below. We have also added the results to Appendix G.2 in Table 6 in the revised version.\n\n\n* Further, the additional calculation of the Monte Carlo estimate occurs only **once** given a pretrained model and training dataset, since we can save the results of $\\Gamma = (\\Gamma_1, \\cdots, \\Gamma_N)$ in Eq.(8) and reuse it among different inference settings (e.g., trajectories of various $K$). The reuse is valid, because the marginal distribution of the shorter forward process $q(x_0, x_{\\tau_1}, \\cdots, x_{\\tau_K})$ at timestep $\\tau_k$ is the same as that of the full-timesteps forward process $q(x_{0:N})$ at timestep $n=\\tau_k$. Indeed, in our experiments (e.g., Table 1,2), $\\Gamma$ is shared across different selections of $K$, trajectories and forward processes. Moreover, in practice, $\\Gamma$ can be calculated offline and deployed together with the pretrained model and the online inference cost of Analytic-DPM is exactly the same as DPM.\n\nWe have updated Section 3 and added Appendix H.1 in the revised version to address this comment.\n\n\n| # timesteps $K$ | 10 |  25 | 50 | 100 |  200 | 400 |\n| ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n| NLL $\\downarrow$ |\n| Analytic-DDPM ($M=10$) | 5.47 | 4.80 | 4.38 | 4.07 | 3.85 | 3.71 |\n| DDPM        | 6.99 | 6.11 | 5.44 | 4.86 | 4.39 | 4.07 |\n| FID $\\downarrow$ |\n| Analytic-DDPM ($M=10$) | 33.69 | 11.99 | 7.24 | 5.39 | 4.19 | 3.58 |\n| DDPM        | 44.45 | 21.83 | 15.21 | 10.94 | 8.23 | 4.86 |\n\nTable 2*: The NLL and FID comparison between Analytic-DDPM with $M=10$ Monte Carlo samples and DDPM on CIFAR10 (LS).\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "uy5TVszw4vk",
        "original": null,
        "number": 11,
        "cdate": 1636980727416,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636980727416,
        "tmdate": 1636989106929,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "HVoY12Mc5YC",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to reviewer FHw9",
          "comment": "We thank reviewer FHw9 for the acknowledgement of our contributions and the insightful comments.\nWe have updated our paper by adding a discussion about the bias caused by the Monte Carlo method, and clarifying the issues about the tuning procedure of $M$, sensitivity of $M$ and the additional computation cost.\nBelow, we provided a point-to-point response to all comments.\n\n\n## Q1: $f(\\hat{\\sigma}_t^2)$ as a stochastic lower bound of $\\mathbb{E}[f(\\sigma_t^2)]$ and the potential bias\n\nThanks for the valuable comment. Generally, $f(\\hat{\\sigma}_t^2)$ is not a stochastic lower bound of $\\mathbb{E}[f(\\sigma_t^2)]$, since $f$ is not concave in $\\sigma_t^2$. Actually, the ELBO can be written as a function of $\\sigma_t^2$ in the form of $f(\\sigma_t^2) = B(\\frac{A}{\\sigma_t^2} + \\log \\sigma_t^2) + C$, where $A, B, C$ are constants unrelated to $\\sigma_t^2$ and $A, B > 0$. $f(\\sigma_t^2)$ is convex when $0 < \\sigma_t^2 < 2A$ and concave when $2A < \\sigma_t^2$. Please refer to Proposition 2 of Appendix H.2 in the revised version for a formal proof.\n\nHowever, in this paper, \n$f(\\hat{\\sigma}_t^2)$ is a stochastic lower bound of $\\mathbb{E}[f(\\sigma_t^{*2})]$ because $\\mathbb{E}[f(\\sigma_t^{*2})]$ is the optimal ELBO. \nPlugging in $\\hat{\\sigma}_t^2$, the bias of $\\mathbb{E}[f(\\hat{\\sigma}_t^2)]$ w.r.t. $\\mathbb{E}[f( \\sigma_t^{*2})]$ is due to the Monte Carlo method as well as the error of the score-based model.\nThe former can be reduced by increasing the number of Monte Carlo samples. The latter is irreducible if the pretrained model is fixed, which motivates us to clip the estimate, as discussed in Section 3.1. We have revised the main text in Section 3 and added a detailed discussion in Appendix H.2 of the updated version.\n\n\n## Q2: The tuning procedure of $M$\n\nThanks for the suggestion. We do not tune $M$ in the original paper. In fact, we use a maximal $M$ without introducing too much computation. \nSee more details in the common concern 1 (1.1).\n\n## Q3: How results depend on $M$\n\nThanks for the suggestion. Based on the original results of varying $M$ in Appendix G.2 and newly added experiments in Table 5 of Appendix G.2 (or see Table 1* in the common concern 1 (1.2)), we conclude that Analytic-DPM is not sensitive to $M$ and usually a small $M$ (e.g. $M=10$) is sufficient for good results.\n\n## Q4: Large $M$ incurs more computation cost during inference\n\nThanks for the valuable comment. As mentioned in the response to Q3, usually a small $M$ is sufficient for accurate inference. Suppose that we have to use a large $M$ in the setting mentioned in the comment (i.e., inference using CPUs). Given a pretrained model and training dataset, we can calculate $\\Gamma = (\\Gamma_1, \\cdots, \\Gamma_N)$\noffline (i.e., on GPUs) and deploy it together with the pretrained model. Consequently, the online inference cost of Analytic-DPM is exactly the same as DPM. In fact, in the paper, we calculate $\\Gamma$ first and reuse it throughout our experiments (e.g., over different selections of $K$, trajectories and forward processes). \nPlease see more details in our response to the common concern 2.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "ccUFQlA7sRy",
        "original": null,
        "number": 12,
        "cdate": 1636980869438,
        "mdate": 1636980869438,
        "ddate": null,
        "tcdate": 1636980869438,
        "tmdate": 1636980869438,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "4Qh32Izg8a5",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to reviewer Xtgn",
          "comment": "We thank reviewer Xtgn for the acknowledgement of our contributions and the valuable comments.\n\n## Q1: Application of this method to other data modalities\n\n\nThanks for the suggestion. It would be interesting to apply Analytic-DPM to other data modalities, e.g. speech data [1*]. We leave it for future work and have added a discussion in Appendix H.4. \n\n## Q2: Performance of Analytic-DPMs on methods that learn forward process variance schedules\n\nThanks for the suggestion. As presented in Appendix E, our method can be applied to VDMs and we're trying to reproduce VDMs. We leave it for future work. \n\n[1*] Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. Wave-grad: Estimating gradients for waveform generation."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "cIBwEZZBTHo",
        "original": null,
        "number": 13,
        "cdate": 1636980942540,
        "mdate": 1636980942540,
        "ddate": null,
        "tcdate": 1636980942540,
        "tmdate": 1636980942540,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "19df0k-PGMz",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to reviewer Qdy8",
          "comment": "We thank reviewer Qdy8 for the acknowledgement of our contributions and the valuable comments.\n\n## Q1: Practical implication of Proposition 1\n\nThanks for the question. Currently, Proposition 1 is purely theoretical and its practical implication is unclear. We have clarified this in Section 5 in the revised version.\n\n\n## Q2: Whether timestep is a good metric to measure efficiency in Table 3\n\nSince the score-based models are nearly the same for all methods compared in Table 3, it is natural to compare the number of timesteps, or equivalently the number of model function evaluations, for efficiency. In fact, we have validated that the averaged time of a single model function evaluation in compared methods are almost the same, as presented in Appendix F.5 (Table 4) in the revised version. Also see our response to common concern 2 for more discussion about the efficiency.\n\n## Q3: Should the comparison to other classes of generative models be conducted or not\n\nThanks for the suggestion. The primary focus of our work is on improving the performance and efficiency of DPMs. Thereby, DPMs and their variants serve as the most direct baselines to validate the effectiveness of the proposed method. Despite this, we have added a new table (Table 10) in Appendix G.8 of the updated version to compare with other classes of generative models including GAN, VAE, Flow and EBM. As shown in Table 10, Analytic-DPM achieves competitive sample quality results among various generative models, and meanwhile significantly reduces the efficiency gap between DPMs and other models.\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "QbB3q0ViKKd",
        "original": null,
        "number": 14,
        "cdate": 1636981064186,
        "mdate": 1636981064186,
        "ddate": null,
        "tcdate": 1636981064186,
        "tmdate": 1636981064186,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "BN1_YyCfcR-",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to reviewer a5eg",
          "comment": "We thank reviewer a5eg for the positive comments and valuable suggestions.\n\n## Q1: On the connection to other Gaussian models and their results\n\nWe appreciate the reviewer for the valuable comment. Below, we directly compare our theoretical results to existing work, especially expectation propagation (EP) with Gaussian process (GP) (e.g., [1*]).\n\nIt is true that both EP and Analytic-DPM use moment matching as a key step to find analytic solutions of $KL(p_{target}||p_{opt})$ terms, and we provide a full proof of moment matching for completeness. However, to our knowledge, the connection of moment matching and DPMs has not been revealed in prior literature. \nFurther, compared to EP, we emphasize that it is highly nontrivial to calculate the second moment of $p_{target}$ in DPMs because $p_{target}$ involves an unknown and potentially complicated data distribution.\n\n\n* In EP with GP (e.g., [1*]), $p_{target}$ is the product of a single likelihood factor and all other approximate factors for tractability. In fact, the form of the likelihood factor is chosen such that the first two moments of $p_{target}$ can be easily computed or approximated.\nFor instance, the original EP [2*] considers Gaussian mixture likelihood (or Bernoulli likelihood for classification) and the moments can be directed obtained by the properties of Gaussian (or integration by parts). Besides, at the cost of the tractability, there is no converge guarantee of EP in general. \n\n* In contrast, $p_{target}$ in our paper is the conditional distribution $q(x_{n-1}|x_n)$ of the corresponding joint distribution $q(x_{0:N})$ defined by the forward process.\nNote that the moments of $q(x_{n-1}|x_n)$ are nontrivial to calculate because it involves an unknown and potentially complicated data distribution.\nTechnically, in Lemma 13, we carefully use the law of total variance conditioned on $x_0$ and convert the second moment of $q(x_{n-1}|x_n)$ to that of $q(x_0|x_n)$,\nwhich can be expressed as the score function surprisingly as proven in Lemma 11. This is regarded as a novel and insightful contribution to the literature of DPMs by reviewers FHw9, Xtgn and Qdy8.\n\n\nWe have revised Section 3 to emphasize our technical contributions and added a comparison to EP with GP in Appendix H.3.\n\n\n[1*] Hyun-Chul Kim and Zoubin Ghahramani. Bayesian gaussian process classification with the em-epalgorithm.\n\n[2*] Thomas Peter Minka. A family of algorithms for approximate Bayesian inference.\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "5-XbDsTTEcy",
        "original": null,
        "number": 15,
        "cdate": 1636981254968,
        "mdate": 1636981254968,
        "ddate": null,
        "tcdate": 1636981254968,
        "tmdate": 1636981254968,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "Pm0oyznxmaz",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to reviewer ejLx",
          "comment": "We thank reviewer ejLx for the acknowledgement of our contributions and the valuable comments.\n\n## Q1: Compare the clipping at $n=2$ to bounds in Theorem 2\n\nThanks for the suggestion. We compare them as suggested and the former is 1 to 3 orders of magnitude smaller than the latter, when $K$ is small (e.g., $K<100$). Please see Table 7 of Appendix G.4 in the updated revision for details. We have added more discussion to the main paper (see Section 6) in the updated version. \n\n\n\n\n## Q2: The post-processing method can be quite expensive and the fairness under the OT setting\nThanks for the valuable comment.\n\n* Suppose we perform inference on $M_1$ samples. The relative additional cost of Analytic-DPM is $\\frac{M N}{M_1 K}$ (please see details in our response to common concern 2). In our experiments, we found that a smaller $M$ (e.g., $M=10$) is sufficient for Analytic-DPM (please see our response to common concern 1 (1.2)), making the relative additional cost small if not negligible. For instance, on CIFAR10, let $M=10$, $N=1000$, $M_1=50000$ and $K\\ge 10$, we obtain $\\frac{M N}{M_1 K}\\le 0.02$ and Analytic-DPM still consistently improves the baselines as presented in Table 2*. \n\n* Further, the additional calculation of the Monte Carlo estimate $\\Gamma$ occurs only **once** given a pretrained model and training dataset, since we can save the results of $\\Gamma = (\\Gamma_1, \\cdots, \\Gamma_N)$ in Eq.(8) and reuse it among different inference settings (e.g., trajectories of various $K$). The reuse is valid, because the marginal distribution of a shorter forward process $q(x_0, x_{\\tau_1}, \\cdots, x_{\\tau_K})$ at timestep $\\tau_k$ is the same as that of the full-timesteps forward process $q(x_{0:N})$ at timestep $n=\\tau_k$. Indeed, in our experiments (e.g., Table 1,2), $\\Gamma$ is shared across different selections of $K$, trajectories and forward processes.\n\n* Finally, the DDPM with OT [4] also requires a post-processing of $M N$ additional function evaluations (see Section 4.3 in [4]) before getting the optimal trajectory. Thereby, under the OT setting, DDPM and Analytic-DDPM have the same function evaluations, and the comparison is fair.\n\nPlease see more details in the common concern 2.\n\n[4] Watson et al. Learning to Efficiently Sample from Diffusion Probabilistic Models. arXiv:2106.03802.\n\n## Q3: How often the estimate is actually clipped\n\nThanks for the valuable suggestion. We have plotted the ratio of estimates that were clipped over different $M$ and $n$ in Figure 9 (Appendix G.3 in the revised version). For all $M$, the curves of the ratio v.s. $n$ are similar, and the estimate is clipped more frequently when $n$ is large. This is as expected because when $n$ is large, the gap between the upper bound in Eq. (12) and the lower bound in Eq. (11) tends to zero. The results also agree with the plot of the bounds in Figure 5 (Appendix G.3 in the original paper).\n\n\n## Q4: The estimate is biased even when the correct score is known\n\nThanks for the suggestion. We have explicitly mentioned it in Section 4. \n\n\n## Q5: Lower $M$ and plotting variance\n\nThanks for the suggestion. We added the results of Analytic-DPM over a wide range of $\\{1,3,10,100,10000,50000\\}$.\nUnder both the NLL and FID metrics, $M=10$ achieves similar results to that of $M=50000$. The results are presented in Table 1*. Please see details in our response to common concern 1 (1.2).\n\nBesides, we plotted the standard deviations of the estimate when $M=1,10,100$ and the results agree with those in Figure 3 in the original paper. We have added the new results to Appendix G.2 in Figure 4\\&5 in the revised version. See details in our response to common concern 1 (1.3). \n\n## Q6: The number of Monte Carlo samples used for results in Tables 1,2,3\n\nThanks for the suggestion. We set $M=50000$ on CIFAR10, $M=10000$ on CelebA 64x64 and ImageNet 64x64 and $M=1000$ on LSUN Bedroom by default without a sweep. See details in our response to common concern 1 (1.1).\n\n## Q7: The optimal variance could also be used for training\n\nThanks for the insightful suggestion. It is a promising future work and we have added a discussion in Section H.4.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "PKNBb6YvQ07",
        "original": null,
        "number": 16,
        "cdate": 1636984632347,
        "mdate": 1636984632347,
        "ddate": null,
        "tcdate": 1636984632347,
        "tmdate": 1636984632347,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Summary of the revision",
          "comment": "We sincerely thank all the reviewers for the valuable comments, which help to improve the quality of our work. We summarize the revision in the updated version as follows:\n* We revised Section 3 to emphasize our technical contributions\n* We moved Proposition 1 to Appendix A.5, and added more discussion of it in Section 5\n* We moved some experimental details to the main paper (see Section 6) and added missing ones (see Appendix F.3\\&F.5)\n* We added more experiments on the number of Monte Carlo samples (see Appendix G.2)\n* We added more experiments on the bounds of Theorem 2 (see Appendix G.3)\n* We showed values of clipping thresholds at $n=2$ (see Table 7)\n* We added a comparison to other classes of generative models (see Appendix G.8)\n* We added discussion on the extra cost of the Monte Carlo estimate (see Appendix H.1)\n* We added discussion on the stochasticity of the variational bound (see Appendix H.2)\n* We added a comparison to other Gaussian models (see Appendix H.3)\n* We added discussion on future works (see Appendix H.4)\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "alt999_6IL-",
        "original": null,
        "number": 17,
        "cdate": 1637014400742,
        "mdate": 1637014400742,
        "ddate": null,
        "tcdate": 1637014400742,
        "tmdate": 1637014400742,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "uy5TVszw4vk",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Thanks",
          "comment": "Thanks for the updates. I read the author's response and will keep my recommendation."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_FHw9"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_FHw9"
        ]
      },
      {
        "id": "cvBK6anXEEU",
        "original": null,
        "number": 18,
        "cdate": 1637254030514,
        "mdate": 1637254030514,
        "ddate": null,
        "tcdate": 1637254030514,
        "tmdate": 1637254030514,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "5-XbDsTTEcy",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to the authors",
          "comment": "I thank the authors for clarifying most of my questions as well as incorporating my suggestions in their paper. \n\nI only want to follow up on one point: the authors say that \"[...] the DDPM with OT [4] also requires a post-processing of $MN$ additional function evaluations (see Section 4.3 in [4]) before getting the optimal trajectory. Thereby, under the OT setting, DDPM and Analytic-DDPM have the same function evaluations, and the comparison is fair.\"\n\nI don't understand why a plain DDPM would need $MN$ function evaluations. The $M$ refers to the number of Monte Carlo samples to compute $\\Gamma_n$ (which is specific to Analytic-DDPM) so it would not apply to plain DDPM? Wouldn't DDPM only need $N$ function evaluations? Could the authors clarify?\n\n[4] Watson et al. Learning to Efficiently Sample from Diffusion Probabilistic Models. arXiv:2106.03802."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ]
      },
      {
        "id": "17k7cmFvw78",
        "original": null,
        "number": 19,
        "cdate": 1637295906607,
        "mdate": 1637295906607,
        "ddate": null,
        "tcdate": 1637295906607,
        "tmdate": 1637295906607,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "cvBK6anXEEU",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Thanks for the valuable question",
          "comment": "Thanks for the valuable question.\n\nIndeed, in order to get the optimal trajectory for DDPM, we need to calculate every term $L(t, s)$ (see Eq.(17) in [4]) appeared in the variational bound. $L(t, s)$ has an expectation term and this term is estimated by $M$ Monte Carlo samples. Empirically, the $M$ samples are drawn from the training dataset. Here we also use $M$ to denote the number of Monte Carlo samples as Analytic-DPM.\n\n\nFormally, $L(t, s)=\\mathbb{E}_q KL(q(x_s|x_t,x_0)||p(x_s|x_t))$ when $s>0$, which can be written as \n\n$$\nL(t, s)=\\frac{d}{2} [  C_{t,s} + A_{t,s} \\mathbb{E}_q || x_0 - \\frac{1}{\\sqrt{\\bar{\\alpha}}_t}(x_t + \\bar\\beta_t s_t (x_t) ) ||^2 / d ],\n$$\n\n\nwhere $C_{t,s},A_{t,s}$ are only related to the forward variance $\\beta_1,\\cdots,\\beta_N$ and  $\\mathbb{E}_q || x_0 - \\frac{1}{\\sqrt{\\bar\\alpha_t}}(x_t + \\bar\\beta_t s_t (x_t) ) ||^2 / d$ is the expectation term to estimate. Similarly, the expectation term also appears in $L(t, s)$ when $s=0$.\n\nThe expectation term is estimated using $M$ Monte Carlo samples:\n\n$$\n\\Phi_t = \\frac{1}{M} \\sum_{m=1}^M || x_{0,m} - \\frac{1}{\\sqrt{\\bar\\alpha_t}}(x_{t,m} + \\bar\\beta_t s_t (x_{t,m}) ) ||^2 / d, \\quad  x_{0,m}, x_{t,m} \\sim q(x_0,x_t).\n$$\n\nThereby, each $\\Phi_t$ requires $M$ function evaluations. To calculate $\\Phi_t$ for all $t=1,\\cdots,N$, we need a total of $MN$ function evaluations.\n\nAs a result, the post-processing of DDPM also requires $MN$ function evaluations.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "6-hBrDvWYIx",
        "original": null,
        "number": 20,
        "cdate": 1637332383376,
        "mdate": 1637332383376,
        "ddate": null,
        "tcdate": 1637332383376,
        "tmdate": 1637332383376,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "17k7cmFvw78",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Response to the authors",
          "comment": "I thank the authors again for clarifying: please see **post discussion period update** in my **Summary Of The Review**."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ]
      },
      {
        "id": "SZv7JEBy99Z",
        "original": null,
        "number": 21,
        "cdate": 1637334803483,
        "mdate": 1637334803483,
        "ddate": null,
        "tcdate": 1637334803483,
        "tmdate": 1637334803483,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "6-hBrDvWYIx",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Thanks for the update",
          "comment": "Thanks for the update. We highly appreciate it."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "kKwOMqRIsIH",
        "original": null,
        "number": 23,
        "cdate": 1637381835282,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637381835282,
        "tmdate": 1637382861581,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "QbB3q0ViKKd",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Thanks for your reply",
          "comment": "Thanks for your replies to all reviews and I have read all of them. The Monte Carlo approximation in other reviews is very common in the Bayesian community when estimating a term that has no closed-form expression and I have no concern about it. The above reply is helpful and I realize that the specific study on the conditional Gaussian with a more complicated mean is non-trivial and can be very helpful for a series of models. As other reviewers point out, this paper is novel in the community of DPMs, so I upgrade my recommendation. Also, I would keep suggesting that it is helpful to discuss some Bayesian works which also rely on similar measures between p_target and p_opt and obtain analytic results. Please also take the related works about the Gaussian Markov process into account, because it is very related to DPMs. The difference or similarities will be helpful for future works along this line."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_a5eg"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_a5eg"
        ]
      },
      {
        "id": "1vNHmSJs_85",
        "original": null,
        "number": 24,
        "cdate": 1637383220318,
        "mdate": 1637383220318,
        "ddate": null,
        "tcdate": 1637383220318,
        "tmdate": 1637383220318,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "kKwOMqRIsIH",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Thanks for the update!",
          "comment": "Thank you very much for the valuable suggestions and the update on the score. We highly appreciate it."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "aYB2hWSIubo",
        "original": null,
        "number": 1,
        "cdate": 1642696845668,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696845668,
        "tmdate": 1642696845668,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Accept (Oral)",
          "comment": "This paper presents an analytic approach for estimating the optimal reverse variance schedule given a pre-trained score-based model. The experimental results demonstrated the efficacy of the proposed method on several datasets across different sampling budgets. Given the recent interest in score-based generative models, I believe that the paper will find applications in various domains. I am pleased to recommend it for acceptance."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "directReplies": [
      {
        "id": "Pm0oyznxmaz",
        "original": null,
        "number": 1,
        "cdate": 1635266291619,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635266291619,
        "tmdate": 1637332603753,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "In Sec. 2, the authors review the general framework of Diffusion Probabilistic Models~(DPMs) with non-Markovian forward processes from [1] which has DDPMs [2] and DDIMs [1] as special cases. They emphasize that the variance of the reverse process, such as in DDPM and DDIM, are generally hand-crafted.\n\nIn Sec. 3, the authors present their main theorem: the optimal variance of the reverse process at step $n$ is a linear function of the expected squared norm of the score at step $n$. As a post-processing scheme of learned models, they then propose to replace the commonly used hand-crafted variances by an estimator of their optimal variance: in particular, the score is replaced by the learned score model and the expectation is replaced by a Monte Carlo estimate (with $M$ samples) thereof. In the remainder of this section, the authors derive bounds for the optimal variance and state that in practice their estimator is clipped according to these bounds.\n\nIn Sec. 4, the authors repeat the derivation of an optimal variance and bounds thereof when only a subset (of size $K$) of the $N$ timesteps are used for inference as is very common in the literature [1, 3, 4]. Furthermore, they show how their estimator in this setting can be used to still compute the optimal subset according to the commonly used DP algorithm introduced in [4].\n\nIn Sec. 6, they apply their post-processing scheme to models trained on CIFAR-10, CelebA 64 and ImageNet 64 and show that it generally leads to improved likelihood and FID scores. They show that their post-procecssing scheme consistently outperforms suboptimal hand-crafted choices (such as in DDPM and DDIM).\n\nReferences:\n\n[1] Song et al. Denoising Diffusion Implicit Models. ICLR 2021.\n\n[2] Ho et al. Denoising Diffusion Probabilistic Models. NeurIPS 2020.\n\n[3] Dhariwal & Nichol. Diffusion Models Beat GANs on Image Synthesis. arXiv:2105.05233.\n\n[4] Watson et al. Learning to Efficiently Sample from Diffusion Probabilistic Models. arXiv:2106.03802.",
          "main_review": "Strengths:\n- Paper has single well-executed idea (optimal variance can be computed as a function of score) \n- Improvements over generally fair base lines are achieved by only post-processing; no additional training needed\n- Paper is generally well-written and straightforward to read\n- I did not check all Lemmas (appendix) in detail, however, it seems that their proofs are generally very rigorous and detailed.\n- The bounds in Theorem 2 are quite nice. Given that DPMs are often used for images, the specific bound for the data distributions supported in the $d$-dimensional cube are quite applicable.\n\nWeaknesses:\n- For $K<100$, FID scores of the proposed method greatly rely on a trick of clipping the variance of the step $n=2$ (can be seen in appendix G.4). This seems to be a crucial element and should be discussed more in the main paper. In particular, I would like to see how this clipping compares to the bounds (and the clipping) of the optimal score wrt Theorem 2.\n- The post-processing method can be quite expensive. For example, on ImageNet the best values are achieved using $MK= 400000$ additional ($M=100, K=N=4000$) function evaluations. For even trajectories (ET), the obvious solution would be to simply use $K \\ll N$ (results for this are shown in paper), however, if I am not mistaken, for the optimal trajectory (OT), computed using the DP algorithm from [4], $MN$ functions have to be evaluated for any $K$ (see appendix B and eq (14)). Therefore, in my opinion, the comparison of DDPM and Analytic=DDPM in the OT setting of Table 1 is unfair.\n\nSuggestions:\n- It would be helpful to understand how often the estimator is actually clipped. I suggest to compute $R$ (maybe $R=100$) estimators for, say $M=[1,10, 50, 100, 500, 1000]$, and plot he number of the ratio of estimators that was clipped over $M$. This could be done for a few different instantiations of $n$ (I guess there will be more clipping for $n$ being small).\n- the estimator $J$ in (14) is biased even when the correct score is known ($J$ is the log of an unbiased (Monte Carlo) estimator); it might be nice to mention this fact.\n- It would be nice to see even lower $M$ in the ablations in G.2. Instead of only indicating variance by plotting the estimator in Figure 3, it would be nice to see the estimated variance of the sampler directly.\n- Please state the number of Monte Carlo samples used for results in Tables 1,2,3.\n- To me it seems that the optimal variance could also be used for training, using for example only $M=1$. I would be curious to see how this performs compared to using the optimal variance only as a guide for post-processing. I greatly encourage the authors to try this (in case there are no major problems I am missing)",
          "summary_of_the_review": "Overall, I vote for accepting. The paper provides an important insight in DPMs and shows improved results for pretrained models by a simple post-processing technique. My major concern about the paper is that OT [4] does not work well in combination with their method, which in my opinion makes the work slightly less significant. I hope the authors can address this concern in the rebuttal period.\n\n**Post discussion period update:**\nI strongly vote for accepting (and also changed the correctness score from 3 to 4). All of my concerns, questions, and suggestions have been addressed by the authors in the discussion period. I thank the authors for this productive reviewing process.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_ejLx"
        ]
      },
      {
        "id": "BN1_YyCfcR-",
        "original": null,
        "number": 2,
        "cdate": 1635580753708,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635580753708,
        "tmdate": 1637381858710,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper studies an estimate of the reverse process of a diffusion probabilistic model (DPM). The reverse process is usually estimated by minimizing the KL divergence between the forward and the reverse process. Authors present that the optimal mean and variance of the reverse process have analytic forms w.r.t. the score function. The form of the optimal mean coincides with the parameterization in the previous work and justifies a reweighted variant of the variational bound proposed in the recent work. Different from the handcrafted strategies employed in other work, the authors propose a novel estimation for the variance and analyze its bias. To reduce the bias, bounds of the optimal reverse variance are analyzed and the estimate is clipped based on the bound. Furthermore, the KL divergence between the forward and the optimal reserve process also has an analytical form and as a result, the authors propose the optimal trajectory which has minimal KL value. Finally, the authors present the relationship between the score function and the data covariance matrix and assess the proposed approach in the experiments. The experiment results show that the analytic results improve the efficiency, likelihood, and sample quality.",
          "main_review": "Strengths:\n\n1. The paper is clearly written and well organized. Contents are easy to follow. There are many technical details for readers to understand the results, such as the derivation of Theorem 1.\n\n2. The analytic results are interesting and novel. According to the introduction and the related work sections, the optimal forms of the reverse process of DPM didn't appear in the previous DPM work and I believe it will help people in the field of DPM better understand this type of models. The bias analysis and the bound of the variance are helpful to understand the estimate and improve the estimate performance. The authors also make detailed discussions on these results, which are very helpful.\n\n3. The experiment results are strong. The authors not only validate their analytic forms but also present the outperformance of their methods. The experiment results show significant improvements in their methods.\n\nWeaknesses:\n\n1. The DPM is a Gaussian-distribution-based simple model and similar analytic results can exist in similar models. The Gaussian model considered in this paper has a simple Markov property, which as a result has decomposable probability. The optimization is via forward KL divergence. Therefore, for example, the classical result on the expectation propagation algorithm with the Gaussian process can simplify the derivation: the decomposable form of the probability guarantees the forward KL decomposable, and minimizing the forward KL is equivalent to moment matching. So, I am concerned that the contribution is not as much as what was introduced in the paper. I also believe that such kind of connection will be helpful to figure out the possible further directions along this line and also save energy to get new results. I suggest authors add some discussions on the connection to other Gaussian models and their results.",
          "summary_of_the_review": "The paper contributes interesting analytic results to the DPM models and the methods perform well in practice. However, the DPM is a simple Gaussian model and similar results can appear in other similar models.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_a5eg"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_a5eg"
        ]
      },
      {
        "id": "19df0k-PGMz",
        "original": null,
        "number": 3,
        "cdate": 1635920012833,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635920012833,
        "tmdate": 1635920012833,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed a modification of the diffusion probabilistic models (DPMs) called analytic-DPM that is based on an analytic estimate of the optimal reverse variance. Using this analytic estimate, the proposed method can achieve fast and performant inference through the Monte Carlo method and pre-trained score-based model. The derivation of the optimal reverse analytic mean and variance is proven to be associated with the score function. Upper bounds and lower bounds are provided for the optimal reverse variance, the relationship between the data covariance and the score function is shown. Experimental results are provided by comparing the proposed method with existing variants of DPMs, through both negative log-likelihood and FID as metrics. The experimental results suggest that the proposed method can potentially provide better performance more efficiently compared to alternatives.",
          "main_review": "Strength:\n1. the paper derives the optimal reverse variance for diffusion probabilistic models as well as its lower and upper bound. This leads to more efficient DPMs with better performance compared to existing DPM variants. It also leads to new insights into DPMs such as why the way the reversed variance is chosen by existing work is not ideal.\n\n2. The paper is clearly presented. The technical results reported in the paper are non-trivially obtained. The relationship between the paper and existing works is well discussed and well-motivated.\n\n3. Experimental results compared to other variants of DPM are well discussed. It also demonstrates the advantage of the proposed method compared to existing DPM variants.\n\nWeakness:\n1. Although proposition 1 establishes the relationship between data covariance and score function, it is unclear to me what is the practical implication of proposition 1.\n\n2. In the experiment, it is unclear to me whether timestep is a good metric to measure efficiency in Table 3. Does each method spend roughly the same time at each timestep?\n\n3. While the authors compare the proposed method with other existing variants of DPMs. Is there any reason why the comparison between the proposed method and other classes of generative models such as GAN should be conducted or not?\n\n",
          "summary_of_the_review": "Correctness: I think the paper is mostly correct. I am not sure if using timestep is a good metric to demonstrate the efficiency of the proposed method. Since efficiency is a major aspect of the proposed method, it would be desirable to make a clarification on this issue.\n\nNovelty and significance: I think the derivation of the optimal reverse variance is novel and insightful. The lower bound and upper bound of the optimal reverse variance is also useful in practice. While the proposed method is performant compared to existing DPM variants, these existing variants achieve better or comparable FID or negative log-likelihood with enough timesteps. These strong baselines suggest the (potentially limited) headroom left for improvement for the proposed method.\n\nOverall, I think the paper solves an interesting problem in DPM. ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "Yes, Potentially harmful insights, methodologies and applications"
          ],
          "details_of_ethics_concerns": "Performant generative models can be misused in situations such as deep fake. ",
          "recommendation": "8: accept, good paper",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Qdy8"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Qdy8"
        ]
      },
      {
        "id": "4Qh32Izg8a5",
        "original": null,
        "number": 4,
        "cdate": 1636121638776,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636121638776,
        "tmdate": 1636121638776,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposes a theoretically grounded method for estimating *optimal* reverse process variances for DDPMs and DDIMs. This method can be applied to a trained DDPM / DDIM after the fact and lead to improved likelihoods and faster sampling (when used together with optimal trajectory search). The proposed method and theoretical insights also perform strongly in practice across a range of models and datasets.",
          "main_review": "**Strengths**\n* Strong theoretical motivation and strong empirical results to support it.\n* Nicely written, does a great job putting prior work in the context of the new insights on optimal reverse mean and variance.\n* Despite the abundance of theory / derivations, the paper still remains accessible.\n\n**Weaknesses**\n\nI am convinced by the paper in its current form. But if I had to list something:\n* It would be great to see applications of this method to other data modalities, such as for example speech / sound generation.\n* The performance of Analytical-DPMs on methods that learn forward process variance schedules (e.g. VDMs) would also be great to see.",
          "summary_of_the_review": "The paper provides valuable insights into optimal reverse process variance of DDPMs and DDIMs, and makes connections between the proposed optimal variance and previous handcrafted choices, etc. The improved understanding of these model classes could have been sufficient to recommend acceptance. However, the empirical results, especially those around faster sampling are also strong and convincing. DDPMs / DDIMs achieve high sample quality and it's primarily their sampling speed that prevents practical application off this model class in real-world systems. This works makes a significant step towards enabling faster sampling for this model class.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Xtgn"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_Xtgn"
        ]
      },
      {
        "id": "HVoY12Mc5YC",
        "original": null,
        "number": 5,
        "cdate": 1636179057869,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636179057869,
        "tmdate": 1636179971025,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper studies diffusion probabilistic models, and derives the optimal mean and variance (as functions of the expected data score) for the reverse process. Authors then propose to plug in a Monte Carlo estimate of the the variance for the reverse process and experimentally show how this leads to improved results with trained and/or pretrained models in terms of FID and NLL. In addition, authors combine their approach with recent work that optimizes for \"knot\" locations given a fixed number of knots for faster sampling. ",
          "main_review": "**novelty, significance**\n\nThe result on optimal variance is new, to the best of my knowledge. The authors also do a reasonable job in convincing me that a Monte Carlo estimate of it is useful for inference. Given the recent progress and interest on DPMs, I think this work will also have reasonable significance and influence. \n\n**presentation**\n\nAuthors do a reasonable job on the writing and presenting experimental results. Past works are adequately and appropriately cited, to the best of my knowledge. \n\n**Technical quality and correctness**\n\nOne thing I'll add here is that once the Monte Carlo estimate of $\\sigma_t^2$ is plugged into the bound computation, it seems we end up with a stochastic lower bound of the ELBO (assuming the loss is concave in $\\sigma_t^2$). The important thing here to note perhaps is that bias is introduced. To put it more concretely, say the quantity being estimated is $\\mathbb{E}[ f(\\sigma_t^2) ]$, where I've written the bound as the expectation of the loss $f$ as a function of $\\sigma_t^2$. The estimator $f(\\hat{\\sigma}_t^2)$ is now a stochastic lower bound on the original quantity by Jensen's, since \n$$\\mathbb{E} [f(\\hat{\\sigma}_t^2)] \\le \\mathbb{E} [f( \\mathbb{E} [ \\hat{\\sigma}_t^2 ] ) ]  = \\mathbb{E} [f( \\sigma_t^2)].$$\n\nI think there should be some discussion about this. I'm assuming $f$ is concave in $\\sigma_t^2$, mostly reasoning from past bounds, but authors should perhaps make parts of the discussion more precise. \n\n**Experimental results**\n\nAuthors do a reasonable job in evaluating their method. One particular point I didn't get is how $M$ (number of samples for estimating the expected score) is chosen. The are a couple of potential issues here.\n- Selecting $M$ requires additional hyperparameter tuning, potentially; the tuning procedure should be reported. \n- How results depend on $M$ isn't entirely clear just from reading the main text (maybe there's some discussion in the appendix, but I didn't have time to read all content in the appendix). Ideally, some discussions should appear in the main text.\n- Large $M$ incurs more compute cost during inference -- while this seems less an issue when inference is run on GPUs (since most scenarios, I'd guess, there's enough cores to parallelize the Monte Carlo samples), this could be an issue for CPU inference. How does the run-time in practice compare in this case? Note while practical systems don't tend to run training on CPUs, inference on CPUs is still quite common. ",
          "summary_of_the_review": "Authors study choosing the optimal variance for the reverse process in DPMs and propose to Monte Carlo estimate it for improved inference.  Technical quality, writing, and experiments are mostly good with the two minor caveats I described above. \n",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "8: accept, good paper",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Reviewer_FHw9"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Reviewer_FHw9"
        ]
      },
      {
        "id": "o0QJ34P13kk",
        "original": null,
        "number": 9,
        "cdate": 1636978709495,
        "mdate": 1636978709495,
        "ddate": null,
        "tcdate": 1636978709495,
        "tmdate": 1636978709495,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Common concern 1",
          "comment": "We thank all the reviewers for their appreciation of our novel contributions as well as the valuable comments, which help to further improve. Below, we first address some common concerns. Then, we address the individual comments to each reviewer.\n\n## Common concern 1 (from reviewers FHw9, ejLx): The tuning procedure of $M$ and more experiments on varying $M$\n\nWe clarify how $M$ is selected in the original paper and add more experiments on varying $M$.\n\n### 1.1 The tuning procedure of $M$ in the original paper\n\nWe did not tune $M$ in the original paper. In fact, we used a maximal $M$ without introducing too much computation. Specifically, we set $M=50,000$ on CIFAR10, $M=10,000$ on CelebA 64x64 and ImageNet 64x64 and $M=1,000$ on LSUN Bedroom by default without a sweep. \nAll of the samples are from the training dataset. We used the default settings of $M$ for all results in Tables 1, 2 and 3. We have added the experimental details in Appendix F.3 in the revised version.\n\n\n### 1.2. How results depend on $M$\n\nIn Appendix G.2 of the original submission, we evaluated Analytic-DPM with $M=100$ and found that it has a small variance and achieves  almost the same NLL results as those of $M=50,000$.\n\nFollowing the reviewers' suggestion, we added the results of Analytic-DPM over a wide range of $M \\in \\\\{1,3,10,100,10000,50000\\\\}$.\nUnder both the NLL and FID metrics, $M=10$ achieves similar results as those of $M=50,000$ on CIFAR10 (LS) and those of $M=10,000$ on ImageNet 64x64. The results are presented in Table 1* below. \nWe have also added the results to Appendix G.2 in Table 5 in the revised version.\n\n\n| CIFAR10 (LS) | NLL $\\downarrow$ | FID $\\downarrow$ |  ImageNet 64x64 | NLL $\\downarrow$ | FID $\\downarrow$ |  \n|  ----        | ----        | ----        |  ----          | ----       | ----        |\n| $M=1$        | 6.220\u00b11.126 | 34.05\u00b14.97 | $M=1$          | 4.943\u00b10.162 | 31.59\u00b15.11 |\n| $M=3$        | 5.689\u00b10.424 | 34.29\u00b12.88 | $M=3$          | 4.821\u00b10.055 | 31.98\u00b11.19 |\n| $M=10$       | 5.469\u00b10.005 | 33.69\u00b12.10 | $M=10$         | 4.791\u00b10.017 | 31.93\u00b11.02 |\n| $M=100$      | 5.468\u00b10.004 | 34.63\u00b10.68 | $M=100$        | 4.785\u00b10.003 | 31.93\u00b10.69 |\n| $M=50000$    | 5.471       | 34.26      | $M=10000$      | 4.783       | 32.56      |\n\nTable 1*: FID and NLL results of Analytic-DPM with different $M$. We use $K=10$ for CIFAR10 (LS) and $K=25$ for ImageNet 64x64.\n\n\n### 1.3. The variance of the estimate $\\Gamma_n$ over different $M$\n\nWe plotted the standard deviations of the estimate $\\Gamma_n$ at different timesteps $n$ when $M\\in \\\\{1,10,100\\\\}$. \nIn all cases, the variance decays fast as $n$ increases. Further, $M=10$ is sufficient to achieve a small standard deviation relative to the mean (e.g. less than 10\\% of the mean) for all $n$. \nSee Figures 4\\&5 in Appendix G.2 of the revised version for the results.\n\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "jiVwWLSUOgh",
        "original": null,
        "number": 10,
        "cdate": 1636979464695,
        "mdate": 1636979464695,
        "ddate": null,
        "tcdate": 1636979464695,
        "tmdate": 1636979464695,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Common concern 2",
          "comment": "\n## Common concern 2 (from reviewers FHw9, ejLx): The extra cost of the Monte Carlo estimate $\\Gamma_n$\n\n* The extra cost of the Monte Carlo estimate is small compared to the whole inference cost.\nIn fact, the Monte Carlo estimate requires $M N$ additional function evaluations. \nDuring inference, suppose we generate $M_1$ samples or calculate the log-likelihood of $M_1$ samples with $K$ timesteps. Both DPMs and Analytic-DPMs need $M_1 K$ function evaluations. Employing the same score-based models, the relative additional cost of Analytic-DPM is $\\frac{M N}{M_1 K}$. In our experiments, we found that a very small $M$ (e.g., $M=10$ or $100$) is sufficient for Analytic-DPM (see our response to common concern 1 (1.2 and 1.3)), making the relative additional cost small if not negligible. For instance, on CIFAR10, let $M=10$, $N=1000$, $M_1=50000$ and $K\\ge 10$, we obtain $\\frac{M N}{M_1 K}\\le 0.02$ and  Analytic-DPM still consistently improves the baselines as presented in Table 2* below. We have also added the results to Appendix G.2 in Table 6 in the revised version.\n\n\n* Further, the additional calculation of the Monte Carlo estimate occurs only **once** given a pretrained model and training dataset, since we can save the results of $\\Gamma = (\\Gamma_1, \\cdots, \\Gamma_N)$ in Eq.(8) and reuse it among different inference settings (e.g., trajectories of various $K$). The reuse is valid, because the marginal distribution of the shorter forward process $q(x_0, x_{\\tau_1}, \\cdots, x_{\\tau_K})$ at timestep $\\tau_k$ is the same as that of the full-timesteps forward process $q(x_{0:N})$ at timestep $n=\\tau_k$. Indeed, in our experiments (e.g., Table 1,2), $\\Gamma$ is shared across different selections of $K$, trajectories and forward processes. Moreover, in practice, $\\Gamma$ can be calculated offline and deployed together with the pretrained model and the online inference cost of Analytic-DPM is exactly the same as DPM.\n\nWe have updated Section 3 and added Appendix H.1 in the revised version to address this comment.\n\n\n| # timesteps $K$ | 10 |  25 | 50 | 100 |  200 | 400 |\n| ---- | ---- | ---- | ---- | ---- | ---- | ---- |\n| NLL $\\downarrow$ |\n| Analytic-DDPM ($M=10$) | 5.47 | 4.80 | 4.38 | 4.07 | 3.85 | 3.71 |\n| DDPM        | 6.99 | 6.11 | 5.44 | 4.86 | 4.39 | 4.07 |\n| FID $\\downarrow$ |\n| Analytic-DDPM ($M=10$) | 33.69 | 11.99 | 7.24 | 5.39 | 4.19 | 3.58 |\n| DDPM        | 44.45 | 21.83 | 15.21 | 10.94 | 8.23 | 4.86 |\n\nTable 2*: The NLL and FID comparison between Analytic-DDPM with $M=10$ Monte Carlo samples and DDPM on CIFAR10 (LS).\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "PKNBb6YvQ07",
        "original": null,
        "number": 16,
        "cdate": 1636984632347,
        "mdate": 1636984632347,
        "ddate": null,
        "tcdate": 1636984632347,
        "tmdate": 1636984632347,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Official_Comment",
        "content": {
          "title": "Summary of the revision",
          "comment": "We sincerely thank all the reviewers for the valuable comments, which help to improve the quality of our work. We summarize the revision in the updated version as follows:\n* We revised Section 3 to emphasize our technical contributions\n* We moved Proposition 1 to Appendix A.5, and added more discussion of it in Section 5\n* We moved some experimental details to the main paper (see Section 6) and added missing ones (see Appendix F.3\\&F.5)\n* We added more experiments on the number of Monte Carlo samples (see Appendix G.2)\n* We added more experiments on the bounds of Theorem 2 (see Appendix G.3)\n* We showed values of clipping thresholds at $n=2$ (see Table 7)\n* We added a comparison to other classes of generative models (see Appendix G.8)\n* We added discussion on the extra cost of the Monte Carlo estimate (see Appendix H.1)\n* We added discussion on the stochasticity of the variational bound (see Appendix H.2)\n* We added a comparison to other Gaussian models (see Appendix H.3)\n* We added discussion on future works (see Appendix H.4)\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper222/Authors"
        ]
      },
      {
        "id": "aYB2hWSIubo",
        "original": null,
        "number": 1,
        "cdate": 1642696845668,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696845668,
        "tmdate": 1642696845668,
        "tddate": null,
        "forum": "0xiJLKH-ufZ",
        "replyto": "0xiJLKH-ufZ",
        "invitation": "ICLR.cc/2022/Conference/Paper222/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Accept (Oral)",
          "comment": "This paper presents an analytic approach for estimating the optimal reverse variance schedule given a pre-trained score-based model. The experimental results demonstrated the efficacy of the proposed method on several datasets across different sampling budgets. Given the recent interest in score-based generative models, I believe that the paper will find applications in various domains. I am pleased to recommend it for acceptance."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "invitation": {
      "reply": {
        "writers": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "signatures": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "content": {
          "title": {
            "value-regex": ".*",
            "order": 1
          },
          "authors": {
            "values": [
              "Anonymous"
            ],
            "order": 2
          },
          "authorids": {
            "value-regex": ".*",
            "order": 3
          },
          "keywords": {
            "value-regex": ".*",
            "order": 6
          },
          "abstract": {
            "value-regex": ".*",
            "order": 8
          },
          "pdf": {
            "value-regex": ".*",
            "order": 9
          },
          "one-sentence_summary": {
            "value-regex": ".*",
            "order": 10
          },
          "supplementary_material": {
            "value-regex": ".*",
            "order": 11
          },
          "code_of_ethics": {
            "value-regex": ".*",
            "order": 12
          },
          "submission_guidelines": {
            "value-regex": ".*",
            "order": 13
          },
          "resubmission": {
            "value-regex": ".*",
            "order": 14
          },
          "student_author": {
            "value-regex": ".*",
            "order": 15
          },
          "serve_as_reviewer": {
            "value-regex": ".*",
            "order": 16
          },
          "community_implementations": {
            "required": false,
            "description": "Optional link to open source implementations",
            "value-regex": ".*",
            "markdown": true,
            "order": 103
          }
        }
      },
      "replyForumViews": [],
      "expdate": 1682960118639,
      "signatures": [
        "ICLR.cc/2022/Conference"
      ],
      "readers": [
        "everyone"
      ],
      "writers": [
        "ICLR.cc/2022/Conference"
      ],
      "invitees": [
        "ICLR.cc/2022/Conference"
      ],
      "tcdate": 1632875419419,
      "tmdate": 1682960118686,
      "id": "ICLR.cc/2022/Conference/-/Blind_Submission",
      "type": "note"
    }
  },
  "tauthor": "OpenReview.net"
}