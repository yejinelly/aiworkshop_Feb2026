{
  "id": "zXne1klXIQ",
  "original": "itzB1R3NQ0U",
  "number": 277,
  "cdate": 1632875441137,
  "pdate": 1643407560000,
  "odate": 1633539600000,
  "mdate": null,
  "tcdate": 1632875441137,
  "tmdate": 1697934947189,
  "ddate": null,
  "content": {
    "title": "Improving Out-of-Distribution Robustness via Selective Augmentation",
    "authorids": [
      "~Huaxiu_Yao1",
      "~Yu_Wang24",
      "saili@ruc.edu.cn",
      "~Linjun_Zhang1",
      "~Weixin_Liang1",
      "~James_Zou1",
      "~Chelsea_Finn1"
    ],
    "authors": [
      "Huaxiu Yao",
      "Yu Wang",
      "Sai Li",
      "Linjun Zhang",
      "Weixin Liang",
      "James Zou",
      "Chelsea Finn"
    ],
    "keywords": [
      "out-of-distribution robustness",
      "distribution shifts",
      "selective data augmentation"
    ],
    "abstract": "Machine learning algorithms typically assume that training and test examples are drawn from the same distribution. However, distribution shifts is a common problem in real-world applications and can cause models to perform dramatically worse at test time. In this paper, we specifically consider the problems of domain shifts and subpopulation shifts, where learning invariant representations by aligning domain-specific representations or balancing the risks across domains with regularizers are popular solutions. However, designing regularizers that are suitable for diverse real-world datasets is challenging. Instead, we shed new light on addressing distribution shifts by directly eliminating domain-related spurious correlations with augmentation, leading to a simple technique based on mixup, called LISA (Learning Invariant Representations via Selective Augmentation). LISA selectively interpolates samples either with the same labels but different domains or with the same domain but different labels. Empirically, we study the effectiveness of LISA on nine benchmarks ranging from subpopulation shifts to domain shifts. The results indicate that LISA consistently outperforms other state-of-the-art methods with superior invariant representations. The empirical findings are further strengthened by our theoretical analysis.",
    "code_of_ethics": "",
    "submission_guidelines": "",
    "resubmission": "",
    "student_author": "",
    "serve_as_reviewer": "",
    "paperhash": "yao|improving_outofdistribution_robustness_via_selective_augmentation",
    "pdf": "/pdf/7bb1d14bf935629e92e4c52c6e88b087df808698.pdf",
    "one-sentence_summary": "Addressing the problem of distribution shift by eliminating the domain-related spurious correlations via data interpolation.",
    "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2201.00299/code)",
    "_bibtex": "@misc{\nyao2022improving,\ntitle={Improving Out-of-Distribution Robustness via Selective Augmentation},\nauthor={Huaxiu Yao and Yu Wang and Sai Li and Linjun Zhang and Weixin Liang and James Zou and Chelsea Finn},\nyear={2022},\nurl={https://openreview.net/forum?id=zXne1klXIQ}\n}",
    "venue": "ICLR 2022 Submitted",
    "venueid": "ICLR.cc/2022/Conference"
  },
  "forum": "zXne1klXIQ",
  "referent": null,
  "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission",
  "replyto": null,
  "readers": [
    "everyone"
  ],
  "nonreaders": [],
  "signatures": [
    "ICLR.cc/2022/Conference"
  ],
  "writers": [
    "ICLR.cc/2022/Conference"
  ],
  "details": {
    "overwriting": [],
    "tags": [],
    "writable": false,
    "replyCount": 18,
    "directReplyCount": 5,
    "revisions": true,
    "replies": [
      {
        "id": "_ChCHY2Eycq",
        "original": null,
        "number": 1,
        "cdate": 1634589471055,
        "mdate": null,
        "ddate": null,
        "tcdate": 1634589471055,
        "tmdate": 1634589517889,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Review",
        "content": {
          "summary_of_the_paper": "Authors introduced approaches aimed at learning invariant predictors across data sources. Rather than using distribution/risk matching schemes as often done by previous work, they propose to train models against mixtures of data points as a means to avoid that models rely on spurious correlations between domain and class labels, since such correlations observed during training might not hold at testing time. The proposed setting uses the idea of mixup to combine data instances in two different schemes: I-combine data points from the same class but different domains, and II-combine data points from the same domain but from different classes.",
          "main_review": "Strengths:\n\n+ The proposed approach is simple and efficient, and can be directly incorporated in or combined with other invariance-inducing approaches;\n\n+ Prediction performance is shown to improve over a number of recent baselines under challenging benchmarks.\n\nWeaknesses/suggestions: \n\n- The proposal requires assumptions that are not discussed in the manuscript. In [1], it was shown that domain-invariant approaches can only improve out-of-distribution generalization if data-conditional label distributions P(y|x) are fixed across domains; i.e., observing x suffices in order to determine y, regardless of the domain according to which x was observed.\n\n- My main concern lies in the reported evaluation, which is focused on showing improvements in terms of downstream performance, and presented results consist of comparing the proposed approach with alternative methods. While improving downstream performance is of course our ultimate goal, and results are strong in this sense, doing so does not explain the sources of improvements. In particular, authors claim that the mixup strategies they introduce yield some type of domain invariance, which is not verified empirically. To verify that learned representations are invariant, that could be achieved via domain-prediction experiments; i.e., train domain classifiers on top of representations learned by different methods. The higher the accuracy of such a classifier, the less invariant are representations. For the case of prediction-level invariance, authors could perhaps evaluate the range of estimated risks across domains. Improvements on either one of these notions of invariance would then explain observed improvements in terms of prediction accuracy.\n\n- \"We argue that the failure of other methods in some datasets may be caused by their regularizers limiting model capacity to some extent\". That's another case where the evaluation lacks in supporting authors' claims. This hypothesis can be verified via in-domain prediction performance, i.e., overly regularized underfitting models should result in accuracy degradation in the training domains. Alternatively, one could rule out the underfitting effect by using higher capacity model classes.\n\n- Conclusions from the risk bounds provided in theorems 1 and 2 are a bit unrealistic given the strong assumptions that imply the results. In particular, the model assumed for the data generating process is overly simplified and, although it enables theoretical analysis, it's unclear to which extend the conclusions hold in practice.\n\n- Finally, regarding novelty, it seems different recent approaches introduce methods that use some sort of mixup across domains in similar settings. For the domain adaptation/generalization cases, there are, for instance, [2,3,4]. For the multi-domain case, cross-domain mixup was studied in [5]. Authors do compare results against [4], but it's unclear how the proposed approach differs from those other recent applications of mixup under similar settings, and the related work section should include such a discussion.\n\nOther comments:\n\n- On page 2, the setting described was not originally introduced by Koh et al. (2021). To my knowledge, it was first discussed in [6] and later on in [7].\n\n- The definition of mixup for labels in the rightmost term in eq. 2 seems to require labels y are one-hot encoded, which is not mentioned in the text.\n\n- While in the title authors claim to be improving out-of-distribution robustness, a large part of the work focus on the multi-domain learning (or fairness) setting, where one's goal is to find predictors with uniform risks across a set of domains that doesn't change from training to testing. Technically, that wouldn't be out-of-distribution. Perhaps there should be a sentence or two in the introduction indicating what authors refer to as out-of-distribution.\n\nReferences:\n\n[1] Zhao, Han, et al. \"On learning invariant representations for domain adaptation.\" International Conference on Machine Learning. PMLR, 2019.\n\n[2] Shu, Yang, et al. \"Open Domain Generalization with Domain-Augmented Meta-Learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[3] Wang, Yufei, Haoliang Li, and Alex C. Kot. \"Heterogeneous domain generalization via domain mixup.\" ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020.\n\n[4] Xu, Minghao, et al. \"Adversarial domain adaptation with domain mixup.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.\n\n[5] Chuang, Ching-Yao, and Youssef Mroueh. \"Fair mixup: Fairness via interpolation.\" arXiv preprint arXiv:2103.06503 (2021).\n\n[6] Muandet, Krikamol, David Balduzzi, and Bernhard Sch\u00f6lkopf. \"Domain generalization via invariant feature representation.\" International Conference on Machine Learning. PMLR, 2013.\n\n[7] Albuquerque, Isabela, et al. \"Generalizing to unseen domains via distribution matching.\" arXiv preprint arXiv:1911.00804 (2019).\n",
          "summary_of_the_review": "The paper is well-written, the approach is efficient and observed to work well on a number of benchmarks. However, experiments supporting key claims are lacking, and it's unclear whether the observed improvements in terms of invariance (either at feature- or prediction-level) hold true since no supporting experiments are reported. Contextualization of the proposal relative to past literature also needs improvements since cross-domain data mixup was studied in the past under both settings considered by the authors. The provided discussion on related work does not clarify what and how the authors' proposal improves upon previous work.",
          "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_4YgJ"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_4YgJ"
        ]
      },
      {
        "id": "AIjTwOXgDz_",
        "original": null,
        "number": 2,
        "cdate": 1635873091123,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635873091123,
        "tmdate": 1637643240071,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper considers the model robustness under distribution shift brought by domains and subpopulations. Specifically, based on the interpolation scheme in mixup, the authors propose two selection strategies to perform data augmentation, aim at eliminating the spurious correlations and learning an invariant representation.",
          "main_review": "Strength:\n(1) The authors address a critical point that prevent models from generalization, namely spurious correlation.\n(2) The proposed method is simple and easy to implement, and the empirical results are within expectation.\n\nWeakness:\n(1) Maybe the biggest concern is the contribution over previous work. The proposed method can be seen as a heuristic extention of mixup. Though simple and easy to follow, the contribution is marginal. \n(2) There ara growing trends on investigating OOD generalization under missing domain label, it is better to at least include such work (e.g. [1]) for discussion.\n(3) There is a hyper-parameter p_sel that controls the probability of performing different strategy, is there a rule of thumb or we need to tune it for every task?\n[1] Qiao, F., Zhao, L., & Peng, X. (2020). Learning to Learn Single Domain Generalization. In CVPR.",
          "summary_of_the_review": "This paper address the spurious correlation by augmenting the data via interpolation. Although intuitions are provided and empirical effectiveness is illustrated accordingly, the contributions over previous work (e.g. mixup) are marginal.\n\n=========After Response==========\n\nThe response from authors has addressed my major concerns, so I raise my score accordingly.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "details_of_ethics_concerns": "N/A",
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_iP5p"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_iP5p"
        ]
      },
      {
        "id": "ZU9Dq3GC-Xp",
        "original": null,
        "number": 3,
        "cdate": 1635925777323,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635925777323,
        "tmdate": 1635925777323,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper propose a mixup-style data augmentation method under the data distribution shift context. In particular, data distributions are formulated as mixture of distributions (i.e., domains), and two distribution shift scenarios are considered: (1) domain shift, where the test domain and train domain are disjoint. (2) subpopulation shift, where test distribution has different mixture proportion than train distribution. It's  assumed that domain identification spuriously correlates with labels. To tackle this problem, this paper proposes two mixup strategies: (I) mixup two examples with same label but different domains; (II) mixup two examples with same domain but different labels. It's claimed that such mixup could cancel out the spurious correlations. Extensive experiments on a variety of datasets show its superiority compared to empirical risk minimization (ERM) and alternative data augmentation methods. The paper further provide theoretical analysis that under certain conditions, the proposed method has asymptotically smaller worst case classification errors than ERM and vanilla mixup. ",
          "main_review": "the idea is quite simple and intuitively reasonable, and empirical results seem extensive and significant, and theoretically justified to some extent\n\nsome of the results analysis is a bit confusing to me\n(1) in 4.1 \"evaluating robustness to domain shifts\", the best strategy was to always mixup same label with different domains, and the potential reason given is that the datasets actually have weak or even no spurious correlation between domain and label. Two questions follow:\n(a) From early text, seems both selection strategies are motivated by the spurious correlation, but here why do we still observe advantage over ERM or vanilla mixup? It would be great if you could clarify the different motivations (if any) of the two selection strategies\n(b) the reasoning about \"weak or no spurious correlation\" seems to be contradicting with claim in 4.3, where it's stated that \"compared with vanilla mixup, ...LISA...improve the OOD robustness by canceling out the spurious correlations..\". or did I misunderstand something? Is it easy to quantify such spurious correlation? if so, why not present the actual correlation metrics for these datasets? \n\n(2) for the ablation study, I think a more convincing way would be: first test LISA and mixup on a dataset that is known to have NO spurious correlations, then we expect neutral results; then test them on a data that is known to have spurious correlations, and we could give quantitative metrics of such correlations if possible, and show LISA is better than mixup; further more, the stronger the correlation, the more advantage LISA has. Is that what you're trying to demonstrate here? \n\n(3) In table 8, vanilla mixup shows much worse performance than ERM in terms of learning invariant representations under the defined metric, which doesn't seem quite reasonable to me. Shouldn't we expect the contrary? \n \n\n\nAnother minor question: In Theorem 1, is p the dimension of x? If so it's better to state that explicitly in the theorem instead of relying on readers to go back to text and only to find in the superscript notation. ",
          "summary_of_the_review": "the idea is quite simple and intuitively reasonable, and empirical results seem extensive and significant, and theoretically justified to some extent, but the results analysis and some experimental design could be more insightful or improved. ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ]
      },
      {
        "id": "arbHuX3TAb3",
        "original": null,
        "number": 1,
        "cdate": 1637312905339,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637312905339,
        "tmdate": 1637316591132,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "ZU9Dq3GC-Xp",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer VX2N, part 1/2",
          "comment": "Thank you for your constructive feedback. We have improved our paper according to your constructive comments and we addressed your questions below. Please kindly let us know if your questions are addressed.\n\n>\uff08a) From early text, seems both selection strategies are motivated by the spurious correlation, but here why do we still observe advantage over ERM or vanilla mixup? It would be great if you could clarify the different motivations (if any) of the two selection strategies (b) the reasoning about \"weak or no spurious correlation\" seems to be contradicting with claim in 4.3, where it's stated that \"compared with vanilla mixup, ...LISA...improve the OOD robustness by canceling out the spurious correlations..\". or did I misunderstand something?\n\n-  We apologize for the confusion. Though both selection strategies in LISA aim to reduce the effect of spurious correlations, we first clarify the different motivations between them below. We also revised Section 3, Section 4.1 to clarify it.\n\n   * Selection strategy I aims to directly cancel out the spurious correlation. If the domain information fully reflects spurious correlation, interpolating samples with the same label but different domains can effectively cancel out the spurious correlation. However, if the current domain information does not fully reflect the spurious correlations, directly applying selection strategy I even without using the given domain information yields the best performance, which has been initially discussed in Appendix A.1.2 and moved to the \"Results\" paragraph of Section 4.1 and Section 3. \n\n   * Selection strategy II, instead, focuses on actively building domain-independent prediction models, where domain information is required to be highly spuriously correlated with the labels. Otherwise, selection strategy II may not be suitable.\n\n- Then, we clarify that there are indeed spurious correlations in datasets with domain shifts, while the current domain information may not fully reflect the spurious correlations. As we mentioned in Section 4.1, in Camelyon17-wilds dataset (Koh et al., 2021), the presence of tumor tissue (i.e., label) mainly depends on the demographic of patients (e.g., race, gender), which shows no significant difference across hospitals (i.e., domain information). This could also explain why ERM, which does not consider domain information, outperforms other baseline models under the domain shifts scenario. Under this setting, we directly use LISA-I without domain information to cancel out the spurious correlations, i.e., $p_{sel}=1.0$. We have revised our paper in the \"Results\" paragraph of Section 4.1 to clarify it.\n\n---\n\n> Ablation study on datasets without spurious correlations\n\nAccording to your suggestions, we conduct new experiments on datasets without spurious correlations. To be more specific, we balance the number of samples for each group under the subpopulation shifts scenario. The results of ERM, vanilla mixup, and LISA on CMNIST, Waterbirds, and CelebA are reported in the following table:\n\n| Dataset | ERM | Vanilla Mixup | LISA |\n| ------ | :-----: | :-----: | :-----: |\n| CMNIST | 73.67% | 74.28% | 73.18% |\n| Waterbirds | 88.07% | 88.23% | 87.05% |\n| CelebA | 86.11% | 88.89% | 87.22% |\n\nThe above results show that LISA performance is similar to ERM when datasets do not have spurious correlations. If there exists any spurious correlation, LISA significantly outperforms ERM. Another interesting finding is that vanilla mixup outperforms LISA and ERM without spurious correlations, while LISA achieves the best performance with spurious correlations. This finding strengthens our conclusion that the performance gains of LISA are caused by eliminating spurious correlations rather than data augmentation. We have revised Section 4.3 and Appendix A.3 to include the new results and analysis.\n\n---\n\n> the stronger the correlation, the more advantage LISA has. Is that what you're trying to demonstrate here?\n\nYes, in Section 4.4, we have analyzed the strength of spurious correlation and the performance gains of LISA. The results corroborate our hypothesis that LISA leads to more improvements with the spurious correlations are stronger\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "1rnzq7vG9CD",
        "original": null,
        "number": 2,
        "cdate": 1637313075643,
        "mdate": 1637313075643,
        "ddate": null,
        "tcdate": 1637313075643,
        "tmdate": 1637313075643,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "arbHuX3TAb3",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer VX2N, part 2/2",
          "comment": "> Comparison between vanilla mixup and ERM in Table 6 (revised paper)\n\nThis scenario is what we expected. In subpopulation shifts (e.g., CMNIST), vanilla mixup actually makes the learned representations less invariant. For example, imagine the toy example with two data groups and an imbalance factor 0.9, which means the proportion between the majority and minority group is 9:1. With vanilla mixup, the percentage of the pure majority/minority groups is 81%/1%, and there are 18% mixed samples from both the majority group and minority group. According to the proportion between the pure majority/minority groups, the model is still biased towards the majority group. The biased model will then make the mixed samples biased to the majority group since they have the information from the majority group, which essentially strengthens the ratio of the majority group and worsen the performance.\n\n---\n\n> Is p the dimension of x?\n\nThanks for your suggestion. Yes, p is the dimension of x. We have revised the paper  to include the definition in the theorem.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "-QUKUYkoLQN",
        "original": null,
        "number": 3,
        "cdate": 1637313517263,
        "mdate": 1637313517263,
        "ddate": null,
        "tcdate": 1637313517263,
        "tmdate": 1637313517263,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "AIjTwOXgDz_",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer iP5p",
          "comment": "Thanks for your valuable comments. We have revised our paper according to your constructive suggestions. We would appreciate it if you could let us know whether our response addresses your concerns.\n\n> Maybe the biggest concern is the contribution over previous work. The proposed method can be seen as a heuristic extension of mixup\n\nWe agree the method is a conceptual extension of mixup. However, LISA mainly focuses on out-of-distribution robustness, and the performance gains compared to vanilla mixup are significant. Further, we provide extensive empirical and theoretical analyses that show and help understand the effectiveness of LISA compared to vanilla mixup. Therefore, we believe that the contribution over the previous work is significant.\n\nWe also would like to note that although mixup is very popular in practice, its theoretical understanding is still limited. To the best of our knowledge, our paper provides the first theoretical analysis of how mixup (with and without the selection strategies) affects mis-classification error across different domains.\n\n---\n\n> There are growing trends on investigating OOD generalization under missing domain label, it is better to at least include such work (e.g. [1]) for discussion.\n\nThanks for your suggestion. We have added the discussion about out-of-domain generalization without domain information in the first paragraph of Section 6.\n\n---\n\n> How to tune p_sel for each task?\n\nAs we discussed in the second paragraph of page 5 and the first paragraph of page 6 in the initial submission, the choice of $p_{sel}$ depends on the number of domains and the relation between domain information and spurious correlations. Empirically, using selection strategy I only brings much more benefits when there are more domains, and/or the domain information can not fully reflect the spurious correlations. LISA with selection strategy II can benefit the performance when domain information is highly spuriously correlated with the label, where we find a balanced ratio (i.e., $p_{sel}=0.5$) performs the best. We have moved this information to the last paragraph of Section 3 to clarify it.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "6Pbn9uSJ6_F",
        "original": null,
        "number": 4,
        "cdate": 1637314098710,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637314098710,
        "tmdate": 1638256192895,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "_ChCHY2Eycq",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer 4YgJ, part 1/2",
          "comment": "Thanks for your thorough and constructive comments. We have revised our paper with new discussions and experiments based on your comments. We detail our response below and would appreciate it if you could let us know whether our response addresses your concerns. \n\n> The proposal requires assumptions that are not discussed in the manuscript.\n\nThanks for pointing it out. However, this condition is implied by our model in equation (1) and our assumption on the 9th line on page 8. In the same line, we defined $\\Delta$, which is later used in Theorem 1. These assumptions have already been explicitly presented.\n\n---\n\n> Evaluation of domain invariance representations and prediction-level invariance\n\n**[Representation-level Invariance]** In the initial submission, we have already conducted experiments to evaluate the representation-level invariance in Section 4.5, where measure the invariance by calculating the pairwise KL divergence of domain representations. Compared with other strategies, the results in Table 6 (revised paper) show that representations from different domains are closer together by applying LISA, verifying that LISA leads to stronger representation invariance.\n\nBesides, we did conduct experiments to classify domains using the learned representation on CMNIST. However, all methods achieve an accuracy of 100%. That is what we expect since it is very easy to classify domains with even a little domain-related information.\n\n**[Prediction-level Invariance]** In light of your comment about prediction-level invariance, we conduct a new experiment by calculating the variance of test risks across all domains, where a small variance represents strong prediction-level invariance. The results on CMNIST and MetaShift have been summarized in the following Table and in Section 4.5 of the revised paper. These results indicate that LISA indeed improves prediction-level invariance. \n\n| Dataset | CMNIST | MetaShift | \n| ------ | :-----: | :-----: | \n| ERM | 12.0486 | 1.8824 |\n| Vanilla mixup | 0.2769 | 0.2659 | \n| IRM | 0.0112 | 0.8748 |\n| DomainMix | 0.1674 | 1.1158 |\n| **LISA (ours)** | **0.0012** | **0.2387** | \n\n---\n\n> Model capacity analysis\n\nThank you for your suggestion. We conduct experiments to analyze the model capacity by calculating the averaged accuracy on the in-distribution validation set. The performance of ERM, IRM, Coral, LISA on CMNIST, Waterbirds, CelebA, MetaShift are reported in the following:\n \n| Dataset | CMNIST | Waterbirds | CelebA | MetaShift |\n| ------ | ----- | ----- | ----- | ----- |\n| ERM | 73.75% | 91.08% | 91.79% | 93.75% | \n| IRM | 70.28% | 89.32% | 90.53% | 92.85% |\n| Coral | 72.77% | 90.15% | 90.48% | 91.96% | \n| **LISA (ours)** | 73.07% | 89.15% | 90.85% | 94.52% | \n\nCompared with LISA, the results demonstrate that directly adding regularizers on ERM (i.e., IRM and Coral) does limit the model capacity due to the worse in-distribution performance.\n\n---\n\n> Conclusions from the risk bounds provided in theorems 1 and 2 are a bit unrealistic \n\nThe aim of our theoretical analysis is to explain some phenomena distilled from our empirical study and to help us understand why LISA can work. Such a simple model has also been adopted to understand empirical observations in the literature of out-of-distribution robustness [Miller et al. 2021] and in the other subfields of deep learning, such as fairness [Chuang et al. 2021] and adversarial robustness [Schmidt et al. 2018, Carmon et al. 2019].\n\n\n[Miller et al. 2021] Miller, John P., Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. \"Accuracy on the line: On the strong correlation between out-of-distribution and in-distribution generalization.\" ICML 2021. \n\n[Chuang et al. 2021] Chuang, Ching-Yao, and Youssef Mroueh. \"Fair mixup: Fairness via interpolation.\" ICLR 2021. \n\n[Schmidt et al. 2018] Schmidt, Ludwig, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and Aleksander Madry. \"Adversarially Robust Generalization Requires More Data.\" In NeurIPS. 2018.\n\n[Carmon et al. 2019] Carmon, Yair, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, and John C. Duchi. \"Unlabeled data improves adversarial robustness.\"  In NeurIPS. 2019. "
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "g8rRulfX41L",
        "original": null,
        "number": 5,
        "cdate": 1637314611485,
        "mdate": 1637314611485,
        "ddate": null,
        "tcdate": 1637314611485,
        "tmdate": 1637314611485,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "6Pbn9uSJ6_F",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer 4YgJ, part 2/2",
          "comment": "> Novelty and discussion with related works\n\nIn the submission, we have cited four methods that generate more domains and discussed the difference in the first part of the related work. We cite [Shu et al. 2021] and [Wang et al. 2020] in the revised version and these papers also belong to the category of augmenting more domains. As mentioned in the related work, the aim of domain augmentation is to learn a representation that is invariant to the domain, whereas LISA tries to ensure that the final predictions are invariant to domain. Thus, LISA places fewer constraints on the learned representation.\n\nIn terms of Fair mixup [Chuang et al. 2021], it enables cross-domain mixup regardless of the class information to achieve more fair classification models. In addition, it uses the interpolated data as an explicit regularization term. Compared with Fair mixup, LISA with selection strategy I further restricts the interpolation scope, i.e., mixing samples with the same label, which is specifically suitable in improving out-of-distribution robustness. Moreover, as we mentioned in the second paragraph on page 2 in the original paper, LISA is an implicit method as it applies standard training (without explicit regularization) directly on the interpolated data. In addition, the motivations of Fairmix and LISA are completely different. Fair mixup aims to obtain a fair classifier, while LISA focuses on eliminating the effects of domain-related spurious correlation. \n\n[Shu et al. 2021] Shu, Yang, et al. \"Open Domain Generalization with Domain-Augmented Meta-Learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[Wang et al. 2020] Wang, Yufei, Haoliang Li, and Alex C. Kot. \"Heterogeneous domain generalization via domain mixup.\" ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020.\n\n[Chuang et al. 2021] Chuang, Ching-Yao, and Youssef Mroueh. \"Fair mixup: Fairness via interpolation.\" ICLR 2021.\n\n---\n\n> On page 2, the setting described was not originally introduced by Koh et al. (2021)\n\nThanks for your comment. We have added the references in the description of distribution shifts in Section 2.\n\n---\n\n> One-hot label in equation 2\n\nThanks for pointing it out. We have clarified it in the revised paper.\n\n---\n\n> Out-of-distribution definition\n\nIn the submission, we refer to \u201cout-of-distribution\u201d as the scenario when training and test data are not independent and identically distributed. This definition has been widely used in the machine learning community [Arjovsky et al. 2019; Ye et al. 2021; Koh et al. 2021]. We have revised our paper in the first paragraph of Section 1 to clarify this.\n\n[Arjovsky et al. 2019] Arjovsky, Martin, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. \"Invariant risk minimization.\" arXiv preprint arXiv:1907.02893 (2019).\n\n[Koh et al. 2021] Koh, Pang Wei, Shiori Sagawa, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga et al. \"Wilds: A benchmark of in-the-wild distribution shifts.\" ICML 2021.\n\n[Ye et al. 2021] Ye, Haotian, Chuanlong Xie, Tianle Cai, Ruichen Li, Zhenguo Li, and Liwei Wang. \"Towards a Theoretical Framework of Out-of-Distribution Generalization.\" NeurIPS 2021.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "Zdo_PIHZ49N",
        "original": null,
        "number": 7,
        "cdate": 1637316562690,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637316562690,
        "tmdate": 1637316791743,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Overall Summary of Changes",
          "comment": "We sincerely thank all reviewers for their constructive feedback. We summarize all major changes in the revised paper below. All changes are in red text.\n\n1. We revised the \u201cIntroduction\u201d and \u201cPreliminaries\u201d to include the definition of \u201cout-of-distribution\u201d and add more references.\n\n2. In Section 3, we clarified the motivations and application scopes of selection strategies I and II in LISA. \n\n3. In Section 4.1, We clarified the explanations and findings of domain shifts.\n\n4. In Section 4.3 and Appendix A.3, we add a new experiment on datasets without spurious correlation.\n\n5. In Section 4.5, we add a new experiment to analyze the prediction-level invariance of LISA and other baselines.\n\n6. We revised the related work (Section 6) to include more references and discussions. \n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "hIUHx4jpCe",
        "original": null,
        "number": 8,
        "cdate": 1638054713923,
        "mdate": 1638054713923,
        "ddate": null,
        "tcdate": 1638054713923,
        "tmdate": 1638054713923,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "g8rRulfX41L",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "We would love to hear back from Reviewer 4YgJ ",
          "comment": "Dear Reviewer 4YgJ,\n\nWe would love to see whether you are still concerning about our empirical analysis. We would really appreciate the opportunity to discuss this further if our response has not already addressed your concern. Many thanks!"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "JdSPU4TVMGz",
        "original": null,
        "number": 9,
        "cdate": 1638054925409,
        "mdate": 1638054925409,
        "ddate": null,
        "tcdate": 1638054925409,
        "tmdate": 1638054925409,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "1rnzq7vG9CD",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "We would love to hear back from Reviewer VX2N ",
          "comment": "Dear Reviewer VX2N,\n\nWe would love to hear back about whether you still have concerns about our experiments and ablation study. We are more than happy to further provide explanations or clarifications if more is needed. Many thanks!"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "Y_QXI23umEM",
        "original": null,
        "number": 12,
        "cdate": 1638209430441,
        "mdate": 1638209430441,
        "ddate": null,
        "tcdate": 1638209430441,
        "tmdate": 1638209430441,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "6Pbn9uSJ6_F",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to authors",
          "comment": "Thank you for the detailed response!\n\nWhile the authors addressed some of our concerns, the main ones unfortunately remain.\n\nOverall, the paper shows that applications of data mixup can improve out-of-distribution generalization, but it gives no explanation as to why that is. The fact that mixup acts as a regularizer and helps to generalize is already known, thus I would say that the paper lacks in providing new information relative to past literature. Explaining how mixup operates and what it does that improves generalization in the considered setting would make the paper very useful to the community.\n\nSpecifically, the evaluation reported in table 6 could be further clarified (the KL is measured between which distributions?). However, even if we assume that the results in table 6 support what the authors suggest, in the response, it was mentioned that they were able to train domain classifiers to 100% accuracy, which clearly indicates no domain-invariance is achieved at the feature level. As such, we are left with assuming that invariance is achieved at the prediction level, but that would require stronger empirical evidence to support the conclusion and some explanation as to why mixup would yield such an effect. The authors included experiments measuring the risk variance, but only for CMNIST which makes it unclear whether results would hold in more realistic evaluation conditions and with naturally occurring domain shifts.\n\nI also have some other concerns with the presentation; the settings under consideration are not detailed in the introductory sections in that key assumptions are hidden in the theoretical results, while they should be clearly highlighted once the settings are introduced. Domains, for instance, apparently are assumed to correspond to marginal distributions over the input space, but that's never stated in the text. Also, as mentioned in the original review, the assumption that P(y|x) is fixed across domains is a strong one which should be clearly highlighted once the settings under consideration are introduced.\n\nThe theoretical results also don't seem to add much value given the somewhat unrealistic assumptions they require. The authors mentioned similar assumptions appeared in other settings, but still, in this case it's unclear whether the conclusions would hold in more realistic cases. A discussion highlighting which assumptions would not hold in practice and how that could affect results could be helpful to address that."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_4YgJ"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_4YgJ"
        ]
      },
      {
        "id": "fORPlNpikth",
        "original": null,
        "number": 13,
        "cdate": 1638258156593,
        "mdate": null,
        "ddate": null,
        "tcdate": 1638258156593,
        "tmdate": 1638258833506,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "Y_QXI23umEM",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer 4YgJ's additional concerns",
          "comment": "Dear Reviewer 4YgJ,\n\nThank you for letting us know your additional concerns. We detail our additional response below.\n\n> the evaluation reported in table 6 could be further clarified (the KL is measured between which distributions?)\n\nIn our initial submission, we have already discussed the distributions used to calculate KL divergence (see Line 8-13 in Section 4.5 in the revised paper). The KL divergence is used to measure the divergence between the distributions of representations from two different domains.\n\n> in the response, it was mentioned that they were able to train domain classifiers to 100% accuracy, which clearly indicates no domain-invariance is achieved at the feature level.\n\nWe would like to clarify that we train domain classifiers on CMNIST and obtain 100% accuracy for all methods since it is easy to classify domains with even a little domain information in the hidden representations. However, the hidden representations do include domain-invariant information that benefits out-of-distribution robustness. In this case, LISA has demonstrated its promise in learning more invariant representations, which is supported by the results in Table 6. Besides, we further train domain classifiers on Waterbirds and also get very high domain classification accuracy. The results are reported below, and LISA indeed leads to more invariant representations to some extent(i.e., worse domain classification accuracy).\n\n| Dataset |  WaterBirds |\n| ------ |  :-----: | \n| ERM | 92.31% |\n| Vanilla mixup | 92.57% |\n| IRM | 91.23% | \n| DomainMix  |  92.35% |\n| **LISA (ours)** |  **89.24%** |\n\n> we are left with assuming that invariance is achieved at the prediction level, but that would require stronger empirical evidence to support the conclusion and some explanation as to why mixup would yield such an effect. The authors included experiments measuring the risk variance, but only for CMNIST which makes it unclear whether results would hold in more realistic evaluation conditions and with naturally occurring domain shifts.\n\nIn our initial response, we have conducted experiments on both CMNIST and MetaShifts, where MetaShifts is a realistic dataset with domain shifts. Besides, we further conduct the experiments on Waterbirds and report the results as follows:\n\n\n\n| Dataset |  WaterBirds |\n| ------ |  :-----: | \n| ERM | 0.2456 |\n| Vanilla mixup | 0.1465 |\n| IRM | 0.1243 | \n| DomainMix  |  0.0995 |\n| **LISA (ours)** |  **0.0016** |\n\nThe superiority of LISA further strengthens our conclusion that LISA can improve prediction-level invariance.\n\n>  the settings under consideration are not detailed in the introductory sections in that key assumptions are hidden in the theoretical results, while they should be clearly highlighted once the settings are introduced. Domains, for instance, apparently are assumed to correspond to marginal distributions over the input space, but that's never stated in the text. Also, as mentioned in the original review, the assumption that P(y|x) is fixed across domains is a strong one which should be clearly highlighted once the settings under consideration are introduced.\n\nWe respectfully disagree with your comment \"that key assumptions are hidden in the theoretical results\". We did not hide the key assumptions at all.  Our model is clearly presented in equation (1) and our assumptions are explicitly presented on the 9th line on page 8. Your claimed condition \"$P(y|x)$ is fixed across domains\" is a consequence of our assumptions. The assumptions that we explicitly presented in the paper are sufficient to prove our theoretical results and show the superiority of our proposed method.\n\n> Contribution of theoretical analysis\n\nWe would like to highlight that our theoretical analysis aims to understand the phenomena in the empirical analysis. The papers listed in our initial response also provide theoretical insights with similar assumptions. In particular, [Miller et al. 2021] also focuses on out-of-distribution robustness. We believe a solid theory can help people to better understand why the proposed algorithm benefits the performance. We will add more discussion in the next version.\n\n[Miller et al. 2021] Miller, John P., Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt. \"Accuracy on the line: On the strong correlation between out-of-distribution and in-distribution generalization.\" ICML 2021.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "udf1sbAaIr6",
        "original": null,
        "number": 14,
        "cdate": 1638345488278,
        "mdate": 1638345488278,
        "ddate": null,
        "tcdate": 1638345488278,
        "tmdate": 1638345488278,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "arbHuX3TAb3",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "still a bit confused ",
          "comment": "Thanks for the detailed response! \n\nI have read your response and revision in section 4.1, I don't feel it becomes more clear, where the first \"key finding\" says there is no spurious correlation in Camelyon17-wilds, but the second \"key finding\" says \"improving OOD robustness by canceling out spurious correlations with augmentation.\" \nWhat does \"existing domain information may not fully reflects the spurious correlation\" mean? I thought it means no spurious correlation. \n\nAnother thing I just noticed is in Table 1 some are using worst acc but some are using average acc, but seems no explanation on why different metrics are used for different datasets? \n\nAnother concern I just realized is, as reviewer iP5p also raised: seems $p_{sel}$ is not a typical ML hyper parameter that we can't choose with cross validation? and I don't see the response to this question is an actionable algorithm on how to choose this parameter.  "
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ]
      },
      {
        "id": "kHHVJ4MfYuZ",
        "original": null,
        "number": 15,
        "cdate": 1638347174335,
        "mdate": null,
        "ddate": null,
        "tcdate": 1638347174335,
        "tmdate": 1638347266098,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "udf1sbAaIr6",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer VX2N's Additional Concerns",
          "comment": "Dear Reviewer VX2N,\n\nThank you for letting us know your additional concerns.\n\n> I have read your response and revision in section 4.1, I don't feel it becomes more clear, where the first \"key finding\" says there is no spurious correlation in Camelyon17-wilds, but the second \"key finding\" says \"improving OOD robustness by canceling out spurious correlations with augmentation.\" What does \"existing domain information may not fully reflects the spurious correlation\" mean? I thought it means no spurious correlation.\n\nThe spurious correlations do exist in these datasets. However, the domain information may not fully reflect the spurious correlation, i.e., some spurious correlations may be unobserved or challenging to capture. That's why we get the first finding. LISA is still capable of eliminating these unobserved spurious correlations, leading to the second finding. We will clarify it in the next version.\n\n> Another thing I just noticed is in Table 1 some are using worst acc but some are using average acc, but seems no explanation on why different metrics are used for different datasets?\n\nIn our experiments, we follow the setting in the WILDS benchmark [Koh et al. 2021], which uses different metrics for different datasets with detailed explanations.\n\n> Another concern I just realized is, as reviewer iP5p also raised: seems $p_{sel}$ is not a typical ML hyper parameter that we can't choose with cross validation? and I don't see the response to this question is an actionable algorithm on how to choose this parameter.\n\n$p_sel$ is a typical hyperparameter, and we can definitely use cross-validation to choose this hyperparameter. In our response to reviewer iP5p, we provide instruction about how to choose $p_{sel}$ roughly. Cross-validation is always a good way to get concise value. "
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "StFbNyQfZp",
        "original": null,
        "number": 16,
        "cdate": 1638725814306,
        "mdate": 1638725814306,
        "ddate": null,
        "tcdate": 1638725814306,
        "tmdate": 1638725814306,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "kHHVJ4MfYuZ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "cross-validation error doesn't reflect test error",
          "comment": "thanks for the explanation. \n\n\"spurious correlations do exist in these datasets. However, the domain information may not fully reflect the spurious correlation, i.e., some spurious correlations may be unobserved or challenging to capture\" -- Are you saying \"spurious correlations do exist in these datasets\" is purely based on speculation without real data points? If so I'm afraid the argument is not that strong. \n\nI don't quite follow how you could use cross-validation to select the $p_{sel}$ parameter. Given that the algorithm is targeting cases where test distribution is different from training distribution, will cross-validation performance still a good estimate of the true test error? At least not naive cross validation. You might have to do some special handling to the validation set to simulate the test set?"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ]
      },
      {
        "id": "whU2_cUXPxG",
        "original": null,
        "number": 17,
        "cdate": 1638952816086,
        "mdate": null,
        "ddate": null,
        "tcdate": 1638952816086,
        "tmdate": 1638953125022,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "StFbNyQfZp",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer VX2N's additional questions about corss-validation",
          "comment": "Dear Reviewer VX2N,\n\nThank you for letting us know your additional concerns. \n\n> Are you saying \"spurious correlations do exist in these datasets\" is purely based on speculation without real data points? If so I'm afraid the argument is not that strong.\n\nOur claim is built on the empirical finding, where in-distribution test accuracy is significantly higher than out-of-distribution test accuracy. Take RxRx1 as an example (see Table 12), the in-distribution test accuracy of ERM is 35.9 $\\pm$ 0.4%, whereas the out-of-distribution test accuracy is 29.9 $\\pm$ 0.4%. If there is no spurious correlation, the in-distribution test accuracy should be similar to the out-of-distribution test accuracy. Thus, there do exist some spurious features that correlate with the label.\n\n> Given that the algorithm is targeting cases where test distribution is different from training distribution, will cross-validation performance still be a good estimate of the true test error? At least not naive cross validation. You might have to do some special handling to the validation set to simulate the test set?\n\nCross-validation indeed works in our setting, where the validation set could be regarded as out-of-distribution data. For example, in Camelyon-17, we use the samples from three hospitals for training. In cross-validation, we can randomly pick two hospitals for training, and the rest is used for validation."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "AQ0KFjyV_5G",
        "original": null,
        "number": 1,
        "cdate": 1642696849860,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696849860,
        "tmdate": 1642696849860,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "The manuscript focuses on model robustness under distribution shift, specifically domain shifts and subpopulation shifts. Domain shift is where the test domain and train domain are disjoint. Subpopulation shift is where test distribution has different mixture proportion than train distribution. The assumption is that domain identification spuriously correlates with labels. The proposed framework learns an invariant representation by using mixup strategies and interpolates samples either with the same labels but different domains or with the same domain but different labels to. Experiments are performed on a variety of domain shift and subpopulation shift benchmarks, and results showed that the proposed framework is better than empirical risk minimization (ERM) and alternative data augmentation methods. Theoretical analysis is also provided and it is shown that, under certain conditions, the proposed framework has asymptotically smaller worst case classification errors than ERM and vanilla mixup.\n\nReviewers agreed on several positive aspects of the manuscript, including:\n1. The manuscripts addresses a critical point that prevent models from generalization, namely spurious correlation; \n2. The proposed method is simple and easy to implement, and the empirical results are within expectation.\n\nReviewers also highlighted several major concerns, including:\n1. Different recent approaches introduce methods that use some sort of mixup across domains in similar settings;\n2. Ablation study on datasets without spurious correlations are missing;\n3. Evaluation of domain invariance representations and prediction-level invariance needs clarifications;\n\nAuthors clarified different motivations of the two selection strategies in relation to spurious correlation between domains and labels, and provided an ablation study on datasets with no spurious correlation. Post-rebuttal, reviewers stayed with borderline ratings, and they have suggested further improvements: improving results analysis and the conclusion that \u201cexisting domain information may not fully reflect the spurious correlation\u201d, understanding the implication and the reasons that invariance is achieved at the prediction level instead of at the representation level despite the original goal is to learn an invariant representation, and improving presentation of the manuscript including settings and assumptions."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "directReplies": [
      {
        "id": "_ChCHY2Eycq",
        "original": null,
        "number": 1,
        "cdate": 1634589471055,
        "mdate": null,
        "ddate": null,
        "tcdate": 1634589471055,
        "tmdate": 1634589517889,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Review",
        "content": {
          "summary_of_the_paper": "Authors introduced approaches aimed at learning invariant predictors across data sources. Rather than using distribution/risk matching schemes as often done by previous work, they propose to train models against mixtures of data points as a means to avoid that models rely on spurious correlations between domain and class labels, since such correlations observed during training might not hold at testing time. The proposed setting uses the idea of mixup to combine data instances in two different schemes: I-combine data points from the same class but different domains, and II-combine data points from the same domain but from different classes.",
          "main_review": "Strengths:\n\n+ The proposed approach is simple and efficient, and can be directly incorporated in or combined with other invariance-inducing approaches;\n\n+ Prediction performance is shown to improve over a number of recent baselines under challenging benchmarks.\n\nWeaknesses/suggestions: \n\n- The proposal requires assumptions that are not discussed in the manuscript. In [1], it was shown that domain-invariant approaches can only improve out-of-distribution generalization if data-conditional label distributions P(y|x) are fixed across domains; i.e., observing x suffices in order to determine y, regardless of the domain according to which x was observed.\n\n- My main concern lies in the reported evaluation, which is focused on showing improvements in terms of downstream performance, and presented results consist of comparing the proposed approach with alternative methods. While improving downstream performance is of course our ultimate goal, and results are strong in this sense, doing so does not explain the sources of improvements. In particular, authors claim that the mixup strategies they introduce yield some type of domain invariance, which is not verified empirically. To verify that learned representations are invariant, that could be achieved via domain-prediction experiments; i.e., train domain classifiers on top of representations learned by different methods. The higher the accuracy of such a classifier, the less invariant are representations. For the case of prediction-level invariance, authors could perhaps evaluate the range of estimated risks across domains. Improvements on either one of these notions of invariance would then explain observed improvements in terms of prediction accuracy.\n\n- \"We argue that the failure of other methods in some datasets may be caused by their regularizers limiting model capacity to some extent\". That's another case where the evaluation lacks in supporting authors' claims. This hypothesis can be verified via in-domain prediction performance, i.e., overly regularized underfitting models should result in accuracy degradation in the training domains. Alternatively, one could rule out the underfitting effect by using higher capacity model classes.\n\n- Conclusions from the risk bounds provided in theorems 1 and 2 are a bit unrealistic given the strong assumptions that imply the results. In particular, the model assumed for the data generating process is overly simplified and, although it enables theoretical analysis, it's unclear to which extend the conclusions hold in practice.\n\n- Finally, regarding novelty, it seems different recent approaches introduce methods that use some sort of mixup across domains in similar settings. For the domain adaptation/generalization cases, there are, for instance, [2,3,4]. For the multi-domain case, cross-domain mixup was studied in [5]. Authors do compare results against [4], but it's unclear how the proposed approach differs from those other recent applications of mixup under similar settings, and the related work section should include such a discussion.\n\nOther comments:\n\n- On page 2, the setting described was not originally introduced by Koh et al. (2021). To my knowledge, it was first discussed in [6] and later on in [7].\n\n- The definition of mixup for labels in the rightmost term in eq. 2 seems to require labels y are one-hot encoded, which is not mentioned in the text.\n\n- While in the title authors claim to be improving out-of-distribution robustness, a large part of the work focus on the multi-domain learning (or fairness) setting, where one's goal is to find predictors with uniform risks across a set of domains that doesn't change from training to testing. Technically, that wouldn't be out-of-distribution. Perhaps there should be a sentence or two in the introduction indicating what authors refer to as out-of-distribution.\n\nReferences:\n\n[1] Zhao, Han, et al. \"On learning invariant representations for domain adaptation.\" International Conference on Machine Learning. PMLR, 2019.\n\n[2] Shu, Yang, et al. \"Open Domain Generalization with Domain-Augmented Meta-Learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[3] Wang, Yufei, Haoliang Li, and Alex C. Kot. \"Heterogeneous domain generalization via domain mixup.\" ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2020.\n\n[4] Xu, Minghao, et al. \"Adversarial domain adaptation with domain mixup.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. No. 04. 2020.\n\n[5] Chuang, Ching-Yao, and Youssef Mroueh. \"Fair mixup: Fairness via interpolation.\" arXiv preprint arXiv:2103.06503 (2021).\n\n[6] Muandet, Krikamol, David Balduzzi, and Bernhard Sch\u00f6lkopf. \"Domain generalization via invariant feature representation.\" International Conference on Machine Learning. PMLR, 2013.\n\n[7] Albuquerque, Isabela, et al. \"Generalizing to unseen domains via distribution matching.\" arXiv preprint arXiv:1911.00804 (2019).\n",
          "summary_of_the_review": "The paper is well-written, the approach is efficient and observed to work well on a number of benchmarks. However, experiments supporting key claims are lacking, and it's unclear whether the observed improvements in terms of invariance (either at feature- or prediction-level) hold true since no supporting experiments are reported. Contextualization of the proposal relative to past literature also needs improvements since cross-domain data mixup was studied in the past under both settings considered by the authors. The provided discussion on related work does not clarify what and how the authors' proposal improves upon previous work.",
          "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_4YgJ"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_4YgJ"
        ]
      },
      {
        "id": "AIjTwOXgDz_",
        "original": null,
        "number": 2,
        "cdate": 1635873091123,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635873091123,
        "tmdate": 1637643240071,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper considers the model robustness under distribution shift brought by domains and subpopulations. Specifically, based on the interpolation scheme in mixup, the authors propose two selection strategies to perform data augmentation, aim at eliminating the spurious correlations and learning an invariant representation.",
          "main_review": "Strength:\n(1) The authors address a critical point that prevent models from generalization, namely spurious correlation.\n(2) The proposed method is simple and easy to implement, and the empirical results are within expectation.\n\nWeakness:\n(1) Maybe the biggest concern is the contribution over previous work. The proposed method can be seen as a heuristic extention of mixup. Though simple and easy to follow, the contribution is marginal. \n(2) There ara growing trends on investigating OOD generalization under missing domain label, it is better to at least include such work (e.g. [1]) for discussion.\n(3) There is a hyper-parameter p_sel that controls the probability of performing different strategy, is there a rule of thumb or we need to tune it for every task?\n[1] Qiao, F., Zhao, L., & Peng, X. (2020). Learning to Learn Single Domain Generalization. In CVPR.",
          "summary_of_the_review": "This paper address the spurious correlation by augmenting the data via interpolation. Although intuitions are provided and empirical effectiveness is illustrated accordingly, the contributions over previous work (e.g. mixup) are marginal.\n\n=========After Response==========\n\nThe response from authors has addressed my major concerns, so I raise my score accordingly.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "details_of_ethics_concerns": "N/A",
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_iP5p"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_iP5p"
        ]
      },
      {
        "id": "ZU9Dq3GC-Xp",
        "original": null,
        "number": 3,
        "cdate": 1635925777323,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635925777323,
        "tmdate": 1635925777323,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper propose a mixup-style data augmentation method under the data distribution shift context. In particular, data distributions are formulated as mixture of distributions (i.e., domains), and two distribution shift scenarios are considered: (1) domain shift, where the test domain and train domain are disjoint. (2) subpopulation shift, where test distribution has different mixture proportion than train distribution. It's  assumed that domain identification spuriously correlates with labels. To tackle this problem, this paper proposes two mixup strategies: (I) mixup two examples with same label but different domains; (II) mixup two examples with same domain but different labels. It's claimed that such mixup could cancel out the spurious correlations. Extensive experiments on a variety of datasets show its superiority compared to empirical risk minimization (ERM) and alternative data augmentation methods. The paper further provide theoretical analysis that under certain conditions, the proposed method has asymptotically smaller worst case classification errors than ERM and vanilla mixup. ",
          "main_review": "the idea is quite simple and intuitively reasonable, and empirical results seem extensive and significant, and theoretically justified to some extent\n\nsome of the results analysis is a bit confusing to me\n(1) in 4.1 \"evaluating robustness to domain shifts\", the best strategy was to always mixup same label with different domains, and the potential reason given is that the datasets actually have weak or even no spurious correlation between domain and label. Two questions follow:\n(a) From early text, seems both selection strategies are motivated by the spurious correlation, but here why do we still observe advantage over ERM or vanilla mixup? It would be great if you could clarify the different motivations (if any) of the two selection strategies\n(b) the reasoning about \"weak or no spurious correlation\" seems to be contradicting with claim in 4.3, where it's stated that \"compared with vanilla mixup, ...LISA...improve the OOD robustness by canceling out the spurious correlations..\". or did I misunderstand something? Is it easy to quantify such spurious correlation? if so, why not present the actual correlation metrics for these datasets? \n\n(2) for the ablation study, I think a more convincing way would be: first test LISA and mixup on a dataset that is known to have NO spurious correlations, then we expect neutral results; then test them on a data that is known to have spurious correlations, and we could give quantitative metrics of such correlations if possible, and show LISA is better than mixup; further more, the stronger the correlation, the more advantage LISA has. Is that what you're trying to demonstrate here? \n\n(3) In table 8, vanilla mixup shows much worse performance than ERM in terms of learning invariant representations under the defined metric, which doesn't seem quite reasonable to me. Shouldn't we expect the contrary? \n \n\n\nAnother minor question: In Theorem 1, is p the dimension of x? If so it's better to state that explicitly in the theorem instead of relying on readers to go back to text and only to find in the superscript notation. ",
          "summary_of_the_review": "the idea is quite simple and intuitively reasonable, and empirical results seem extensive and significant, and theoretically justified to some extent, but the results analysis and some experimental design could be more insightful or improved. ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Reviewer_VX2N"
        ]
      },
      {
        "id": "Zdo_PIHZ49N",
        "original": null,
        "number": 7,
        "cdate": 1637316562690,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637316562690,
        "tmdate": 1637316791743,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Official_Comment",
        "content": {
          "title": "Overall Summary of Changes",
          "comment": "We sincerely thank all reviewers for their constructive feedback. We summarize all major changes in the revised paper below. All changes are in red text.\n\n1. We revised the \u201cIntroduction\u201d and \u201cPreliminaries\u201d to include the definition of \u201cout-of-distribution\u201d and add more references.\n\n2. In Section 3, we clarified the motivations and application scopes of selection strategies I and II in LISA. \n\n3. In Section 4.1, We clarified the explanations and findings of domain shifts.\n\n4. In Section 4.3 and Appendix A.3, we add a new experiment on datasets without spurious correlation.\n\n5. In Section 4.5, we add a new experiment to analyze the prediction-level invariance of LISA and other baselines.\n\n6. We revised the related work (Section 6) to include more references and discussions. \n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper277/Authors"
        ]
      },
      {
        "id": "AQ0KFjyV_5G",
        "original": null,
        "number": 1,
        "cdate": 1642696849860,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696849860,
        "tmdate": 1642696849860,
        "tddate": null,
        "forum": "zXne1klXIQ",
        "replyto": "zXne1klXIQ",
        "invitation": "ICLR.cc/2022/Conference/Paper277/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "The manuscript focuses on model robustness under distribution shift, specifically domain shifts and subpopulation shifts. Domain shift is where the test domain and train domain are disjoint. Subpopulation shift is where test distribution has different mixture proportion than train distribution. The assumption is that domain identification spuriously correlates with labels. The proposed framework learns an invariant representation by using mixup strategies and interpolates samples either with the same labels but different domains or with the same domain but different labels to. Experiments are performed on a variety of domain shift and subpopulation shift benchmarks, and results showed that the proposed framework is better than empirical risk minimization (ERM) and alternative data augmentation methods. Theoretical analysis is also provided and it is shown that, under certain conditions, the proposed framework has asymptotically smaller worst case classification errors than ERM and vanilla mixup.\n\nReviewers agreed on several positive aspects of the manuscript, including:\n1. The manuscripts addresses a critical point that prevent models from generalization, namely spurious correlation; \n2. The proposed method is simple and easy to implement, and the empirical results are within expectation.\n\nReviewers also highlighted several major concerns, including:\n1. Different recent approaches introduce methods that use some sort of mixup across domains in similar settings;\n2. Ablation study on datasets without spurious correlations are missing;\n3. Evaluation of domain invariance representations and prediction-level invariance needs clarifications;\n\nAuthors clarified different motivations of the two selection strategies in relation to spurious correlation between domains and labels, and provided an ablation study on datasets with no spurious correlation. Post-rebuttal, reviewers stayed with borderline ratings, and they have suggested further improvements: improving results analysis and the conclusion that \u201cexisting domain information may not fully reflect the spurious correlation\u201d, understanding the implication and the reasons that invariance is achieved at the prediction level instead of at the representation level despite the original goal is to learn an invariant representation, and improving presentation of the manuscript including settings and assumptions."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "invitation": {
      "reply": {
        "writers": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "signatures": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "content": {
          "title": {
            "value-regex": ".*",
            "order": 1
          },
          "authors": {
            "values": [
              "Anonymous"
            ],
            "order": 2
          },
          "authorids": {
            "value-regex": ".*",
            "order": 3
          },
          "keywords": {
            "value-regex": ".*",
            "order": 6
          },
          "abstract": {
            "value-regex": ".*",
            "order": 8
          },
          "pdf": {
            "value-regex": ".*",
            "order": 9
          },
          "one-sentence_summary": {
            "value-regex": ".*",
            "order": 10
          },
          "supplementary_material": {
            "value-regex": ".*",
            "order": 11
          },
          "code_of_ethics": {
            "value-regex": ".*",
            "order": 12
          },
          "submission_guidelines": {
            "value-regex": ".*",
            "order": 13
          },
          "resubmission": {
            "value-regex": ".*",
            "order": 14
          },
          "student_author": {
            "value-regex": ".*",
            "order": 15
          },
          "serve_as_reviewer": {
            "value-regex": ".*",
            "order": 16
          },
          "community_implementations": {
            "required": false,
            "description": "Optional link to open source implementations",
            "value-regex": ".*",
            "markdown": true,
            "order": 103
          }
        }
      },
      "replyForumViews": [],
      "expdate": 1682960118639,
      "signatures": [
        "ICLR.cc/2022/Conference"
      ],
      "readers": [
        "everyone"
      ],
      "writers": [
        "ICLR.cc/2022/Conference"
      ],
      "invitees": [
        "ICLR.cc/2022/Conference"
      ],
      "tcdate": 1632875419419,
      "tmdate": 1682960118686,
      "id": "ICLR.cc/2022/Conference/-/Blind_Submission",
      "type": "note"
    }
  },
  "tauthor": "OpenReview.net"
}