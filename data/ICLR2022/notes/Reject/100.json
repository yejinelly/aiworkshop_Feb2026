{
  "id": "oSP1hwZB24",
  "original": "FcEej82qUJ",
  "number": 100,
  "cdate": 1632875428618,
  "pdate": 1643407560000,
  "odate": 1633539600000,
  "mdate": null,
  "tcdate": 1632875428618,
  "tmdate": 1697934966859,
  "ddate": null,
  "content": {
    "title": "Dynamic Parameterized Network for CTR Prediction",
    "authorids": [
      "~Jian_Zhu1",
      "~Congcong_Liu1",
      "~Pei_Wang9",
      "~Xiwei_Zhao1",
      "~Guangpeng_Chen2",
      "~Jin_Jun_Sheng1",
      "~Changping_Peng1",
      "~Zhangang_Lin1",
      "~Jingping_Shao1"
    ],
    "authors": [
      "Jian Zhu",
      "Congcong Liu",
      "Pei Wang",
      "Xiwei Zhao",
      "Guangpeng Chen",
      "Jin Jun Sheng",
      "Changping Peng",
      "Zhangang Lin",
      "Jingping Shao"
    ],
    "keywords": [
      "Recommendation System",
      "Feature modeling",
      "User Behavior modeling",
      "Dynamic Network"
    ],
    "abstract": "Learning to capture feature relations effectively and efficiently is essential in click-through rate (CTR) prediction of modern recommendation systems. Most existing CTR prediction methods model such relations either through tedious manually-designed low-order interactions or through inflexible and inefficient high-order interactions, which both require extra DNN modules for implicit interaction modeling. In this paper, we proposed a novel plug-in operation, Dynamic Parameterized Operation (DPO), to learn both explicit and implicit interaction instance-wisely. We showed that the introduction of DPO into DNN modules and Attention modules can respectively benefit two main tasks in CTR prediction, enhancing the adaptiveness of feature-based modeling and improving user behavior modeling with the instance-wise locality. Our Dynamic Parameterized Networks significantly outperforms state-of-the-art methods in the offline experiments on the public dataset and real-world production dataset, together with an online A/B test. Furthermore, the proposed Dynamic Parameterized Networks has been deployed in the ranking system of one of the world's largest e-commerce companies, serving the main traffic of hundreds of millions of active users.",
    "pdf": "/pdf/4518a756d447cd30e99ef5c59cadcbe053ee96b7.pdf",
    "code_of_ethics": "",
    "submission_guidelines": "",
    "resubmission": "",
    "student_author": "",
    "serve_as_reviewer": "",
    "paperhash": "zhu|dynamic_parameterized_network_for_ctr_prediction",
    "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.04983/code)",
    "_bibtex": "@misc{\nzhu2022dynamic,\ntitle={Dynamic Parameterized Network for {CTR} Prediction},\nauthor={Jian Zhu and Congcong Liu and Pei Wang and Xiwei Zhao and Guangpeng Chen and Jin Jun Sheng and Changping Peng and Zhangang Lin and Jingping Shao},\nyear={2022},\nurl={https://openreview.net/forum?id=oSP1hwZB24}\n}",
    "venue": "ICLR 2022 Submitted",
    "venueid": "ICLR.cc/2022/Conference"
  },
  "forum": "oSP1hwZB24",
  "referent": null,
  "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission",
  "replyto": null,
  "readers": [
    "everyone"
  ],
  "nonreaders": [],
  "signatures": [
    "ICLR.cc/2022/Conference"
  ],
  "writers": [
    "ICLR.cc/2022/Conference"
  ],
  "details": {
    "overwriting": [],
    "tags": [],
    "writable": false,
    "replyCount": 15,
    "directReplyCount": 4,
    "revisions": true,
    "replies": [
      {
        "id": "UxR3LCb5nXs",
        "original": null,
        "number": 1,
        "cdate": 1635663631186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635663631186,
        "tmdate": 1635663631186,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed a new method to handle feature/context interactions within the eCTR prediction neural networks. Details are provided in different scenarios. Experiments are conducted for offline and real-world experiments with promising results.",
          "main_review": "Strengths:\n1. A good way to model and utilize feature/context interactions in order to better predict CTR.\n\n2. Promising offline/online results and detailed discussion of offline results.\n\n3. Well written paper. Clear illustration of the methodology as well as discussions about the relations with existing methods\n\nWeaknesses:\n1. Table 7 is way too simple, and so are related descriptions for the experiments. Are there more metrics to demonstrate the superiority of the new method? Is it affecting different segments of queries/users evenly? More details would be helpful to make the A/B test results stronger. Also, it seems CPC also increased. Any intuitions?\n\n2. Why TP99 jumped a lot? Is it purely from the network structure change? How about TP50/90/99.9?\n\n3. Page 4 \"Relation to FM\" would be more interesting to have details. The current high-level discussion is confusing. What is \"self-excluded version\"?\n\n4. In section 2.1 Preliminary, why is it helpful to separate traditional/sequence-base CTR prediction? \n\n5. To distinguish from \"a random paper which tweaks the neural network structure for better performance\", I would suggest more intuitions or discussions on why the added interaction component helps with the CTR prediction accuracy.\n",
          "summary_of_the_review": "It's a methodology paper working on an important problem (CTR prediction). The proposed method is not extremely innovative but the idea is natural and makes sense, so are the results positive and promising. The novelty is a subjective matter but personally I see enough contributions to clarify and materialize some of the vague commonsense in the industry. One minor concern is about its relevance to \"ICLR\" which focuses on representation learning.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_2XAa"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_2XAa"
        ]
      },
      {
        "id": "zWgrfthWzIe",
        "original": null,
        "number": 2,
        "cdate": 1635753169265,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635753169265,
        "tmdate": 1635753169265,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed a module DPO for CTR prediction to enhence the explicit and implicit information. The authors claimed that they provide the first attempt to extend the dynamic neural networks to CTR prediction, and experiments show that DPN (Dynamic Parameterized Network) significantly outperforms other state-of-the-art methods. ",
          "main_review": "Pros: \n1) This paper is organised well and clearly written. 2) The idea of behavior modeling is novel to me. 3) Detailed theoretical analysis.\n\nCons:\n1) Even though I think the proposed method is technically sound, the results cannot convince me. For the experimental results shown in Table 1, some baselines run worse than their normal performances, and the result of Dynamic Parameterized Network seems not good enough, e.g. compared with the results in [1]. \n2) Eq.5, how to demostrate the rationality of using the low-rank strategy.\n3) few typos, e.g., section 2.5, actions.to\n\n[1] Field-wise Learning for Multi-field Categorical Data, NeurIPS 2020.",
          "summary_of_the_review": "The idea is somewhat novel, but the result is not good enough.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_pP6H"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_pP6H"
        ]
      },
      {
        "id": "kFcdvrjuCoO",
        "original": null,
        "number": 3,
        "cdate": 1635873151026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635873151026,
        "tmdate": 1635873151026,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This submission is on modeling feature interactions for CTR prediction. It proposes a framework that follows meta-learning. Specifically, to model the interaction between feature F1 and feature F2, it uses a meta neural-network g(F1) that takes F1 and produces the parameter for another neural network f(F2) that takes F2, i.e., the outcome of feature crossing is f(F2) where f's parameter is g(F1). It outperforms the baselines and is deployed online.",
          "main_review": "Pros:\n- The algorithm is deployed in a real-world production system.\n- Many variants are proposed and empirically studied.\n\nCons:\n- Not enough novelty. The idea is almost the same as [1] and [2]. Both [1] and [2] conducts feature crossing by using one feature to generate the parameters of a neural network that takes another feature as input. Note that [1] is a recent work that has been deployed in a large-scale real-world e-commerce system as well and is a well-known work among some industry practitioners, especially in China.\n- More details about the experimental setup may be needed to assess if the setup is fair. For example, please consider reporting the total number of parameters of each baseline, since sometimes performance can be increased by simply increasing the model's capacity. It seems possible that the so-called state-of-art baselines are not well-tuned.\n- The reported +1% improvement in the online A/B test could be meaningless without details about the production systems. For example, +1% improvement in an early-stage business with a weak baseline is not as impressive as +1% improvement in a well-developed business with a strong baseline.\n- The writing can be improved.\n\n[1] CAN: https://arxiv.org/abs/2011.05625\n\n[2] A Meta-Learning Perspective on Cold-Start Recommendations for Items. NeurIPS 2017.",
          "summary_of_the_review": "The idea is almost the same as the existing works, especially [1].",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "3: reject, not good enough",
          "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_AzFU"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_AzFU"
        ]
      },
      {
        "id": "jKAbxGZ0HEt",
        "original": null,
        "number": 6,
        "cdate": 1636540377310,
        "mdate": 1636540377310,
        "ddate": null,
        "tcdate": 1636540377310,
        "tmdate": 1636540377310,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "kFcdvrjuCoO",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Cons.3",
          "comment": "Note that on the real production data, 1% increase in online A/B results is significant and brings about 6 millions dollars lift in the overall advertising income when the model serves on the main trafic. Also, we find our model can perform pretty better on small trafic than a simple baseline. We have stated in the paper our model earned 1\u2030 auc increase over the highly optimized base model on our ad system, which serves the main traffic of hundreds of millions of active users.\n\nBased on the clarification above, we do not see any major point to justify this reject decision.\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "cyefUgLaGU",
        "original": null,
        "number": 7,
        "cdate": 1636540412600,
        "mdate": 1636540412600,
        "ddate": null,
        "tcdate": 1636540412600,
        "tmdate": 1636540412600,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "kFcdvrjuCoO",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Cons.2",
          "comment": "The Reviewer  might have overlooked Table (1)-c. on page 6.  For each baseline in movielen-tag, avazu and criteo datasets, we set the embedding layer with the same hidden size 10, We report the base model parameters in Table1 and Table2. As shown in the following Tables ,  the parameters of  best feature-based DPN are less than the AFN, CIN while field-based DPN almost has less parameters than other baselines. For user behavior modeling, sDPN only increase extra 2% parameters compared to Transformer baseline while have much better performance as shown in Table 5 of our papers.\n\nTable 1: Parameters of different algorithms of feature-based datasets.\n\n| BaseModel         | Movielen-tag | Avazu | Criteo |\n| ----------------- | ------------ | ----- | ------ |\n| FM                | 90k          | 1.5m  | 2.1m   |\n| AFM               | 91k          | 1.6m  | 2.1m   |\n| HOFM              | 2.9m         | 18m   | 107m   |\n| PNN               | 102k         | 195k  | 893k   |\n| CIN               | 153k         | 5.2m  | 4.2m   |\n| AFN               | 242k         | 3.3m  | 7.8m   |\n| CrossNet          | 510          | 3.3k  | 6.6k   |\n| CrossMix          | 47k          | 184k  | 318k   |\n| DNN               | 101k         | 126k  | 449k   |\n| Feature-based DPN | 400k         | 509k  | 2.1m   |\n| Field-based DPN   | 87k          | 219k  | 246k   |\n\nTable 2: Parameters of different algorithms of user behaviors modelings\n\n| BaseModel   | Amazon-Electronic |\n| ----------- | ----------------- |\n| DIN         | 86.9k             |\n| DIEN        | 332.2k            |\n| Transformer | 1.22m             |\n| KFAtt       | 2.17m             |\n| DIN+Heter   | 206.7k            |\n| DIEN+Heter  | 452.1k            |\n| Trans+Heter | 1.46m             |\n| Trans+Homo  | 1.23m             |\n| sDPN        | 1.24m             |\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "CC5emHK-41L",
        "original": null,
        "number": 8,
        "cdate": 1636540474211,
        "mdate": 1636540474211,
        "ddate": null,
        "tcdate": 1636540474211,
        "tmdate": 1636540474211,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "kFcdvrjuCoO",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Cons.1 ( con'd) ",
          "comment": "## The difference to NLBA[2] and LWA[2]:\n\n1. NLBA and LWA mainly focus on the cold-start problem on Twitter recommendation. DPN focuses on the interaction module for traditional and sequence-based CTR prediction task compared to strong baselines.\n2. Besides the difference in motivation, LWA and NLBA build on the top of matrix factorization (a shallow linear or non-linear classifer), while DPN builds on the top of pointwise methods, e.g. MLP. LWA and NLBA use users\u2019 history as task-dependent weights and bias which can be seen as an instantiation of sequence-based DPO which only utilized in the final layer.  The NLBA don't produce dynamic weights across users in the hidden layers. However the sDPN generate dynamic weights in both homogeneous dynamic convolution operation and heterogeneous query-behavior interaction module.\n\nThe related part in original paper is quoted as follows:\n\n>Our first approach to conditioning predictions on users\u2019 item histories has parallels to latent factor\nmodels and is appealing due to its simplicity: we learn a linear classifier (for new items) whose\nweights are determined by the user\u2019s history $V_j$. Given the two class-representative embeddings $R^0_j ;R^1_j$ described above, LWA provides the bias (first\nterm) and weights (second term) of a linear logistic regression classifier.\n\n>In contrast to LWA, all weights (output and hidden) in NLBA are constant across users, while the\nbiases of output and hidden units are adapted per user. One can think of this approach as learning a\nshared pool of hidden units whose activation can be modulated depending on the user (e.g. a unit\ncould be entirely shot down for a user with a large negative bias).\n\n> Compared to LWA, NLBA produces a non-linear classifier of the item representations $F(t_i)$ and\ncan model complex interactions between classes and also between the classes and the test item. For\nexample, interactions allow NLBA to explore a different part of the classifier function space that is not\naccessible to LWA\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "BCOzReSaqm",
        "original": null,
        "number": 9,
        "cdate": 1636540507451,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636540507451,
        "tmdate": 1636627567019,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "kFcdvrjuCoO",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Cons.1",
          "comment": "The reviewer mistakenly determines the DPN has no novelty at all and thinks that CAN[1], NLBA[2] and LWA[2] share the same idea with DPN. We strongly disagree with the reviewer on this point and would clarify the difference from both motivation, approach and experiments:\n\n## The difference to CAN[1]: \n\n ### Motivation: \n\n1.  CAN: aims to capture feature co-action by assuming there exists an optimal function $f_*(A,B)$, and models the function only in the input stage. And they stress the hypothesis the feature co-occurrence can boost the performance by a \u201cCARTESIAN PRODUCT\u201d model. Thus, CAN only cares about how to build an expressive mutual representation for feature pairs at the INPUT STAGE.\n\nThe related part in original paper is quoted as follows:\n\n> In this paper, we stress the importance of feature co-action modeling and argue state-of-the-art methods underestimate the importance of co-action seriously. These methods fail to capture the feature co-action due to the limited expressive power. The importance of capturing feature co-action to augment the input is that it can reduce the difficulty for the model to learning and capture the co-action.\n\n> To this end, we propose feature Co-Action Network (CAN) that can capture the feature co-action at the input stage and utilize\nthe mutual and common information of different feature pairs effectively.\n\n2. Our DPN: does not care about feature co-action. DPN addresses the suboptimal combinatory way to build implicit and explicit feature interaction models in previous works [3-6],  by learning both additive and multiplicative interaction in a single module, which can be applied to any stage.\n\nThe related part in original paper is quoted as follows:\n\n> The methods mentioned above either model implicit and explicit feature interactions isolated oradopt a suboptimal way to combine them, which can be inefficient. In this work, we aim to address these problems by introducing a small MLP layer that dynamically generates kernels conditioned by the current instance to capture both implicit and explicit feature interactions. The core idea is\nto first generate context weights and biases from the context stream, and then aggregate them with the input stream adaptively. We formulate a generic function and implement it with an efficient dynamic parameterized operation (DPO).\n\n### Approach:\n\n1. CAN: can be formulated as $y=DNN(e_{item}, e_{user}, H(x_{user}, x_{item} ; \\theta_{can}) ; \\theta_{DNN}) $ and $H $means Co-Action Unit. As shown in their paper, the Co-Action Unit only models the user-item interaction in a specific way where they choose $P_{item}$ as the parameter of $MLP_{can}$. In section 4.2 of their paper, CAN seperate the embedding outputs of $P_{item}$ as weight matrix and bias vector followed by matrix multiplication with $P_{user}$ which can be seen as an instantiation of feature-based DPO. The details of CAN can be formulated as:\n\n>$P_{item} = concatenate({flatten(w^{i}}, b)_{i=0,...,k-1})$\n\n>$|P_{item}| = \\sum_{i=1}^{k} |w^i| + |b^i|$\n\n>$h^0=P_{user}$\n\n>$h^i=\\sigma(w^{i-1} \\otimes h^{i-1} + b^{i-1})$\n\n>$H(P_{user}, P_{item})=h^{k}, i \\in 1, 2, ... , k-1$\n\n2. Our DPN: first give an atomic formulation as $y_i= \\frac{1}{C(z)} \\sum_{\\forall j}(f(x_i ; g_i(z_j ; \\theta))$, followed by feature-based, field-based, sequence-based variants. As shown in DPN, the inputs and context don\u2019t specified as User and Item which can be utilized to a broader extent. Despite that, DPN discusses more variants than CAN. In Table2.b and Table3 of our paper, DPN compares the performance of different context e.g. User and Item, which covers the CAN. There is no reason to consider DPN the same as CAN. The variants can be formulated as :\n\n> Feature-based DPO: $ y=(\\hat{W}^T z+\\hat{b})^T x+(\\dot{W}^T z+\\dot{b})=z^T\\hat{W}x+\\dot{W}^Tz+\\hat{B}^Tx+\\dot{b} $\n\n> Homo Behavior DPO: $ y_i = \\frac{1}{C(x)} \\sum_{l= \\lfloor -\\frac{k}{2} \\rfloor}^{  \\lfloor \\frac{k}{2} \\rfloor} \\sum_{j=0}^{t} g_l(x_j ; \\theta)  x_{i+l} $\n\n> Hetero Behavior DPO: $ y= g(\\frac{1}{C(z)}\\sum_{\\forall j\\in t} z_j ; \\theta)^T x$\n\n### Experiments:\n\n1. CAN: conducts both feature-interaction and user behavior modeling experiments, while ablation study is far less than DPN. They didn't conduct the experiments on industrial dataset.\n2. Our DPN: shows more experiments on feature interaction and user behavior experiments, and even gives the results on industrial dataset, which further confirm the online A/B test results.\n\n\n[1] CAN: https://arxiv.org/abs/2011.05625\n\n[2] A Meta-Learning Perspective on Cold-Start Recommendations for Items. NeurIPS 2017.\n\n[3] Deep & Cross Network for Ad Click Predictions, KDD 2017\n\n[4] DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems, WWW 2021\n\n[5] Product-based Neural Networks for User Response Prediction,  ICDM 2016\n\n[6] AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks, CIKM 2019\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "JHyqhwqvMft",
        "original": null,
        "number": 10,
        "cdate": 1636611650893,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636611650893,
        "tmdate": 1636611913751,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "zWgrfthWzIe",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer pP6H",
          "comment": "Thank the reviewer for highlighting the novelty of our work and suggestions. We address the reviewer\u2019s questions below:\n\n### Question 1: \nWhy are the results of Table 1 different to the results in [1]?\n### Response to Q1:\nThe main reasons are the different training settings which we would clarify below.\n1. As shown in DPN, the experiment setting follows the same training setting in previous works( AFN[2], NFM[3]). They provide a unified train/valid/test splits on Avazu and Criteo. However, [1] uses random splits which is different to our setting.\n2. Training Details: \n  * [1] reimplemented baseline models in PyTorch and select the best strategies on validation sets, especially the embedding dimension,  weight lambda for regularization term. For example they chose the embedding dimension from {20, 40, 60, 80, 100} for FM while {2,4,8,16} for FFM which is unfair to compare the model component. Furthermore, they randomly split the dataset into train (80%), valid(10%), test(10%). However, we split the dataset into train (70%), valid(20%), test(10%). Please refer to reading Appendix B in our paper.\n   * For fair comparison, we set the same embedding dimension as 10 for all models and without using l2 regularization. We only tune the dropout ratio and learning rates. Also different from [1], we implement all models in TensorFlow the same as AFN[2] and NFM[3].\n\n\n### Question 2: \nWhy do we use low-rank strategies?\n### Respose to Q2:\nThe original hypernetwork-style implementation causes larger computation and parameters. As shown in Table 2(a) in our paper, HyperDense achieves similar performance with MLP while having much more parameters.  In section 2.3, we have stated the low-rank methods help reduce the quadratic complexity of W. In Dynamic Conv[1] and CondConv[2], the low-rank strategy can be seen as the efficient implementation of MoE.\n\nThe related part in original paper is quoted as follows:\n\n>  compares different types of a feature-based dynamic operation added to the DNN baseline (right after the embedding layer for replacing the fully-connected layer). After we search the best DNN baseline model, we replace a dynamic operation with the first fully-connected layer. We list the results of different weight-generate functions, where not all methods perform better than the baseline. We implement the hypernetworks-based idea as HyperDense which slightly improve the baseline while add a big chunk of computation resulting for optimization difficulty. When we adopt our proposed simple and effective method, gate mechanism can be exploited for better performance, which means mixture of kernels have better generality.\n\n\n\nRegarding the typo, thank you for pointing it out. We have modified it in the revised version. \n\n\n\n[1] Field-wise Learning for Multi-field Categorical Data, NeurIPS 2020.\n\n[2] Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions\n\n[3] Neural Factorization Machines for Sparse Predictive Analytics\n\n[4] Dynamic Convolution: Attention over Convolution Kernels\n\n[5] CondConv: Conditionally Parameterized Convolutions for Efficient Inference"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "36nAkqlQSoY",
        "original": null,
        "number": 11,
        "cdate": 1636615394621,
        "mdate": 1636615394621,
        "ddate": null,
        "tcdate": 1636615394621,
        "tmdate": 1636615394621,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "JHyqhwqvMft",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Concerns on experiment setting",
          "comment": "In my experience, the split settings train (80%), valid(10%), test(10%) or train (70%), valid(20%), test(10%) will not make results changing a lot in the datasets Avazu and Criteo. I also checked some baselines used in this paper, such as [1]  and [2], both of them used the random split setting 80%, 10%, 10%, For example: in [2]:For the Criteo dataset and the Dianping dataset, we randomly split instances by 8:1:1 for training , validation and test; and in [1]: For each dataset, we randomly split the instances by 8:1:1.  However, in this paper, the author seems  to use the same setting (hyperparameters) for their baselines but using the different dataset splits instead, which is unfair. Furthermore, I suggest authors do not use a unified train/valid/test splits because it against the generality. I also suggest adding comparisons with [3].\n\n[1]Adaptive Factorization Network: Learning Adaptive-Order Feature Interactions\n[2]xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems\n[3] Field-wise Learning for Multi-field Categorical Data, NeurIPS 2020."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_pP6H"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_pP6H"
        ]
      },
      {
        "id": "rvhbRkedcU9",
        "original": null,
        "number": 12,
        "cdate": 1636621824233,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636621824233,
        "tmdate": 1636627608180,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "UxR3LCb5nXs",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer 2XAa",
          "comment": "We thank the reviewer for highlighting the significance of our work and valuable suggestions. We address the reviewer\u2019s questions below:\n### Response to Question about the metrics in Table 7 in DPN:\n\n1. For sponsored search advertising, we mainly focus on the CTR gain on the main traffic. More metrics like CVR, CPC, ctrPR, ctrPI, RPM etc have been attached below.\n| CVRgain | CPC    | ctrPR  | ctrPI  | RPM    |\n| ------- | ------ | ------ | ------ | ------ |\n| +1.22%  | +0.51% | +1.21% | +0.54% | +1.73% |\n2. In the online A/B testing, typically it\u2019s hard to evenly segment the traffic by user/query but the system can segment similar user/query for fair comparison. For the details, we adopt the 10% of the main traffic for online A/B testing where 5% serves on the base model and another 5% serves on ours. The system controls to segment the traffic evenly.\n3. We observe that CPC has increased somewhat. Because the search advertisement system is more complicated than the recommendation system. After finerank stage, other modules will utilize the ranking result or the CTR values. For instance,  CVR models are mainly based on the CTR value to adaptively change the bid. However, the details of other modules are not revealed in finerank stage. Over-descriptive may affect the subject of our paper.\n\n### Response to Question about TP99 latency:\n1. The main reason is the computation brought by sequence-based dpo. Dynamic Convolution aims to build shared convolution kernels over all time-steps. However, TensorFlow doesn't provide an efficient implementation, which has occurred in DyConv[1]. Besides,  we find that the convolution operation induces large computation and memory overhead while the matmul in SelfAttention is light-weight. For most users, the modelled behavior length is more than 250 in the ad system which is longer than other online A/B test settings as far as we know. Thus we observe a similar gain on TP50/TP99/TP99.9 latency. A considerable method to address the computation complexity is to use multi-head sequence-based dpo or reduce the dimension in dpo while the memory overhead need more engineering works.\n\n### Response to the Question about the details of \"Relation to FM\":\n\nAs shown in [2], FM can be formulated as:\n\n\\begin{equation}\\begin{aligned}\n        y(x) &= b + \\sum_{i=1}^{n} w_i x_i + \\sum_{i=1}^{n} \\sum_{j=i+1}^{n} <v_i, v_j> x_i x_j \\\\\n             &= linear(x;\\theta) + \\frac{1}{n-1} \\sum_{i=1}^{n} (v_i x_i \\otimes \\sum_{\\forall j!=i} v_j x_j)\\\\\n            %  &= linear(x;\\theta) + \\frac{1}{n-1} \\sum_{i=1}^{n} g(x_i|\\theta_g) h(\\hat x_j|\\theta_h)) \\\\\n             &= linear(x;\\theta) + \\frac{1}{n-1} \\sum_{i=1}^{n} f(v_i x_i;g(\\sum_{\\forall j!=i } v_j x_j)) \\\\\n    \\end{aligned}\\end{equation}\nWhere $v$ denotes the embedding table, $x$ denotes the categorical features. Thus we can decompose the output $y$ as summation of each field-wise interaction features. Thus the function $f$ and function $g$ can be represented for matrix multiplication and identity function. The self-excluded version means we use the $\\sum_{\\forall j!=i}v_j x_j$ as context features which exclude the input feature $v_i x_i$.\n\n### Response to Question about the reason to separate traditional/sequnce-based CTR prediciton:\n\nTraditional CTR prediction mostly focuses on the feature-interaction methods, which neglect the sequential information of user behavior not only in datasets but also the proposed methods, e.g. DCN, DeepFM, FFM. Furthermore, when using user behavior, the sparse sequence cannot be incorporated into some specific models, like OPNN, AFN, DCN etc, due to the different behavior length after flattening and concatenation. Thus the sparse user behaviors typically are mapped into low dimensional embedding vectors and transformed into fixed-length features. However, sequence-based CTR prediction aims to capture user interests by well-designed sequential models to learn the sequence information of user behaviors, e.g. DIN, DIEN. In real-world ranking systems, sequence-based models are often built as a sub-module together with traditional CTR models.\n\n\n[1] Pay Less Attention with Lightweight and Dynamic Convolutions, ICLR 2019\n\n[2] Factorization Machines, ICDM 2010"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone",
          "ICLR.cc/2022/Conference/Program_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Senior_Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "DmySTB3apm3",
        "original": null,
        "number": 13,
        "cdate": 1636623943186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636623943186,
        "tmdate": 1636624136426,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "rvhbRkedcU9",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Reviewer 2XAa (con'd)",
          "comment": "### More intuitions and discussions:\nWe would like to clarify the relation to mixture of experts, multiplicative interaction and dynamic convolution for better understanding. we have concluded these discussions in our revised version. \n\n>Relation to Mixture of Experts: We denote that it can act as another homogeneous implementation of MoE where the weight-generate function can be armed with an attention mechanism. Despite the similar complexity, our formulation is more favorable to be explained as the multiplicative interaction between two different features with an inner aggregation approach. However, Moe resorts to weighted aggregate the outputs of highly abstract expert towers. \n\n>Relation to Multiplicative Interaction: Eqn.(4) in the paper shows dynamic parameterized operation can be decomposed as explicit feature interaction term and implicit feature interaction term. The explicit term can be simply seen as a bilinear fusion operation which captures channel interaction. The implicit term means a low-order feature interaction mechanism.\n\n>Relation to Dynamic Convolution: We denote behavior-behavior operation that coincides with the ideas of Dynamic Convolution while differing on the motivation. DPO can be degraded to DyConv, if we set $g$ to combine softmax-normalized experts only depending on time-steps for depth-wise convolving.\n\n>Understanding of dynamic parameterized operation: Our dynamic parameterized operation is one method to fuse two different stream by pretending ordinary \"matrix multiplication\" or \"Convolution\" with contextual kernels. In the atom scene, we outspread the context representation from $\\mathbb R^{n}$ to $\\mathbb R^{m*c}$. As mentioned in section 2.3, when $c=1$ in the simplest situation, the dot production can be used to calculate similarity. Thus, we calculate $c$ times similarity if we set sigmoid as nonlinear function to learn robust features on the hypothesis that single calculation is not precise, i.e. $\\sigma(z^tx)\\rightarrow \\sigma(z^tWx)$, also can be seen as a bilinear operation . Hence, the next dynamic layer aims to integrate refined similarity into another context, yielding high-order similarity. Without the dynamic bias term, DPO can be reduced to a deep bilinear model. Beyond its capacity for channel interaction, DPO shows instance-wise interaction between channels and time-steps, i.e. convolve extracted time-steps with produced kernels by channels. \nAlthough fancy weight-generate function is not discussed in our work, we have shown it can introduce strong inductive bias, e.g. attention mechanism and local interaction."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "everyone",
          "ICLR.cc/2022/Conference/Program_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Senior_Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "clJyLqLD9v",
        "original": null,
        "number": 15,
        "cdate": 1637121867904,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637121867904,
        "tmdate": 1637217521257,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "36nAkqlQSoY",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to Experimental Setting",
          "comment": "We re-run our DPN following the same setting as[1]. After simply tuning some parameters, we find our DPN perform competively compared to the results in [1].  \n\n| Dataset | Models | Setting                                                | Auc    | Loss   | Params |\n| ------- | ------ | ------------------------------------------------------ | ------ | ------ | ------ |\n| Criteo  | DPN  | ebd_dim=100, lr=0.1, wdcy=1e-6, dropout=0.2            | 0.8130 | 0.4390 |  40.69M |\n| Avazu   | DPN  | ebd_dim=100, lr=0.01, wdcy=1e-5, dropout=0.8           | 0.7960 | 0.3707 | 202.89M |\n| Criteo  | [1]    | ebd_dim=log_1.6_{d_i}, lr=0.01, wdcy=1e-6, lambda=1e-3 | 0.8129 | 0.4391 | 357.18M |\n| Avazu   | [1]    | ebd_dim=8, lr=0.1, wdcy=1e-8, lambda=1e-5              | 0.7946 | 0.3715 | 206.65M |\n\nFor all models, we use Adagrad optimizer with a batch size of 2048.\nCompared to [1], our DPN achieves better performance on Avazu while have similar results on Criteo. \nAlso, the DPNs have fewer parameters.\n\nThanks for your suggestions. We will include these results and give a more detailed analysis in our final version upon the acceptance of this paper. \n\n[1]Field-wise Learning for Multi-field Categorical Data, NeurIPS 2020"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "ICLR.cc/2022/Conference/Program_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Senior_Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Authors",
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "ELEN8u8gjV",
        "original": null,
        "number": 16,
        "cdate": 1637221701463,
        "mdate": 1637221701463,
        "ddate": null,
        "tcdate": 1637221701463,
        "tmdate": 1637221701463,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "BCOzReSaqm",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "The contributions still seem incremental.",
          "comment": "# Motivation:\n\n## CAN aims to capture co-action:\n\nI think that \"co-action\" is an unnecessary and misleading term coined by the authors of CAN and do not see significant differences between \"co-action\" and \"feature-crossing\".\n\n## CAN only cares ... the INPUT STAGE:\n\nThis point seems irrelevant, because: (1) CAN can be trivially extended to handle the intermedia stages, and (2) more importantly, many of the existing works on feature crossing also focus mainly on the input stage.\n\n\n# Approach:\n\nI agree that the exact implementations are different. However, I believe that both [1] and [2] also fulfill the submission's title \"Dynamic Parameterized Network\". In this regard, this submission is not the first paper that comes up with a \"dynamic parameterized network for CTR prediction\", which makes the submission's contribution incremental.\n\n\n# Experiments:\n\n## CAN ... didn't conduct the experiments on industrial dataset. DPN ...:\n\nCAN is fully deployed in their systems. They certainly have their results on their industrial dataset. To be honest, reporting results on the industrial dataset provides no extra insight if A/B testing results are already reported.\n\n## About the reported results:\n\nI share the same concerns with the other reviewers and suspect that the baselines might not be well-tuned.\n\nMoreover, I strongly encourage the authors to provide some showcases that can illustrate why the proposed method works and on what kind of data it excels while the baselines do not.\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_AzFU"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_AzFU"
        ]
      },
      {
        "id": "HkWXrEfJTY",
        "original": null,
        "number": 17,
        "cdate": 1637336034322,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637336034322,
        "tmdate": 1637637194992,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "ELEN8u8gjV",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Comment",
        "content": {
          "title": "Response to the Reviewer AzFU",
          "comment": "## Response to the Motivation of CAN:\n\n1. In CAN, the co-action is defined as the co-occurence of feature A and B which is treated as a new feature corresponding to the baseline model named as \u201ccartesian production\u201d. As shown in their paper, though, such a model induces problems of huge computation and difficulty to learn low frequency features while beating SOTA combinatorial embedding methods such as PNN, NCF, DeepFM. Overall, they propose that pairwise feature combination implemented by CARTESIAN PRODUCT is better than well-known feature-crossing methods but suffers from huge complexity. Thus, they propose CAN to mitigate the de facto of the CARTESIAN while having competitive performance.  What\u2019s the motivation of CAN If \u201cco-action\u201d is the same as \u201cfeature-crossing\u201d ?\n\n2. We have stressed that CAN is only employed on the input stage without any other extensive experiments in the intermediate stages. However, DPN reparameterize all the neurons by context in feature-based, field-based and sequence-based methods. Our papers propose a generic DPO formulation and provide more ablation studies about how to build weight-generate and feature-aggregation operations in DPO which covers not only the stages where we aim to deploy but also specific implements corresponding to the dataset. We strongly disagree with the statement [2].  The methods of feature-crossing contain a stacked paradigm and parallel paradigm. The first contains IPNN, OPNN. The latter contains DeepFM, XDeepFM, DCN, DCN v2. \nWe don\u2019t deny the contribution of CAN. The contribution of DPN aims to broaden the stacked and parallel paradigm by introducing explicit and implicit interaction modules into a module together while CAN still follows a stacked paradigm.\n\n## Response to Approach:\n\nWe have stated the difference in [1] and [2] by comparing the formulation and implementation both on traditional ctr prediction and user behavior modeling. But the reviewer still sticks to the semantics of the title of our paper which avoids the contribution of our papers. In [1] and [2], they somewhat fulfill the dynamic attribute by introducing multiplication between pairwise features into a submodule of a big model. But we don\u2019t observe any clear claims about the relationship to dynamic neural networks nor citation to the  dynamic neural networks. Please elaborate the evidence of how [1] and [2] clearly claim the dynamic network as shown in our paper and their improvement over static counterparts. \n\n## Response to the Experiment\n\n1. There are no offline results presented on the industrial dataset in the CAN paper which is an important proof to verify the reliability of the proposed method.The point that results on the industrial dataset provides no extra insight if the A/B testing results reported is nonsense. Just as the reviewer mentioned before, bare online A/B test results are not convincing enough which can be achieved easily with low baselines. It is common to have inconsistent results between offline experiments and online A/B test in the real-world recommender systems due to the complexity of the industrial data. Therefore, consistent performance on both offline industrial experiments and online A/B tests can serve as strong evidence for the effectiveness of the methods. If the reviewer really knows the recommender systems in the real-world production, it is unbelievable to make this statement.\n\n2. We have clearly stated the experimental settings in our paper. Please also refer to the response to Reviewer pP6H.\n\n3. We have indeed included showcases to show the benefit of our paper on warming up infrequent user embeddings, which is clearly reported in Table 3 and Table 5. The related part in the original paper is quoted as follows:\n> We found they share similar results for most experiments while get best performance when we set context as zt  (i.e. use the tag information of context embeddings as context inputs). This handcraft best results mainly originate from the expertise knowledge of MovieLens dataset and recommendation system. Meanwhile, it reveals a nice property of our methods: the intrinsic decoupling attribute can be more separably modeled. \n\nEnhancing the interaction of non-user features with global embedding reduces the dependence on the sufficiency of user features, and improves the performance on infrequent user embeddings accordingly.\nAlso, we conducted analysis of relations to the mixture of experts, multiplicative interaction and dynamic convolution in our paper for better understanding the intuitions of our paper. Please refer to Appendix H on page 22 in the revised version.\n\n\n[1] CAN: https://arxiv.org/abs/2011.05625\n\n[2] A Meta-Learning Perspective on Cold-Start Recommendations for Items. NeurIPS 2017.\n\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ],
        "readers": [
          "ICLR.cc/2022/Conference/Program_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Senior_Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Area_Chairs",
          "ICLR.cc/2022/Conference/Paper100/Reviewers",
          "ICLR.cc/2022/Conference/Paper100/Authors",
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Authors"
        ]
      },
      {
        "id": "U8S7uxGIEH",
        "original": null,
        "number": 1,
        "cdate": 1642696837420,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696837420,
        "tmdate": 1642696837420,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "Although scores are somewhat mixed, even ignoring the most negative review the overall score would still be somewhat below the acceptance threshold.\n\nThe authors and reviewers had a robust discussion, mostly about the novelty, experimental setting, and the significance of the results. Although the discussion ultimately did not reach a consensus, I think there are valid points on both sides. E.g. I somewhat disagree with the reviewer that the paper is too application-focused for ICLR, though several other points remain valid. The overall message that the experiments seem not totally convincing was highlighted by multiple reviewers."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "directReplies": [
      {
        "id": "UxR3LCb5nXs",
        "original": null,
        "number": 1,
        "cdate": 1635663631186,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635663631186,
        "tmdate": 1635663631186,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed a new method to handle feature/context interactions within the eCTR prediction neural networks. Details are provided in different scenarios. Experiments are conducted for offline and real-world experiments with promising results.",
          "main_review": "Strengths:\n1. A good way to model and utilize feature/context interactions in order to better predict CTR.\n\n2. Promising offline/online results and detailed discussion of offline results.\n\n3. Well written paper. Clear illustration of the methodology as well as discussions about the relations with existing methods\n\nWeaknesses:\n1. Table 7 is way too simple, and so are related descriptions for the experiments. Are there more metrics to demonstrate the superiority of the new method? Is it affecting different segments of queries/users evenly? More details would be helpful to make the A/B test results stronger. Also, it seems CPC also increased. Any intuitions?\n\n2. Why TP99 jumped a lot? Is it purely from the network structure change? How about TP50/90/99.9?\n\n3. Page 4 \"Relation to FM\" would be more interesting to have details. The current high-level discussion is confusing. What is \"self-excluded version\"?\n\n4. In section 2.1 Preliminary, why is it helpful to separate traditional/sequence-base CTR prediction? \n\n5. To distinguish from \"a random paper which tweaks the neural network structure for better performance\", I would suggest more intuitions or discussions on why the added interaction component helps with the CTR prediction accuracy.\n",
          "summary_of_the_review": "It's a methodology paper working on an important problem (CTR prediction). The proposed method is not extremely innovative but the idea is natural and makes sense, so are the results positive and promising. The novelty is a subjective matter but personally I see enough contributions to clarify and materialize some of the vague commonsense in the industry. One minor concern is about its relevance to \"ICLR\" which focuses on representation learning.",
          "correctness": "4: All of the claims and statements are well-supported and correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_2XAa"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_2XAa"
        ]
      },
      {
        "id": "zWgrfthWzIe",
        "original": null,
        "number": 2,
        "cdate": 1635753169265,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635753169265,
        "tmdate": 1635753169265,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed a module DPO for CTR prediction to enhence the explicit and implicit information. The authors claimed that they provide the first attempt to extend the dynamic neural networks to CTR prediction, and experiments show that DPN (Dynamic Parameterized Network) significantly outperforms other state-of-the-art methods. ",
          "main_review": "Pros: \n1) This paper is organised well and clearly written. 2) The idea of behavior modeling is novel to me. 3) Detailed theoretical analysis.\n\nCons:\n1) Even though I think the proposed method is technically sound, the results cannot convince me. For the experimental results shown in Table 1, some baselines run worse than their normal performances, and the result of Dynamic Parameterized Network seems not good enough, e.g. compared with the results in [1]. \n2) Eq.5, how to demostrate the rationality of using the low-rank strategy.\n3) few typos, e.g., section 2.5, actions.to\n\n[1] Field-wise Learning for Multi-field Categorical Data, NeurIPS 2020.",
          "summary_of_the_review": "The idea is somewhat novel, but the result is not good enough.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_pP6H"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_pP6H"
        ]
      },
      {
        "id": "kFcdvrjuCoO",
        "original": null,
        "number": 3,
        "cdate": 1635873151026,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635873151026,
        "tmdate": 1635873151026,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This submission is on modeling feature interactions for CTR prediction. It proposes a framework that follows meta-learning. Specifically, to model the interaction between feature F1 and feature F2, it uses a meta neural-network g(F1) that takes F1 and produces the parameter for another neural network f(F2) that takes F2, i.e., the outcome of feature crossing is f(F2) where f's parameter is g(F1). It outperforms the baselines and is deployed online.",
          "main_review": "Pros:\n- The algorithm is deployed in a real-world production system.\n- Many variants are proposed and empirically studied.\n\nCons:\n- Not enough novelty. The idea is almost the same as [1] and [2]. Both [1] and [2] conducts feature crossing by using one feature to generate the parameters of a neural network that takes another feature as input. Note that [1] is a recent work that has been deployed in a large-scale real-world e-commerce system as well and is a well-known work among some industry practitioners, especially in China.\n- More details about the experimental setup may be needed to assess if the setup is fair. For example, please consider reporting the total number of parameters of each baseline, since sometimes performance can be increased by simply increasing the model's capacity. It seems possible that the so-called state-of-art baselines are not well-tuned.\n- The reported +1% improvement in the online A/B test could be meaningless without details about the production systems. For example, +1% improvement in an early-stage business with a weak baseline is not as impressive as +1% improvement in a well-developed business with a strong baseline.\n- The writing can be improved.\n\n[1] CAN: https://arxiv.org/abs/2011.05625\n\n[2] A Meta-Learning Perspective on Cold-Start Recommendations for Items. NeurIPS 2017.",
          "summary_of_the_review": "The idea is almost the same as the existing works, especially [1].",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "3: reject, not good enough",
          "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper100/Reviewer_AzFU"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper100/Reviewer_AzFU"
        ]
      },
      {
        "id": "U8S7uxGIEH",
        "original": null,
        "number": 1,
        "cdate": 1642696837420,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696837420,
        "tmdate": 1642696837420,
        "tddate": null,
        "forum": "oSP1hwZB24",
        "replyto": "oSP1hwZB24",
        "invitation": "ICLR.cc/2022/Conference/Paper100/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "Although scores are somewhat mixed, even ignoring the most negative review the overall score would still be somewhat below the acceptance threshold.\n\nThe authors and reviewers had a robust discussion, mostly about the novelty, experimental setting, and the significance of the results. Although the discussion ultimately did not reach a consensus, I think there are valid points on both sides. E.g. I somewhat disagree with the reviewer that the paper is too application-focused for ICLR, though several other points remain valid. The overall message that the experiments seem not totally convincing was highlighted by multiple reviewers."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "invitation": {
      "reply": {
        "writers": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "signatures": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "content": {
          "title": {
            "value-regex": ".*",
            "order": 1
          },
          "authors": {
            "values": [
              "Anonymous"
            ],
            "order": 2
          },
          "authorids": {
            "value-regex": ".*",
            "order": 3
          },
          "keywords": {
            "value-regex": ".*",
            "order": 6
          },
          "abstract": {
            "value-regex": ".*",
            "order": 8
          },
          "pdf": {
            "value-regex": ".*",
            "order": 9
          },
          "one-sentence_summary": {
            "value-regex": ".*",
            "order": 10
          },
          "supplementary_material": {
            "value-regex": ".*",
            "order": 11
          },
          "code_of_ethics": {
            "value-regex": ".*",
            "order": 12
          },
          "submission_guidelines": {
            "value-regex": ".*",
            "order": 13
          },
          "resubmission": {
            "value-regex": ".*",
            "order": 14
          },
          "student_author": {
            "value-regex": ".*",
            "order": 15
          },
          "serve_as_reviewer": {
            "value-regex": ".*",
            "order": 16
          },
          "community_implementations": {
            "required": false,
            "description": "Optional link to open source implementations",
            "value-regex": ".*",
            "markdown": true,
            "order": 103
          }
        }
      },
      "replyForumViews": [],
      "expdate": 1682960118639,
      "signatures": [
        "ICLR.cc/2022/Conference"
      ],
      "readers": [
        "everyone"
      ],
      "writers": [
        "ICLR.cc/2022/Conference"
      ],
      "invitees": [
        "ICLR.cc/2022/Conference"
      ],
      "tcdate": 1632875419419,
      "tmdate": 1682960118686,
      "id": "ICLR.cc/2022/Conference/-/Blind_Submission",
      "type": "note"
    }
  },
  "tauthor": "OpenReview.net"
}