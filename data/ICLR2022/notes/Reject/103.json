{
  "id": "cMBKc-0OTY5",
  "original": "1um-vxqiIit",
  "number": 103,
  "cdate": 1632875428852,
  "pdate": 1643407560000,
  "odate": 1633539600000,
  "mdate": null,
  "tcdate": 1632875428852,
  "tmdate": 1676330688522,
  "ddate": null,
  "content": {
    "title": "Kalman Filter Is All You Need: Optimization Works When Noise Estimation Fails",
    "authorids": [
      "~Ido_Greenberg1",
      "~Shie_Mannor2",
      "~Netanel_Yannay1"
    ],
    "authors": [
      "Ido Greenberg",
      "Shie Mannor",
      "Netanel Yannay"
    ],
    "keywords": [
      "Kalman Filter",
      "noise estimation",
      "optimization",
      "gradient descent",
      "parameterization"
    ],
    "abstract": "Determining the noise parameters of a Kalman Filter (KF) has been studied for decades. A huge body of research focuses on the task of noise estimation under various conditions, since precise noise estimation is considered equivalent to minimization of the filtering errors. However, we show that even a small violation of the KF assumptions can significantly modify the effective noise, breaking the equivalence between the tasks and making noise estimation an inferior strategy. We show that such violations are common, and are often not trivial to handle or even notice. Consequentially, we argue that a robust solution is needed - rather than choosing a dedicated model per problem.\nTo that end, we apply gradient-based optimization to the filtering errors directly, with relation to an efficient parameterization of the symmetric and positive-definite parameters of the KF. In a variety of state-estimation and tracking problems, we show that the optimization improves both the accuracy of the KF and its robustness to design decisions.\nIn addition, we demonstrate how an optimized neural network model can seem to reduce the errors significantly compared to a KF - and how this reduction vanishes once the KF is optimized similarly. This indicates how complicated models can be wrongly identified as superior to the KF, while in fact they were merely more optimized.",
    "pdf": "/pdf/d8f1d280c0797aebce0c0f6d5743d8ff67215313.pdf",
    "one-sentence_summary": "Optimization of the KF parameters (instead of determining them by noise estimation) is crucial whenever the KF assumptions are violated, and sometimes removes the need for more complicated models such as neural networks.",
    "supplementary_material": "",
    "code_of_ethics": "",
    "submission_guidelines": "",
    "resubmission": "",
    "student_author": "",
    "serve_as_reviewer": "",
    "paperhash": "greenberg|kalman_filter_is_all_you_need_optimization_works_when_noise_estimation_fails",
    "_bibtex": "@misc{\ngreenberg2022kalman,\ntitle={Kalman Filter Is All You Need: Optimization Works When Noise Estimation Fails},\nauthor={Ido Greenberg and Shie Mannor and Netanel Yannay},\nyear={2022},\nurl={https://openreview.net/forum?id=cMBKc-0OTY5}\n}",
    "venue": "ICLR 2022 Submitted",
    "venueid": "ICLR.cc/2022/Conference"
  },
  "forum": "cMBKc-0OTY5",
  "referent": null,
  "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission",
  "replyto": null,
  "readers": [
    "everyone"
  ],
  "nonreaders": [],
  "signatures": [
    "ICLR.cc/2022/Conference"
  ],
  "writers": [
    "ICLR.cc/2022/Conference"
  ],
  "details": {
    "overwriting": [],
    "tags": [],
    "writable": false,
    "replyCount": 13,
    "directReplyCount": 5,
    "revisions": true,
    "replies": [
      {
        "id": "rCg2w3aSiKW",
        "original": null,
        "number": 1,
        "cdate": 1635859630573,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635859630573,
        "tmdate": 1635859630573,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper proposes using gradient-based optimization to tune the state and noise covariance parameters defining a Kalman Filter via supervised learning (i.e., assuming access to ground truth state measurements during training).  The need for this approach is motivated by the stringent assumptions under which optimality of the Kalman Filter is shown, and that these assumptions often fail in practice.  It is shown through several case-studies that the Optimized Kalman Filter (OKF) not only significantly outperforms a baseline KF implemented with estimated noise covariances, but also matches or outperforms Extended Kalman Filters and an LSTM-based \"neural KF\" introduced by the authors.",
          "main_review": "Strengths\n\n+ The problem of estimating state from noisy observations for nonlinear systems is an open and important challenge, and the proposed method is intuitive and simple to implement, and appears to yield good empirical performance.\n\n+ The paper is clearly written and easy to follow.\n\n+ The empirical evaluations are comprehensive, in that many scenarios and baselines are considered.\n\nWeaknesses\n\n- Some of the more minor contributions are in fact well established.  While I completely agree that highlighting the shortcomings of the Kalman Filter in an expository manner provides excellent motivation for this work, the idea that state-estimation was a solved problem since Kalman and that the paper is reopening this solved problem is incorrect and a bit over the top.  That the Kalman Filter is only optimal under strong assumptions, and that it can fail spectacularly when these assumptions are violated, is very well known and hardly a contribution. Similarly, using a Cholesky parameterization for optimizing over PSD matrices is standard.  In light of this, I would recommend that the grandiose tone taken in the introduction perhaps be pared back a little bit, as I found it distracted from the otherwise nice insights of the paper.\n\n- Definition 2 is formulated under the assumption of a linear-time-invariant system; however, Kalman Filtering approaches in the time-varying setting also exist, see for example the textbook \"Linear Estimation\" by Sayed, Hassibi and Kailath.  That no such time-varying approach was used as a baseline was also disappointing, as this could likely have compensated for some of the errors introduced by nonlinear dynamics.\n\n- There has been a recent line of work on regret minimization based Kalman Filtering, which updates parameters/estimates online to compensate for the fact that \"effective noise\" is in fact rarely Gaussian or as modeled.  That no comparison to these baselines is presented is also disappointing.  These methods are further completely online, and require no labeled datasets for supervised learning.  Relevant papers to look at include:\n\n@article{goel2021regret,\n  title={Regret-optimal estimation and control},\n  author={Goel, Gautam and Hassibi, Babak},\n  journal={arXiv preprint arXiv:2106.12097},\n  year={2021}\n}\n\n@article{tsiamis2020online,\n  title={Online learning of the kalman filter with logarithmic regret},\n  author={Tsiamis, Anastasios and Pappas, George},\n  journal={arXiv preprint arXiv:2002.05141},\n  year={2020}\n}\n",
          "summary_of_the_review": "While the paper highlights and addresses an important problem, and proposes a simple yet effective solution, I believe that without a comparison to *online Kalman Filtering* approaches that minimize regret, it is impossible to determine if this truly represents an improvement over the state of the art in terms of empirical performance.  From a theoretical perspective, I see little to no novelty in the paper's contributions.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "3: reject, not good enough",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_D5C1"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_D5C1"
        ]
      },
      {
        "id": "Ha02MUsb1OM",
        "original": null,
        "number": 2,
        "cdate": 1635900669138,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635900669138,
        "tmdate": 1635900793404,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper targets the design of a classical filtering method - the Kalman filter (KF). The linearity assumption is a strong limitation of KF models although a wide range of variants have been demonstrated for non-linear systems. Different from these studies, the authors focused on the estimation of the noise models in the KF(-class) models, in order to improve the accuracy and robustness of the KF estimates, through an optimization method. The proposed approach was assessed on a benchmark dataset, and the results demonstrated the superiority of the proposed method. Also theoretical analyses are provided in the appendices.",
          "main_review": "(+) The paper is well-organized and well-written.\n\n(+) Theoretical analyses of the proposed optimization method.\n\n(-) Noise estimation in KF models is a classical and open issue. The authors should carefully claim their contributions on this point.\n\n(-) The proposed method is a supervised learning method - ground truths are required - this is the major downside as compared to the regular KF methods.\n\n(-) Cholesky decomposition-based gradient descent is not novel for SPD matrices estimation.\n\n(-) Only benchmark datasets were used to demonstrate the superiority to the baseline KF. The data from practical applications are expected. Although a few samples of the filtering results over the real-world data were given in the appendices, no statistical comparisons were shown.\n\n(-) It is not clear on the explanation of the benchmark results - what is the scale of the errors obtained? They should be relative or percentage values, to better understand the improvements.\n\n(-) As ground truths are involved, it is interesting to see how the machine learning methods other than KF-related perform. It is reasonable to compare the proposed approach to the KF-related methods only. However, the ground truths are enforced, which are the most costly and most difficult to obtain in practice. From this perspective, it would be necessary to demonstrate the proposed KF approach performs comparably against these supervised machine learning methods other than KF-related.",
          "summary_of_the_review": "Please refer to the weaknesses in the above section.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Qzvj"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Qzvj"
        ]
      },
      {
        "id": "ll0b3tZfOP3",
        "original": null,
        "number": 3,
        "cdate": 1635911867240,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635911867240,
        "tmdate": 1635911867240,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper claims that optimization of the Kalman filter parameters are needed in cases where the filter assumptions are violated.",
          "main_review": "The main contribution of the paper is not clear to me.\nIt looks like that the paper tackles the problem of noise estimation of the Kalman filter in an alternative method. However, the paper is not written in a cohesive way which makes it very difficult to follow what it narrates. It is not clear how different parts of the paper are related to each other.\nThe paper contains many well established concepts that looks unnecessary to include in the paper. \nThe title of the paper does not explain what has been tackled in the paper.\n",
          "summary_of_the_review": "The paper is not written well and does not have a flow. The rationale and objective of the paper is not clear. Therefore, I can not recommend it for publication. ",
          "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "3: reject, not good enough",
          "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_NGZA"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_NGZA"
        ]
      },
      {
        "id": "1KC7GyH6ocx",
        "original": null,
        "number": 4,
        "cdate": 1635989058774,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635989058774,
        "tmdate": 1635989058774,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper studies the problem of using Kalman filter for estimating the state of a dynamical system when the noise covariance matrices, for both state dynamics and observation, are unknown. The paper assumes access to trajectories of both state and observation. In this setting, a natural approach to solve the problem is to use the data to form an estimate for the covariance matrices. However, the paper argues that an optimization procedure to find noise covariance matrices to minimize the MSE is favorable and should become the \"new standard procedure for KF tuning\". With several numerical experiments, the paper illustrates that the optimization based KF tuning provides much better and robust result compared to standard KF based on estimation, and the comparisons made in the advanced neural network based estimation literature is not fair.\n\n\n\n\n ",
          "main_review": "The paper is nice to read. I think the message that the paper is trying to convey is very clear, important and impactful. I appreciated the simplicity of the message, the style of the paper, and the effort in addressing its limitations and connection to related work. \n\nHowever, I am not convinced with the main message that the  optimization based procedure is better than noise estimation. In particular, I am not sure how do the authors evaluate the noise estimation for nonlinear setting, since the formulas given in paper are only for linear observation model. If, for nonlinear observation model y = h(x) + w , the noise covariance is estimated with Cov[y-h(x)] from data, then this is indeed the optimal estimator for the covariance matrix in mse. For a trajectory (x_k,y_k), the difference y_k - h(x_k) = w_k, where w_k are i.i.d, and empirical covariance of w_k is the best mse estimate for cov(w). So I would appreciate if the authors explain the noise estimation for nonlinear observation model and theoretically why is it bad. I read appendix E, but I did not understand the need for defining \\tilde{H}, why not use the full nonlinear observation model to estimate R.     \n\nMoreover, it is not clear if the proposed optimization procedure has a unique solution. For example, in (Formentin and Bittanti, 2014), it is shown that the KF estimate depends only on the ratio of noise covariances in scalar case. Therefore, the MSE optimization problem can only recover the ratio between noise covariances. So, it would be great if the paper have a clear and precise statement of the optimization problem it aims to solve, and analysis on why the minimizer is unique.    \n\nAlso, a main disadvantage of the proposed procedure is that the optimization problem is highly nonlinear and nonconvex, specially after Cholesky decompostion. The paper does not provide any guarantee for its convergence, unlike estimation which simply follows from law of large numbers. \n\nSome minor questions/issues:\n1- I could not find the result in (Humpherys et al., 2012) that the paper refers to. \n\n2- It will be good to add some classical adaptive filtering papers by Mehra and Carew and B\u00e9langer.\n\n3- I don't think KF requires F and H to be time-invariant. \n\n4- I was confused by polar coordinates in 3d. Does it mean spherical? \n\n5- Does the proposed procedure have any advantage for linear Gaussian setting? \n\n\n   \n\n \n\n   ",
          "summary_of_the_review": "I recommend marginally below acceptance threshold. I think the paper is well-written, but it should be much more precise mathematically, explaining the estimation procedure for nonlinear setting, and address some fundamental questions about the optimization problem.  ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ]
      },
      {
        "id": "nbXyy7ueNZp",
        "original": null,
        "number": 1,
        "cdate": 1636669290251,
        "mdate": 1636669290251,
        "ddate": null,
        "tcdate": 1636669290251,
        "tmdate": 1636669290251,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "1KC7GyH6ocx",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Correctness explained; estimation definition clarified; numeric optimization discussion added",
          "comment": "We thank the reviewer for the helpful comments. We modified the paper according to the comments, and as explained below, we believe that the current discussion only proves the necessity of our work.\n\n1. **Correctness and noise estimation**:\n* Thanks for pointing out the unclarity. We now clarify the implementation of the KF and the tuning methods 1,2 given the non-linear Doppler model (mentioned in Section 4.1 and discussed in detail in Appendix A.3).\n* **We did in fact exactly what you said**: R:=Cov[y-h(x)] (or in our notation: Cov[z-h(x)] = Cov[z-H(x)*x]).\n* This is **not** optimal in terms of estimation-errors of x. It would be optimal if we knew h(x) in runtime. However, as we don\u2019t know x in runtime, we can only use an approximation of h(x) (denoted \\tilde{H} in Appendix E), which effectively adds noise to the filtering, leading to the results in Section 4.2.\n* There *is* in fact an optimal analytical correction in this case, discussed in Appendix E: R:=Cov[z-H(z)*x].\n* **This discussion demonstrates exactly how trying to pick the optimal analytical solution per setting is prone to errors**. And this discussion only refers to the Toy benchmark with the Cartesian KF baseline, out of tens of settings in the paper. One could look for analytical tricks in every single setting, which may be infeasible, tedious and prone to errors; or instead, one could simply use our optimizer.\n\n2. **Gradient-based optimization**:\n\n* That\u2019s an important discussion which is now added to the *limitations* paragraph (Section 1) and in more detail to Appendix L. Thanks!\n* Convergence is actually guaranteed under reasonable assumptions, but only to a local optimum. There is indeed no guarantee of convergence to the global optimum.\n* Having said that, algorithms such as SGD and Adam have been shown effective and robust in a wide variety of supervised problems with much higher complexity (e.g., BERT model with 340M parameters).\n* Note that the alternative - noise estimation - has no optimality guarantees either under practical assumptions, and in fact is analytically proven to be sub-optimal in a sample of private cases (Appendices E,F).\n\n3. **Uniqueness**: There indeed may be different valid solutions that yield the same model predictions, and the model could converge to any of them. We briefly discuss the issue in Appendix E, where Q=0 and thus the values of R only matter up to a constant factor.\n\nRegarding the minor comments:\n1. In (Humpherys et al., 2012), the assumptions are stated in Section 3 and the optimality in Section 3.2.\n2. Done, thanks.\n3. The KF framework is sometimes defined with F,H and sometimes with F_t,H_t. While the dynamics often depend on the unknown state X, they usually do not depend directly on the known time t, and thus we prefered to keep the simpler formulation. Note that both noise estimation and optimization can be trivially generalized to F_t,H_t.\n4. By polar we mean spherical. We fixed it, thanks for pointing it out.\n5. Yes, if the noise is not i.i.d (e.g. see Appendix F). If *all* the KF assumptions are known to hold, then there shouldn\u2019t be an advantage to optimization."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ]
      },
      {
        "id": "0pObvr-HV7s",
        "original": null,
        "number": 2,
        "cdate": 1636669498608,
        "mdate": 1636669498608,
        "ddate": null,
        "tcdate": 1636669498608,
        "tmdate": 1636669498608,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "ll0b3tZfOP3",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Response to comments",
          "comment": "The main claim of the reviewer is that the paper is unclear. The 3 other reviewers wrote:\n* \u201cI think the message that the paper is trying to convey is very clear\u201d (Eeik).\n* \u201cThe paper is well-organized and well-written\u201d (Qzvj).\n* \u201cThe paper is clearly written and easy to follow\u201d (D5C1).\n\nThe introduction explains our goal, framework, and \u201chow different parts of the paper are related to each other\u201d, as put by the reviewer. If there are more concrete unclarities, we will be happy to address them and appreciate the reviewer\u2019s help in identifying those."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ]
      },
      {
        "id": "NmMrcs5myzG",
        "original": null,
        "number": 3,
        "cdate": 1636669911638,
        "mdate": 1636669911638,
        "ddate": null,
        "tcdate": 1636669911638,
        "tmdate": 1636669911638,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "Ha02MUsb1OM",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Responses to comments",
          "comment": "We thank the reviewer for the helpful comments. As discussed below, we now did some rephrasing to ensure the clarity of our claims.\n\n1. **Re-opening a solved problem**: The problem that was considered solved is tuning of KF *given available ground-truth (hidden-states) data for training*: the gold-standard is to calculate the sample covariance matrix of the noise. We now rephrased this claim in Section 1 to ensure it is unambiguous.\n\n2. **Scope**: We indeed focus on filtering problems with available ground-truth training data, as we point to multiple times in the paper (e.g., in the *limitations* paragraph in Section 1). This is a standard framework, as can be seen in the references in Section 6. Our method is intended to leverage the supervised data whenever it is available; other methods are intended to work without it and thus cannot exploit it. This is not a weakness or a strength, but simply the scope of the problem.\n\n3. **Cholesky parameterization**: We essentially claim novelty only for using it to optimize the KF from ground-truth data. We now rephrased the corresponding paragraph at the end of Section 3 to make it clearer.\n\n4. **Real-world data**: Results are shown in Figure 3 in the front paper (the video tracking task), including statistical-significance metrics.\n\n5. **Scale of errors**: In all the experiments we report the absolute errors (not only relative ones), so the scale should be clear. Did you refer to the relative errors in the barplot in Figure 5? If so, the absolute errors are shown as labels in the figure (as explained in the caption).\n\n6. **Comparison to supervised learning models**: this is addressed in Section 5, where we compare our method to an LSTM-based model (and to additional models in Appendix K). Note that we keep the framework of the KF to provide the whole posterior estimation of the state, but the point-estimate of the predictions is provided directly by the supervised LSTM.\n\nFinally, regarding the second (+): our theoretical analysis explains why noise-estimation is not optimal, thus justifying the necessity of optimization. However, we do not provide theoretical analysis of the proposed gradient-based optimization, which is a whole field of research by itself (see the new Appendix L).\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ]
      },
      {
        "id": "c6ylW3X3Mza",
        "original": null,
        "number": 4,
        "cdate": 1636671643730,
        "mdate": null,
        "ddate": null,
        "tcdate": 1636671643730,
        "tmdate": 1636671905505,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "rCg2w3aSiKW",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Contribution claims rephrased for clarity; baselines suggested by the reviewer do not address the same problem",
          "comment": "We thank the reviewer for the comments, and look forward to a fruitful discussion. Rereading our claims in the introduction, we see how some of them could be interpreted differently than intended, and we rephrased accordingly (in particular in the contribution paragraph). Regarding the baselines for comparison, if we understand the suggestions correctly, they correspond to inherently different frameworks and cannot address the problem presented in the paper, as explained below. We hope that the reviewer can clarify if we misunderstood any of their comments, or otherwise reconsider their recommendation.\n___\n1. **Novelty and correctness of claims**:\n* \u201cthe idea that state-estimation was a solved problem\u2026 is incorrect\u201d - this is indeed not our claim, and we cite many counter examples. Our claim is that *tuning KF parameters* given *ground-truth training data* was considered solved - the gold-standard is to calculate the sample covariance matrix of the noise. Having said that, we are willing to tone down the claim about reopening a closed problem, if after the rephrasing the reviewer still sees it as a source for unclarity.\n* We indeed cite the Cholesky parameterization as an existing technique for SPD optimization. We now also refined the paragraph discussing it in Section 3.\n* \u201cthat the KF is only optimal under strong assumptions\u2026 is well known\u201d - the actual claim is that the *parameters tuning* of KF is only optimal under the assumptions. And while no user would explicitly claim otherwise, **the sub-optimality still often goes unnoticed** - not out of ignorance, but due to sensitivity to details. An excellent example is our current discussion with Reviewer Eeik, where we try to agree on which analytical model is optimal in the Toy benchmark. **Thus, we believe that showing exactly how violating different assumptions causes different changes in the optimal parameters is an important contribution**.\n* The contribution discussed above justifies the need for **our main novelty: a simple method for tuning the KF from ground-truth data, which is robust to (noticed and unnoticed) model misspecifications**. This novelty does not pretend to be complicated - just putting together a few concepts to obtain lower errors in an important set of problems, in a way that is not currently done.\n* Another important contribution is deducing and demonstrating the popular erroneous methodology, where optimized complicated learning models are compared to a non-optimized KF.\n2. **Time-varying model**:\n\nThe problems discussed in the paper have stationary dynamics: the dynamics may be state-dependent (e.g. H=H(x_t)) but are not time-dependent. Thus, there is not a clear way to choose time-dependent models H_t or F_t, and no reason to believe they will help.\n\nRegarding the dependence on (the time through) the state - note that in the Doppler radar problem, where indeed H=H(x_t), our baseline KF implementation *does* exploit this dependence by using H=H(z_t) (as an approximation for the unknown H(x_t)). This is a common practice, but it was not stated clearly in the text before, and we now clarify it in Section 4.1 and Appendix A.3.\n\nThe distinction between time-invariant and time-dependent dynamics relates to the setting and is orthogonal to parameters optimization: both the standard noise-estimation and our optimization can be trivially generalized to a setting with given F_t & H_t instead of F & H.\n\n3. **Online regret minimization**:\n\nWhile the motivation is similar, the online framework is quite different: Tsiamis and Pappas, for example, rely on *the current trajectory*, with *no ground-truth data* (hidden-states), to predict the next *observation*. We rely on *offline data*, with *available ground-truth*, to predict the *hidden-state*. The online setting is thus substantially different and while interesting on its own, not the topic of our work.\n\nSupervised learning from an offline dataset is a common practice in filtering problems (see Section 6), and by no means is a special case of online learning. In such a setting, online learning (1) does not exploit most of the data, and (2) requires updates in runtime - which is often inapplicable to latency/compute-sensitive systems. If you need to monitor the plane that has just taken off, and you have a dataset of 100 trajectories X 30 time steps X [observation + hidden state], you don\u2019t try to build a new model from the 5 radar measurements collected in the last few seconds.\n\nThat being said, the distinction of our framework from online regret-minimization is important and we now added it to the related work section. Thanks for pointing this out.\n\nFinally, it is worth noting that we take a prominent algorithm used in every plane, car, and cell phone, and make it work better in a significant number of applications, just by changing its parameters. The possibility of addressing some of the shortcomings of the Kalman filter with online learning should not detract from our contribution."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ]
      },
      {
        "id": "LY7VgyZYb0K",
        "original": null,
        "number": 6,
        "cdate": 1637625477857,
        "mdate": 1637625477857,
        "ddate": null,
        "tcdate": 1637625477857,
        "tmdate": 1637625477857,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "nbXyy7ueNZp",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Response to rebuttal",
          "comment": "Thanks for taking the time to respond to my questions.\n\n- Why do you assume you don't know 'x'? I thought the proposed method trains on trajectories of state and observation.\n\n- The non-uniqueness is an important issue that should be discussed in the paper. It effects the generalization of the proposed method, in the sense that a change in dynamics or observation requires re training.  The learned noise parameters for dynamics and observation are dependent of each other and have no meaning on their own.  \n\n- Related to assumptions for Kalman filter in Def 2.1, it is simply wrong that KF requires time-invariant dynamics [1]. Please correct that! \n\n[1] Kalman, R. E. (1960). A new approach to linear filtering and prediction problems."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ]
      },
      {
        "id": "Z6IMuMTAcU5",
        "original": null,
        "number": 7,
        "cdate": 1637657268183,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637657268183,
        "tmdate": 1637697271768,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "LY7VgyZYb0K",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Response",
          "comment": "Thanks for responding.\n* As usual in supervised learning, we know x on training but not on testing/inference: \u201cOur work focuses on such problems with ground-truth available for learning (but not for inference after the learning, of course)\u201d (from the beginning of the intro). So we can\u2019t rely on x nor on h(x) in inference. Otherwise, our prediction model would be pred(z,x)=x.\n\n* If I suspect that the environment changed and want to update the model, I need to gather data and retrain - whether using noise estimation or supervised optimization, and even if the optimal solution were always unique. Did you mean that if I knew that specifically Q changed and R didn\u2019t, in noise estimation I wouldn\u2019t need to recalculate R? As I need to gather new data anyway for Q, this would hardly save me anything. In fact, using parameters optimization to compensate for errors in the modeling is the essence of our method, so in this sense retraining both Q and R is an advantage. Eventually, note that if we are not informed of the change in the environment, Appendix G (referred form Section 4) shows that empirically, our method actually generalizes better than noise estimation.\n\n* It is common to introduce the time-invariant model when the dynamics are indeed time-invariant, but you're right that we should stick to the more general framework in the introduction and the methods. We fixed it, thanks!"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ]
      },
      {
        "id": "jivgG3j2cXe",
        "original": null,
        "number": 8,
        "cdate": 1637782474488,
        "mdate": 1637782474488,
        "ddate": null,
        "tcdate": 1637782474488,
        "tmdate": 1637782474488,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "Z6IMuMTAcU5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Thanks for the clarifications. ",
          "comment": "Thanks for your response and clarifications. \n\n1- To make sure I understand correctly, why can't you use training data to do Cov[z-h(x)]  to learn the noise covariance? \n\n2- Thanks for explaining. I am not saying this as a significant disadvantage of  your proposed method. I think the non-uniqueness issue is important because the learned noise parameters, though giving the correct prediction after training, do not have physical meaning. I think this is a point a reader wants to see in the main paper. \n\nRegarding generalization, right now you are not considering any control input in dynamics. The proposed method suggests that the algorithm should be trained beforehand for each control input. While, a method that is based on learning the actual values of the noise parameters, can handle any control input without any retraining.\n\n3- Thanks for correcting. It is true that the KF is introduced in time-invariant setting in some textbooks, but it is wrong to mention this as limitation of KF.  "
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ]
      },
      {
        "id": "bGqedhjuwvv",
        "original": null,
        "number": 9,
        "cdate": 1637840553423,
        "mdate": 1637840553423,
        "ddate": null,
        "tcdate": 1637840553423,
        "tmdate": 1637840553423,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "jivgG3j2cXe",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Comment",
        "content": {
          "title": "Thanks for the comments",
          "comment": "1. We do exactly that. And this is indeed the sensor noise in the physical sense - yet not the optimal parameter for state prediction!\n\nWhy? As explained at the end of Section 4.2, in inference mode (testing) we must replace the unknown H(x) (e.g. by the approximation H(z)). This inserts noise to the *processing* of the observation (specifically in the Doppler component) - in addition to the noise of the observation itself - thus the *effective* Doppler noise in inference is larger. The optimization takes care of this phenomenon even if we fail to notice it; and while this whole discussion focuses on a single scenario, the optimization also handles tens of other scenarios in our experiments - each with its own (known and unknown) issues.\n\n2. Thanks for pointing this out, we will add it to the discussion. The optimized parameters may actually reveal interesting physical meaning (e.g. as with the Doppler noise discussed above), but this meaning is indeed entangled with the other params and the state prediction process.\n\nRegarding control, this is indeed out of our scope and is not included in the problem definition. We will mention it explicitly. Optimization in this case is an important extension that may be addressed in future work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Authors"
        ]
      },
      {
        "id": "cNlnVa9-_h1",
        "original": null,
        "number": 1,
        "cdate": 1642696837507,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696837507,
        "tmdate": 1642696837507,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "This paper studies the problem of estimating the trajectory of a linear dynamical system when the covariances for the process and observation noise are unknown. The standard solution is to estimate these covariances from data, and this paper instead suggests an optimization procedure. They show promising experimental results. However there are two shortcomings: In terms of theoretical guarantees, they can only show convergence to a local optimum. Moreover they assume they have access to the ground-truth hidden states. Although this is an assumption that has appeared in earlier works, it seems to limit the applicability."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "directReplies": [
      {
        "id": "rCg2w3aSiKW",
        "original": null,
        "number": 1,
        "cdate": 1635859630573,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635859630573,
        "tmdate": 1635859630573,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper proposes using gradient-based optimization to tune the state and noise covariance parameters defining a Kalman Filter via supervised learning (i.e., assuming access to ground truth state measurements during training).  The need for this approach is motivated by the stringent assumptions under which optimality of the Kalman Filter is shown, and that these assumptions often fail in practice.  It is shown through several case-studies that the Optimized Kalman Filter (OKF) not only significantly outperforms a baseline KF implemented with estimated noise covariances, but also matches or outperforms Extended Kalman Filters and an LSTM-based \"neural KF\" introduced by the authors.",
          "main_review": "Strengths\n\n+ The problem of estimating state from noisy observations for nonlinear systems is an open and important challenge, and the proposed method is intuitive and simple to implement, and appears to yield good empirical performance.\n\n+ The paper is clearly written and easy to follow.\n\n+ The empirical evaluations are comprehensive, in that many scenarios and baselines are considered.\n\nWeaknesses\n\n- Some of the more minor contributions are in fact well established.  While I completely agree that highlighting the shortcomings of the Kalman Filter in an expository manner provides excellent motivation for this work, the idea that state-estimation was a solved problem since Kalman and that the paper is reopening this solved problem is incorrect and a bit over the top.  That the Kalman Filter is only optimal under strong assumptions, and that it can fail spectacularly when these assumptions are violated, is very well known and hardly a contribution. Similarly, using a Cholesky parameterization for optimizing over PSD matrices is standard.  In light of this, I would recommend that the grandiose tone taken in the introduction perhaps be pared back a little bit, as I found it distracted from the otherwise nice insights of the paper.\n\n- Definition 2 is formulated under the assumption of a linear-time-invariant system; however, Kalman Filtering approaches in the time-varying setting also exist, see for example the textbook \"Linear Estimation\" by Sayed, Hassibi and Kailath.  That no such time-varying approach was used as a baseline was also disappointing, as this could likely have compensated for some of the errors introduced by nonlinear dynamics.\n\n- There has been a recent line of work on regret minimization based Kalman Filtering, which updates parameters/estimates online to compensate for the fact that \"effective noise\" is in fact rarely Gaussian or as modeled.  That no comparison to these baselines is presented is also disappointing.  These methods are further completely online, and require no labeled datasets for supervised learning.  Relevant papers to look at include:\n\n@article{goel2021regret,\n  title={Regret-optimal estimation and control},\n  author={Goel, Gautam and Hassibi, Babak},\n  journal={arXiv preprint arXiv:2106.12097},\n  year={2021}\n}\n\n@article{tsiamis2020online,\n  title={Online learning of the kalman filter with logarithmic regret},\n  author={Tsiamis, Anastasios and Pappas, George},\n  journal={arXiv preprint arXiv:2002.05141},\n  year={2020}\n}\n",
          "summary_of_the_review": "While the paper highlights and addresses an important problem, and proposes a simple yet effective solution, I believe that without a comparison to *online Kalman Filtering* approaches that minimize regret, it is impossible to determine if this truly represents an improvement over the state of the art in terms of empirical performance.  From a theoretical perspective, I see little to no novelty in the paper's contributions.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "3: reject, not good enough",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_D5C1"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_D5C1"
        ]
      },
      {
        "id": "Ha02MUsb1OM",
        "original": null,
        "number": 2,
        "cdate": 1635900669138,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635900669138,
        "tmdate": 1635900793404,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper targets the design of a classical filtering method - the Kalman filter (KF). The linearity assumption is a strong limitation of KF models although a wide range of variants have been demonstrated for non-linear systems. Different from these studies, the authors focused on the estimation of the noise models in the KF(-class) models, in order to improve the accuracy and robustness of the KF estimates, through an optimization method. The proposed approach was assessed on a benchmark dataset, and the results demonstrated the superiority of the proposed method. Also theoretical analyses are provided in the appendices.",
          "main_review": "(+) The paper is well-organized and well-written.\n\n(+) Theoretical analyses of the proposed optimization method.\n\n(-) Noise estimation in KF models is a classical and open issue. The authors should carefully claim their contributions on this point.\n\n(-) The proposed method is a supervised learning method - ground truths are required - this is the major downside as compared to the regular KF methods.\n\n(-) Cholesky decomposition-based gradient descent is not novel for SPD matrices estimation.\n\n(-) Only benchmark datasets were used to demonstrate the superiority to the baseline KF. The data from practical applications are expected. Although a few samples of the filtering results over the real-world data were given in the appendices, no statistical comparisons were shown.\n\n(-) It is not clear on the explanation of the benchmark results - what is the scale of the errors obtained? They should be relative or percentage values, to better understand the improvements.\n\n(-) As ground truths are involved, it is interesting to see how the machine learning methods other than KF-related perform. It is reasonable to compare the proposed approach to the KF-related methods only. However, the ground truths are enforced, which are the most costly and most difficult to obtain in practice. From this perspective, it would be necessary to demonstrate the proposed KF approach performs comparably against these supervised machine learning methods other than KF-related.",
          "summary_of_the_review": "Please refer to the weaknesses in the above section.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Qzvj"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Qzvj"
        ]
      },
      {
        "id": "ll0b3tZfOP3",
        "original": null,
        "number": 3,
        "cdate": 1635911867240,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635911867240,
        "tmdate": 1635911867240,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper claims that optimization of the Kalman filter parameters are needed in cases where the filter assumptions are violated.",
          "main_review": "The main contribution of the paper is not clear to me.\nIt looks like that the paper tackles the problem of noise estimation of the Kalman filter in an alternative method. However, the paper is not written in a cohesive way which makes it very difficult to follow what it narrates. It is not clear how different parts of the paper are related to each other.\nThe paper contains many well established concepts that looks unnecessary to include in the paper. \nThe title of the paper does not explain what has been tackled in the paper.\n",
          "summary_of_the_review": "The paper is not written well and does not have a flow. The rationale and objective of the paper is not clear. Therefore, I can not recommend it for publication. ",
          "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "3: reject, not good enough",
          "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_NGZA"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_NGZA"
        ]
      },
      {
        "id": "1KC7GyH6ocx",
        "original": null,
        "number": 4,
        "cdate": 1635989058774,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635989058774,
        "tmdate": 1635989058774,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper studies the problem of using Kalman filter for estimating the state of a dynamical system when the noise covariance matrices, for both state dynamics and observation, are unknown. The paper assumes access to trajectories of both state and observation. In this setting, a natural approach to solve the problem is to use the data to form an estimate for the covariance matrices. However, the paper argues that an optimization procedure to find noise covariance matrices to minimize the MSE is favorable and should become the \"new standard procedure for KF tuning\". With several numerical experiments, the paper illustrates that the optimization based KF tuning provides much better and robust result compared to standard KF based on estimation, and the comparisons made in the advanced neural network based estimation literature is not fair.\n\n\n\n\n ",
          "main_review": "The paper is nice to read. I think the message that the paper is trying to convey is very clear, important and impactful. I appreciated the simplicity of the message, the style of the paper, and the effort in addressing its limitations and connection to related work. \n\nHowever, I am not convinced with the main message that the  optimization based procedure is better than noise estimation. In particular, I am not sure how do the authors evaluate the noise estimation for nonlinear setting, since the formulas given in paper are only for linear observation model. If, for nonlinear observation model y = h(x) + w , the noise covariance is estimated with Cov[y-h(x)] from data, then this is indeed the optimal estimator for the covariance matrix in mse. For a trajectory (x_k,y_k), the difference y_k - h(x_k) = w_k, where w_k are i.i.d, and empirical covariance of w_k is the best mse estimate for cov(w). So I would appreciate if the authors explain the noise estimation for nonlinear observation model and theoretically why is it bad. I read appendix E, but I did not understand the need for defining \\tilde{H}, why not use the full nonlinear observation model to estimate R.     \n\nMoreover, it is not clear if the proposed optimization procedure has a unique solution. For example, in (Formentin and Bittanti, 2014), it is shown that the KF estimate depends only on the ratio of noise covariances in scalar case. Therefore, the MSE optimization problem can only recover the ratio between noise covariances. So, it would be great if the paper have a clear and precise statement of the optimization problem it aims to solve, and analysis on why the minimizer is unique.    \n\nAlso, a main disadvantage of the proposed procedure is that the optimization problem is highly nonlinear and nonconvex, specially after Cholesky decompostion. The paper does not provide any guarantee for its convergence, unlike estimation which simply follows from law of large numbers. \n\nSome minor questions/issues:\n1- I could not find the result in (Humpherys et al., 2012) that the paper refers to. \n\n2- It will be good to add some classical adaptive filtering papers by Mehra and Carew and B\u00e9langer.\n\n3- I don't think KF requires F and H to be time-invariant. \n\n4- I was confused by polar coordinates in 3d. Does it mean spherical? \n\n5- Does the proposed procedure have any advantage for linear Gaussian setting? \n\n\n   \n\n \n\n   ",
          "summary_of_the_review": "I recommend marginally below acceptance threshold. I think the paper is well-written, but it should be much more precise mathematically, explaining the estimation procedure for nonlinear setting, and address some fundamental questions about the optimization problem.  ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper103/Reviewer_Eeik"
        ]
      },
      {
        "id": "cNlnVa9-_h1",
        "original": null,
        "number": 1,
        "cdate": 1642696837507,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696837507,
        "tmdate": 1642696837507,
        "tddate": null,
        "forum": "cMBKc-0OTY5",
        "replyto": "cMBKc-0OTY5",
        "invitation": "ICLR.cc/2022/Conference/Paper103/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "This paper studies the problem of estimating the trajectory of a linear dynamical system when the covariances for the process and observation noise are unknown. The standard solution is to estimate these covariances from data, and this paper instead suggests an optimization procedure. They show promising experimental results. However there are two shortcomings: In terms of theoretical guarantees, they can only show convergence to a local optimum. Moreover they assume they have access to the ground-truth hidden states. Although this is an assumption that has appeared in earlier works, it seems to limit the applicability."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "invitation": {
      "reply": {
        "writers": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "signatures": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "content": {
          "title": {
            "value-regex": ".*",
            "order": 1
          },
          "authors": {
            "values": [
              "Anonymous"
            ],
            "order": 2
          },
          "authorids": {
            "value-regex": ".*",
            "order": 3
          },
          "keywords": {
            "value-regex": ".*",
            "order": 6
          },
          "abstract": {
            "value-regex": ".*",
            "order": 8
          },
          "pdf": {
            "value-regex": ".*",
            "order": 9
          },
          "one-sentence_summary": {
            "value-regex": ".*",
            "order": 10
          },
          "supplementary_material": {
            "value-regex": ".*",
            "order": 11
          },
          "code_of_ethics": {
            "value-regex": ".*",
            "order": 12
          },
          "submission_guidelines": {
            "value-regex": ".*",
            "order": 13
          },
          "resubmission": {
            "value-regex": ".*",
            "order": 14
          },
          "student_author": {
            "value-regex": ".*",
            "order": 15
          },
          "serve_as_reviewer": {
            "value-regex": ".*",
            "order": 16
          },
          "community_implementations": {
            "required": false,
            "description": "Optional link to open source implementations",
            "value-regex": ".*",
            "markdown": true,
            "order": 103
          }
        }
      },
      "replyForumViews": [],
      "expdate": 1682960118639,
      "signatures": [
        "ICLR.cc/2022/Conference"
      ],
      "readers": [
        "everyone"
      ],
      "writers": [
        "ICLR.cc/2022/Conference"
      ],
      "invitees": [
        "ICLR.cc/2022/Conference"
      ],
      "tcdate": 1632875419419,
      "tmdate": 1682960118686,
      "id": "ICLR.cc/2022/Conference/-/Blind_Submission",
      "type": "note"
    }
  },
  "tauthor": "OpenReview.net"
}