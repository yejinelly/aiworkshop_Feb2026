{
  "id": "9W2KnHqm_xN",
  "original": "ep9-iMVsh57",
  "number": 95,
  "cdate": 1632875428238,
  "pdate": 1643407560000,
  "odate": 1633539600000,
  "mdate": null,
  "tcdate": 1632875428238,
  "tmdate": 1676330689366,
  "ddate": null,
  "content": {
    "title": "Successive POI Recommendation via Brain-inspired Spatiotemporal Aware Representation",
    "authorids": [
      "~Gehua_Ma1",
      "~Jingyuan_Zhao1",
      "~Huajin_Tang1"
    ],
    "authors": [
      "Gehua Ma",
      "Jingyuan Zhao",
      "Huajin Tang"
    ],
    "keywords": [
      "Neuroscience",
      "spatiotemporal aware modeling",
      "successive POI recommendation"
    ],
    "abstract": "POI vector representation (embedding) is the core of successive POI recommendation. However, existing approaches only rely on basic discretization and interval analyses and fail to fully exploit complicated spatiotemporal attributes of POIs. Neuroscience research has shown that the mammalian brain entorhinal-hippocampal system provides efficient graph representations for general knowledge. Moreover, entorhinal grid cells present concise spatial representations, while hippocampal place cells represent perception conjunctions effectively. Thus, the entorhinal-hippocampal system provides a novel angle for spatiotemporal aware representation, which inspires us to propose the SpatioTemporal aware Embedding framework (STE) and  apply to POIs (STEP). STEP considers two types of POI-specific representations: sequential representation and spatiotemporal conjunctive representation, learned using sparse unlabeled data based on the proposed graph-building policies. Notably, the spatiotemporal conjunctive representation represents POIs from spatial and temporal aspects jointly and precisely. Furthermore, we introduce a user privacy secure successive POI recommendation method using STEP. Experimental results on two datasets demonstrate that STEP captures POI-specific spatiotemporal information more accurately and achieves the state-of-the-art successive POI recommendation performance. Therefore, this work provides a novel solution to spatiotemporal aware representation and paves a new way for spatiotemporal modeling-related tasks.",
    "code_of_ethics": "",
    "submission_guidelines": "",
    "resubmission": "",
    "student_author": "",
    "serve_as_reviewer": "",
    "paperhash": "ma|successive_poi_recommendation_via_braininspired_spatiotemporal_aware_representation",
    "pdf": "/pdf/76bc46e614a95cdc197c0edadeb0d062e0ccaf1e.pdf",
    "supplementary_material": "",
    "_bibtex": "@misc{\nma2022successive,\ntitle={Successive {POI} Recommendation via Brain-inspired Spatiotemporal Aware Representation},\nauthor={Gehua Ma and Jingyuan Zhao and Huajin Tang},\nyear={2022},\nurl={https://openreview.net/forum?id=9W2KnHqm_xN}\n}",
    "venue": "ICLR 2022 Submitted",
    "venueid": "ICLR.cc/2022/Conference"
  },
  "forum": "9W2KnHqm_xN",
  "referent": null,
  "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission",
  "replyto": null,
  "readers": [
    "everyone"
  ],
  "nonreaders": [],
  "signatures": [
    "ICLR.cc/2022/Conference"
  ],
  "writers": [
    "ICLR.cc/2022/Conference"
  ],
  "details": {
    "overwriting": [],
    "tags": [],
    "writable": false,
    "replyCount": 12,
    "directReplyCount": 6,
    "revisions": true,
    "replies": [
      {
        "id": "kQQv6LR48Km",
        "original": null,
        "number": 1,
        "cdate": 1635600375544,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635600375544,
        "tmdate": 1635600375544,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "To address the successive POI recommendation problem, this paper proposes a brain-inspired spatiotemporal-aware embedding method, called STEP, which learns the conjunctive representations over the unique spatiotemporal context graphs. The experimental results demonstrate the superiority against other SOTA methods",
          "main_review": "This paper proposes a spatiotemporal-aware embedding framework and apply to the successive POI recommendation problem. The proposed method, called STEP, is inspired by the mammalian brain entorhinal-hippocampal system that has the conjunctive representation mechanism. Thus, the main motivation of the STEP is to learn the conjunctive representations on the unique spatiotemporal context graphs, which is different from the previous methods dealing with the spatial and temporal information separately.\n\nThe experiments are conducted on two real-world datasets, and the experimental results show that the proposed STEP could significantly outperform other baselines including embedding-recommender methods and one-stage methods, although the STEP does not utilize the user preference information.\n\nOverall, the proposed visiting time pattern encoding and spatiotemporal conjunctive embedding learning are interesting and useful, and the paper is well written. The concerns are list below:\n\n1.\tFor the neighboring timestamps, it is unclear why the weekend time is not be considered.\n2.\tThe paper claims that the proposed framework could be applied to other applications such as the wildlife preservation and urban traffic scheduling problems. However, it is better to give some more details about how to transfer the proposed method to other tasks. For example, the authors could provide a case study experiment on traffic scheduling problem.\n",
          "summary_of_the_review": "This paper is technically sound, and the experiments are sufficient. Thus, my rating for this paper is weak accept. ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_F7HP"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_F7HP"
        ]
      },
      {
        "id": "zY0OVuDJUW",
        "original": null,
        "number": 2,
        "cdate": 1635847572663,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635847572663,
        "tmdate": 1635847572663,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed SpatioTemporal aware Embedding framework for POIs (STEP), which considers two types of POI-specific representations: sequential representation and spatiotemporal conjunctive representation. Specifically, the spatiotemporal conjunctive representation represents POIs from spatial and temporal aspects jointly.",
          "main_review": "Strengths:\nThe paper proposed a new model to utilize both spatial and temporal information of POIs to make Successive POI Recommendations.\n\nWeaknesses:\n1. The paper claims the proposed solution is based on the entorhinal-hippocampal system to process spatial and temporal information. However, spatial and temporal information has long been applied for POI embedding and recommendations. It seems the major difference between the proposed model has the theoretical support from entorhinal-hippocampal systems while others have not, but I cannot find such proof in the paper.\n\n2. It's not clear to find a clear proof or discussion regarding the difference with other models in the use of spatial and temporal information.\n\n3. The writing of Section 3 needs more clarification. It's unclear if the STEP model in Section 3 is learned per sequence, per user, or all records together. The description in Section 3.1 says \"Given one POI and its context in the check-in sequence\", my understanding is:\nThe sequential model (Sec. 3.1) G_seq is learned for each sequence, which refers to \"one set of continuous checkins of one user in one day\". \nThe spatial model (Sec. 3.2) G_spa is learned for all POIs regarding their coordinates.\nThe temporal model (Sec. 3.3) is learned from all visits (from different sequences) to each POI.\nThe spatiotemporal neighboring considers both spatial model and temporal model. Thus, the recommendation highly prefers POIs in the top K closest neighbors which were also visited frequently by all users within a short time window.",
          "summary_of_the_review": "The paper needs to clarify the model definition and how each sub-model is integrated.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "details_of_ethics_concerns": "N/A",
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_a1wE"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_a1wE"
        ]
      },
      {
        "id": "54moBcrQjkp",
        "original": null,
        "number": 3,
        "cdate": 1635872400618,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635872400618,
        "tmdate": 1635872400618,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper proposed a successive POI recommendation method inspired by entorhinal-hippocampal system.",
          "main_review": "Strengths\n1. The writing is easy to follow.\n2. The inspiration from the entorhinal-hippocampal system is interesting.\n\nWeakness\n1. In the experiment, how to construct user preference embedding for baselines is not clear.\n2. What is the difference of the objective between the sequential model and time pattern model? It seems the sequential model can also capture temporal information.",
          "summary_of_the_review": "The inspiration is interesting. But some parts need further clarification. I suggest \"weak reject\".",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_qsPw"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_qsPw"
        ]
      },
      {
        "id": "okgYcZgSqP",
        "original": null,
        "number": 4,
        "cdate": 1635917585745,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635917585745,
        "tmdate": 1635917585745,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper proposes a SpatioTemporal aware Embedding framework (STE) and applies to POIs (STEP) for successive POI recommendation. Specifically, the proposed STE framework consists of three parts: the context graph building strategies to construct simplified affinity graphs, the spatiotemporal model to extract the spatiotemporal features of check-ins, and the sequential model to extract sequential feature of check-ins. ",
          "main_review": "The introduced spatiotemporal model of STE, which consists of a grid-cell spatial encoder and a visiting time encoder, is capable of mining the POI-specific spatiotemporal characteristics. Finally, the authors implement successive POI recommendation systems based on the STEP using simple recurrent neural networks as recommenders. Experimental results on Instagram Check-in and Gowalla datasets demonstrate that STEP achieves the state-of-the-art successive POI recommendation performance. However, the novelty of this paper may be over-claimed. My detailed comments are as follows.\n\nPositive points:\n1.\tThe proposed conjunctive representing approach based on a unique spatiotemporal context graph solves the problem of previous spatiotemporal modeling methods in which spatial and temporal information are isolated and represented separately. \n2.\tThe proposed method does not need access to private information such as user preferences. \n3.\tThe experimental results on Instagram Check-in and Gowalla datasets demonstrate the proposed method outperforms baselines.\n\nNegative points: \n1.\tThe motivation and novelty of the proposed method are not convincing.\n1)\tIn the first contribution, the authors claim that they propose this method motivated by the graph-embedding strategy of structural knowledge in the entorhinal-hippocampal system, which is very confusing. The proposed sequential context graph $G_{seq}$ and spatial context graph $G_{spa}$ are very similar to temporal graph $G_t$ and spatial graph $G_s$ in STP-UDGAT[1], respectively. However, the authors do not explain anything about this.\n2)\tThe authors design the grid-cell spatial encoder motivated by grid-cells in the entorhinal-hippocampal system. However, it is worth noting that the formulations of the grid-cell spatial encoder are the same as Space2Vec [2]. The authors only slightly claim that the number of grid scales following the previous work [2].\n3)\tAccording to [3], hippocampal place cells encode a geometric representation of space. It is very confusing to claim that hippocampal place cells represent perception conjunctions effectively in the abstract. As shown in Figure 1, why do the authors propose the spatiotemporal conjunctive representation motivated by place cells? More explanations on it may be better.\n\n2.\tThe authors claim that POI $p_i$ and $p_j$ are spatiotemporal neighboring if they are spatial and temporal neighboring in Sec.3.2.2. However, why do average values of $E_{st}$ per POI exceed those of $E_{spa}$ per POI in Table 3?\n\nMinor issues:\n\n1.\tIn the Introduction, \"Most importantly, we elaborate \u2026 an visiting time encoder \u2026\" should be \"Most importantly, we elaborate \u2026 a visiting time encoder \u2026\".\n\n2.\tIn the One-stage methods of Sec.4, \u201can LSTM variant\u201d and \u201can LSTM-based method\u201d should be \u201ca LSTM variant\u201d and \u201ca LSTM-based method\u201d, respectively.\n\nReferences:\n\n[1]\tSTP-UDGAT : Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation. In Proceedings of the ACM International Conference on Information & Knowledge Management, pp. 845\u2013854, 2020.  \n[2]\tMulti-Scale Representation Learning for Spatial Feature Distributions using Grid Cells. In Proceedings of the International Conference on Learning Representations, 2020.  \n[3]\tThe hippocampus as a predictive map. Nature Neuroscience, 20(11):1643\u20131653, 2018.  \n",
          "summary_of_the_review": "The introduced spatiotemporal model of STE, which consists of a grid-cell spatial encoder and a visiting time encoder, is capable of mining the POI-specific spatiotemporal characteristics. Finally, the authors implement successive POI recommendation systems based on the STEP using simple recurrent neural networks as recommenders. Experimental results on Instagram Check-in and Gowalla datasets demonstrate that STEP achieves the state-of-the-art successive POI recommendation performance. However, the novelty of this paper seems to be over-claimed. ",
          "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_sU9T"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_sU9T"
        ]
      },
      {
        "id": "syACrp4kJaS",
        "original": null,
        "number": 1,
        "cdate": 1637137001514,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637137001514,
        "tmdate": 1637138614461,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Paper updated !",
          "comment": "Dear Reviewers:\n\nThanks for the beneficial reviews. We have tried our best to address all the points you have raised. Please find our detailed replies under your reviews. \n\nAfter revision and supplementation, we have updated our paper, including a *case study* about **traffic flow forecasting** with the proposed STE (presented in **Appendix. A**).\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "Nol86X4bHXJ",
        "original": null,
        "number": 2,
        "cdate": 1637137286724,
        "mdate": 1637137286724,
        "ddate": null,
        "tcdate": 1637137286724,
        "tmdate": 1637137286724,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "okgYcZgSqP",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Initial response to #sU9T",
          "comment": "We thank the reviewer for these insightful comments and suggestions. We have grouped our answers into topics with detailed explanations:\n\n\n\n**1. Context graph construction**\n\nBuilding affinities between elements into a graph is a very classic idea [1]. Usually, the affinity/similarity is calculated by a distance function. For example, euclidean distance is a common choice for measuring spatial similarity. Also, defining tokens within a specified-width window in sentences/sequences as neighbors are usual in the sentence/sequence-related embedding. \n\nThe core of the STEP is a conjunctive embedding model receiving observation&contextual information from spatiotemporal dimension. As the context graphs are used to preserve the qualitative adjacency relations, we assign non-weighted uniform edges to vertices. However, STP-UDGAT constructs spatial/temporal graphs for quantitative calculation in GAT layers to get STA vector  $\\vec{o}^A_{t_i}$\u200b\u200b\u200b\u200b\u200b\u200b\u200b. For this purpose, the edge weight of neighboring POI pairs in temporal graph $G_t$\u200b\u200b\u200b\u200b is assigned as $\\frac{1}{\\Delta \\hat{t}}$\u200b\u200b\u200b\u200b , *i.e.*, reciprocal averaged time interval and weight of $E_s$\u200b\u200b\u200b  is set to $\\frac{1}{\\Delta d(v_i, v_j)}$\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b.   Therefore, the graph construction in these two works follows some classical operations, but there are apparent differences in the resulting graph and graphs' usage.  In addition, the core of the context graph construction of our work is the construction of spatiotemporal context graph, based on which the STEP model can encode spatiotemporal conjunctions into the vector representation.\n\nWe agree with the reviewer that the content of this part should be improved. We have supplemented the discussion about this in the revised version of the paper to improve the content.\n\n\n\n**2. Grid-cell encoder in the spatial sub-model** \n\nWe claim to design the spatiotemporal model that consists of a spatial sub-model based on the grid-cell encoder, but not the grid-cell encoder itself, an essential part of the spatiotemporal model in STEP. The grid-cell encoder is based on the spatial representing theorem in [2], which also provides a classic multi-scale spatial representing formulation adopted in [3]. \nWe have improved the annotation and citation of this part of the content in the revised version.\n\n\n\n**3. Place cells**\n\nWhile performing remarkable ability to remember 'landmarks' in controlled laboratory environments,  place cells are thought to represent integrations (conjunctions) of sensory inputs from diverse dimensions and sensory & contextual information [4, 5].\n\nWe agree with the reviewer that this part could be improved and added relevant explanations in the revised version. \n\n\n\n**4. Fixes**\n\nWe have made corrections according to the comments of reviewers, including the issue of stats in Table.3-averaged $|E_{st}|$\u200b\u200b\u200b  caused by not dividing the number of timestamps and other minor expression issues. \n\n\n\n**Refs**\n\n[1] Hsu, Winston H., Lyndon S. Kennedy, and Shih-Fu Chang. \"Video search reranking through random walk over document-level context graph.\" *ACM MM*, 2007.\n\n[2] Ruiqi Gao, Jianwen Xie, and Ying, Nian Zhu, Songchunand Wu. Learning Grid Cells as Vector Representation of Self-Position Coupled with Matrix Representation of Self-Motion. *ICLR*, 2019.\n\n[3] Gengchen Mai, Janowicz Krzysztof, Yan Bo, Zhu Rui, Cai Ling, and Ni Lao. Multi-Scale Representation Learning for Spatial Feature Distributions using Grid Cells. *ICLR*, 2020.\n\n[4] Eichenbaum, Howard. \"On the integration of space, time, and memory.\" *Neuron* 95.5 (2017): 1007-1018.\n\n[5] Jeffery, Kathryn J. \"Integration of the sensory inputs to place cells: what, where, why, and how?.\" *Hippocampus* 17.9 (2007): 775-785."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "NAjrQxuX4v",
        "original": null,
        "number": 3,
        "cdate": 1637137497912,
        "mdate": 1637137497912,
        "ddate": null,
        "tcdate": 1637137497912,
        "tmdate": 1637137497912,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "54moBcrQjkp",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Initial response to #qsPw",
          "comment": "We thank the reviewer for these insightful comments and suggestions. We have grouped our answers into topics with detailed explanations:\n\n\n\n**1.** Some recommendation methods improve the quality of recommendations by assigning unique identifiers to users to depict their preferences. In our comparison table, these methods are marked as 'use user preference embedding' to emphasize the usage of user portrait since STEP only uses anonymous check-in sequences to get embeddings. Although the information from the user-depiction dimension could help the recommendation, it can also lead to privacy issues.\n\nIn different methods, the specific realization of obtaining user preference representation/modeling is different,  and detailed descriptions can be found in corresponding papers. Thus, in order to avoid repetitiveness, we do not give a detailed introduction in this paper.\n\n\n\n**2. Distinction between sequential and temporal information**\n\nIn the sequential model, the actual time information is actually replaced by the order in the sequence, this is realized by applying a top-k (k=1/2 w, w is the sequential neighboring window width) policy to filter closest POIs as sequential neighbors.  However, the time encoding part of the spatiotemporal model takes a purely temporal consideration, *i.e.*, encodes  timestamps into temporal observation $\\mathrm{t}$\u200b\u200b , and applies an $\\epsilon$\u200b\u200b-based ($\\epsilon =\\mathtt{h}$\u200b\u200b) policy (See Sec.3.2.2) to filter temporal neighbors. "
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "X2E45NszWw",
        "original": null,
        "number": 4,
        "cdate": 1637137564526,
        "mdate": 1637137564526,
        "ddate": null,
        "tcdate": 1637137564526,
        "tmdate": 1637137564526,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "zY0OVuDJUW",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Initial response to #a1wE",
          "comment": "We thank the reviewer for these insightful comments and suggestions. We have grouped our answers into topics with detailed explanations:\n\n**1.**  Existing works use either contextual information or observation information (such as time interval, spatial location) to represent POIs. Also, they represent items from temporal and spatial dimensions respectively, which leads to sub-optimal predictions. However, the brain-inspired [1,2] STEP  adopts a conjunctive representing method, which is reflected in two aspects. First, representing the conjunction of metric(observation) information and contextual (observation & context conjunction); second, combining information from spatial and temporal dimensions (representing spatiotemporal conjunctions that were built into $G_{st}$\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b).\n\n\n\n**2.** The STE framework focuses on item-specific representation. For POIs, the STEP representation is POI-specific, and all learning processes are geared towards optimizing POI representation using multiple data (observations and contextual information expressed by context graphs) from different dimensions. In the whole learning process, users are not differentiated, and the user preferences are not considered. \nThe sequential model in STEP describes POI from the check-in sequential perspective and results in the sequential adjacency consideration in the recommendation stage. \nOn the other hand, the spatiotemporal model in STEP describes POI's spatiotemporal nature and tends to recommend candidates with similar spatiotemporal characteristics (spatiotemporal conjunctions expressed by the geographical and visiting time pattern similar). \n\n\n\n**Refs**\n\n[1] Eichenbaum, Howard. \"On the integration of space, time, and memory.\" *Neuron* 95.5 (2017): 1007-1018.\n\n[2] Jeffery, Kathryn J. \"Integration of the sensory inputs to place cells: what, where, why, and how?.\" *Hippocampus* 17.9 (2007): 775-785."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "5goNVdW4imL",
        "original": null,
        "number": 5,
        "cdate": 1637138025561,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637138025561,
        "tmdate": 1637138362979,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "kQQv6LR48Km",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Initial response to #F7HP",
          "comment": "We thank the reviewer for these insightful comments and suggestions. We have grouped our answers into topics with detailed explanations:\n\n**1.** Methods to define temporal adjacency will directly affect the construction of the spatiotemporal context graph. Therefore, the characters of downstream tasks should be taken into account, combined with prior knowledge. This paper introduces a time adjacency definition method suitable for the POI representation task based on the analysis of POI visitings temporal patterns[1]. Specifically, in addition to the basic time adjacency window, we divided the timestamps into weekday/weekend to obtain more fine-grained temporal adjacency relations suitable for the POI downstream tasks like retrieval and recommendation. \n\n\n\n**2.** As the basis of traffic scheduling, it is very important to accurately predict the in/out flow of a region. We perform a case study on urban traffic flow forecasting with STE ,*i.e.,* STE of Traffic Grid (STE-TG). We listed the **RMSE** comparison results on TaxiBJ15 and TaxiBJ datasets in the following tables.  Please refer to **Appendix. A** in the updated paper for more details.\n\n\n\n| Method\\Dataset | TaxiBJ15 |\n| -------------- | -------- |\n| ARIMA          | 25.58    |\n| SARIMA         | 29.11    |\n| VAR            | 25.59    |\n| CNN            | 26.08    |\n| DeepST-CPTM    | 22.59    |\n| STE-TG(Ours)   | 21.92    |\n\n| Method\\Dataset | TaxiBJ |\n| -------------- | ------ |\n| HA             | 57.69  |\n| ARIMA          | 22.78  |\n| SARIMA         | 26.88  |\n| LinUOTD        | 21.23  |\n| ConvLSTM       | 19.54  |\n| DeepST-CPTM    | 18.18  |\n| STE-TG(Ours)   | 18.03  |\n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "RPC0wvTAn9O",
        "original": null,
        "number": 6,
        "cdate": 1637442534216,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637442534216,
        "tmdate": 1637442615724,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "okgYcZgSqP",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Further Discussion",
          "comment": "Thanks for the author's responses. The revised version provided an explanation of context graph construction between STEP and STP-UDGAT [1] and solved partial issues about my questions or concerns.\n\nThe two main concerns are still remaining:\n1. The inspiration from the entorhinal-hippocampal system is over-packaged.   \nThe responses agree that building affinity context graphs between elements are a classic idea [2], so the motivations from the entorhinal-hippocampal system are not convincing. The responses do not explain what is the relationships between the proposed graph-embedding strategy and the entorhinal-hippocampal system. Do any relevant studies clarify the graph-embedding strategy of the entorhinal-hippocampal system? \n\n2. The claims of place cells are vague.   \nThe responses claimed that place cells are thought to represent integrations (conjunctions) of sensory inputs from diverse dimensions and sensory & contextual information, which is hard to find support from [3, 4]. But it is too unclear and vague. According to [3], the place cells receive information from many different sensory sources to correctly localize their firing to restricted regions of an environment. As claimed in the conclusion of [3], much integration occurs upstream of the place cells. It is hard to say that place cells are thought to represent integrations (conjunctions). According to [4], the hippocampus map locations in spatially organized environments and map moments in temporally organized experiences. There is no evidence to demonstrate that place cells represent integrations (conjunctions) of space and time information in [4]. According to the authors, they propose the spatiotemporal conjunctive representation motivated by place cells, but this may not be credible.\n\nReferences:    \n[1] STP-UDGAT: Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation. In Proceedings of the ACM International Conference on Information & Knowledge Management, pp. 845\u2013854, 2020.    \n[2] \"Video search reranking through random walk over document-level context graph.\" ACM MM, 2007.   \n[3] \"Integration of the sensory inputs to place cells: what, where, why, and how?.\" Hippocampus 17.9 (2007): 775-785.   \n[4] \"On the integration of space, time, and memory.\" Neuron 95.5 (2017): 1007-1018.    \n\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_sU9T"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_sU9T"
        ]
      },
      {
        "id": "TAIv1gts9F",
        "original": null,
        "number": 7,
        "cdate": 1637458894764,
        "mdate": 1637458894764,
        "ddate": null,
        "tcdate": 1637458894764,
        "tmdate": 1637458894764,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "RPC0wvTAn9O",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Further response to #sU9T",
          "comment": "Thanks for the feedback! \n\nThe core of this paper is to bridge the spatiotemporal representation mechanism in the entorhinal-hippocampal circuit with practical spatiotemporal representation problems. Albeit the entorhinal-hippocampal structure has long been thought to be highly relevant to the outstanding performance of biological agents on spatiotemporal tasks, the gap between representational hypothesis and specific spatiotemporal tasks remains unbridged. The ability of the entorhinal-hippocampal circuit to represent conjunctions is considered to account for its powerful representation capability, although the clear biological experimental evidence of the spatiotemporal representation theory in the entorhinal-hippocampal circuit is not as thorough as the place cell's memory function for specific locations, as the reviewer said. Therefore, the STE is stated as being inspired by the representation mechanisms rather than mimicking them. In addition, some previous works [1, 2] have proposed model structures for reasoning tasks based on the conjunction representation mechanisms, like the observation-abstract location conjunction representing mechanism [3], in the entorhinal-hippocampal circuit.\n\n\n\n**Refs**\n\n[1] Whittington, J. C. R., et al. \"Generalisation of structural knowledge in the hippocampal-entorhinal system.\" Neural Information Processing Systems (NeurIPS), 2018.\n\n[2] Whittington, James CR, et al. \"The Tolman-Eichenbaum machine: Unifying space and relational memory through generalization in the hippocampal formation.\" *Cell* 183.5 (2020): 1249-1263.\n\n[3] Komorowski, Robert W., Joseph R. Manns, and Howard Eichenbaum. \"Robust conjunctive item\u2013place coding by hippocampal neurons parallels learning what happens where.\" *Journal of Neuroscience* 29.31 (2009): 9918-9929."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "2AGaOiknJhj",
        "original": null,
        "number": 1,
        "cdate": 1642696836781,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696836781,
        "tmdate": 1642696836781,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "Despite some positive points, the criticisms (and overall scores) put this paper below the bar. The reviewers raise issues of novelty, as well as problems with the experiments and argue that some claims are unsupported."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "directReplies": [
      {
        "id": "kQQv6LR48Km",
        "original": null,
        "number": 1,
        "cdate": 1635600375544,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635600375544,
        "tmdate": 1635600375544,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "To address the successive POI recommendation problem, this paper proposes a brain-inspired spatiotemporal-aware embedding method, called STEP, which learns the conjunctive representations over the unique spatiotemporal context graphs. The experimental results demonstrate the superiority against other SOTA methods",
          "main_review": "This paper proposes a spatiotemporal-aware embedding framework and apply to the successive POI recommendation problem. The proposed method, called STEP, is inspired by the mammalian brain entorhinal-hippocampal system that has the conjunctive representation mechanism. Thus, the main motivation of the STEP is to learn the conjunctive representations on the unique spatiotemporal context graphs, which is different from the previous methods dealing with the spatial and temporal information separately.\n\nThe experiments are conducted on two real-world datasets, and the experimental results show that the proposed STEP could significantly outperform other baselines including embedding-recommender methods and one-stage methods, although the STEP does not utilize the user preference information.\n\nOverall, the proposed visiting time pattern encoding and spatiotemporal conjunctive embedding learning are interesting and useful, and the paper is well written. The concerns are list below:\n\n1.\tFor the neighboring timestamps, it is unclear why the weekend time is not be considered.\n2.\tThe paper claims that the proposed framework could be applied to other applications such as the wildlife preservation and urban traffic scheduling problems. However, it is better to give some more details about how to transfer the proposed method to other tasks. For example, the authors could provide a case study experiment on traffic scheduling problem.\n",
          "summary_of_the_review": "This paper is technically sound, and the experiments are sufficient. Thus, my rating for this paper is weak accept. ",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "6: marginally above the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_F7HP"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_F7HP"
        ]
      },
      {
        "id": "zY0OVuDJUW",
        "original": null,
        "number": 2,
        "cdate": 1635847572663,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635847572663,
        "tmdate": 1635847572663,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "The paper proposed SpatioTemporal aware Embedding framework for POIs (STEP), which considers two types of POI-specific representations: sequential representation and spatiotemporal conjunctive representation. Specifically, the spatiotemporal conjunctive representation represents POIs from spatial and temporal aspects jointly.",
          "main_review": "Strengths:\nThe paper proposed a new model to utilize both spatial and temporal information of POIs to make Successive POI Recommendations.\n\nWeaknesses:\n1. The paper claims the proposed solution is based on the entorhinal-hippocampal system to process spatial and temporal information. However, spatial and temporal information has long been applied for POI embedding and recommendations. It seems the major difference between the proposed model has the theoretical support from entorhinal-hippocampal systems while others have not, but I cannot find such proof in the paper.\n\n2. It's not clear to find a clear proof or discussion regarding the difference with other models in the use of spatial and temporal information.\n\n3. The writing of Section 3 needs more clarification. It's unclear if the STEP model in Section 3 is learned per sequence, per user, or all records together. The description in Section 3.1 says \"Given one POI and its context in the check-in sequence\", my understanding is:\nThe sequential model (Sec. 3.1) G_seq is learned for each sequence, which refers to \"one set of continuous checkins of one user in one day\". \nThe spatial model (Sec. 3.2) G_spa is learned for all POIs regarding their coordinates.\nThe temporal model (Sec. 3.3) is learned from all visits (from different sequences) to each POI.\nThe spatiotemporal neighboring considers both spatial model and temporal model. Thus, the recommendation highly prefers POIs in the top K closest neighbors which were also visited frequently by all users within a short time window.",
          "summary_of_the_review": "The paper needs to clarify the model definition and how each sub-model is integrated.",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "details_of_ethics_concerns": "N/A",
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_a1wE"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_a1wE"
        ]
      },
      {
        "id": "54moBcrQjkp",
        "original": null,
        "number": 3,
        "cdate": 1635872400618,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635872400618,
        "tmdate": 1635872400618,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper proposed a successive POI recommendation method inspired by entorhinal-hippocampal system.",
          "main_review": "Strengths\n1. The writing is easy to follow.\n2. The inspiration from the entorhinal-hippocampal system is interesting.\n\nWeakness\n1. In the experiment, how to construct user preference embedding for baselines is not clear.\n2. What is the difference of the objective between the sequential model and time pattern model? It seems the sequential model can also capture temporal information.",
          "summary_of_the_review": "The inspiration is interesting. But some parts need further clarification. I suggest \"weak reject\".",
          "correctness": "3: Some of the paper\u2019s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
          "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_qsPw"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_qsPw"
        ]
      },
      {
        "id": "okgYcZgSqP",
        "original": null,
        "number": 4,
        "cdate": 1635917585745,
        "mdate": null,
        "ddate": null,
        "tcdate": 1635917585745,
        "tmdate": 1635917585745,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Review",
        "content": {
          "summary_of_the_paper": "This paper proposes a SpatioTemporal aware Embedding framework (STE) and applies to POIs (STEP) for successive POI recommendation. Specifically, the proposed STE framework consists of three parts: the context graph building strategies to construct simplified affinity graphs, the spatiotemporal model to extract the spatiotemporal features of check-ins, and the sequential model to extract sequential feature of check-ins. ",
          "main_review": "The introduced spatiotemporal model of STE, which consists of a grid-cell spatial encoder and a visiting time encoder, is capable of mining the POI-specific spatiotemporal characteristics. Finally, the authors implement successive POI recommendation systems based on the STEP using simple recurrent neural networks as recommenders. Experimental results on Instagram Check-in and Gowalla datasets demonstrate that STEP achieves the state-of-the-art successive POI recommendation performance. However, the novelty of this paper may be over-claimed. My detailed comments are as follows.\n\nPositive points:\n1.\tThe proposed conjunctive representing approach based on a unique spatiotemporal context graph solves the problem of previous spatiotemporal modeling methods in which spatial and temporal information are isolated and represented separately. \n2.\tThe proposed method does not need access to private information such as user preferences. \n3.\tThe experimental results on Instagram Check-in and Gowalla datasets demonstrate the proposed method outperforms baselines.\n\nNegative points: \n1.\tThe motivation and novelty of the proposed method are not convincing.\n1)\tIn the first contribution, the authors claim that they propose this method motivated by the graph-embedding strategy of structural knowledge in the entorhinal-hippocampal system, which is very confusing. The proposed sequential context graph $G_{seq}$ and spatial context graph $G_{spa}$ are very similar to temporal graph $G_t$ and spatial graph $G_s$ in STP-UDGAT[1], respectively. However, the authors do not explain anything about this.\n2)\tThe authors design the grid-cell spatial encoder motivated by grid-cells in the entorhinal-hippocampal system. However, it is worth noting that the formulations of the grid-cell spatial encoder are the same as Space2Vec [2]. The authors only slightly claim that the number of grid scales following the previous work [2].\n3)\tAccording to [3], hippocampal place cells encode a geometric representation of space. It is very confusing to claim that hippocampal place cells represent perception conjunctions effectively in the abstract. As shown in Figure 1, why do the authors propose the spatiotemporal conjunctive representation motivated by place cells? More explanations on it may be better.\n\n2.\tThe authors claim that POI $p_i$ and $p_j$ are spatiotemporal neighboring if they are spatial and temporal neighboring in Sec.3.2.2. However, why do average values of $E_{st}$ per POI exceed those of $E_{spa}$ per POI in Table 3?\n\nMinor issues:\n\n1.\tIn the Introduction, \"Most importantly, we elaborate \u2026 an visiting time encoder \u2026\" should be \"Most importantly, we elaborate \u2026 a visiting time encoder \u2026\".\n\n2.\tIn the One-stage methods of Sec.4, \u201can LSTM variant\u201d and \u201can LSTM-based method\u201d should be \u201ca LSTM variant\u201d and \u201ca LSTM-based method\u201d, respectively.\n\nReferences:\n\n[1]\tSTP-UDGAT : Spatial-Temporal-Preference User Dimensional Graph Attention Network for Next POI Recommendation. In Proceedings of the ACM International Conference on Information & Knowledge Management, pp. 845\u2013854, 2020.  \n[2]\tMulti-Scale Representation Learning for Spatial Feature Distributions using Grid Cells. In Proceedings of the International Conference on Learning Representations, 2020.  \n[3]\tThe hippocampus as a predictive map. Nature Neuroscience, 20(11):1643\u20131653, 2018.  \n",
          "summary_of_the_review": "The introduced spatiotemporal model of STE, which consists of a grid-cell spatial encoder and a visiting time encoder, is capable of mining the POI-specific spatiotemporal characteristics. Finally, the authors implement successive POI recommendation systems based on the STEP using simple recurrent neural networks as recommenders. Experimental results on Instagram Check-in and Gowalla datasets demonstrate that STEP achieves the state-of-the-art successive POI recommendation performance. However, the novelty of this paper seems to be over-claimed. ",
          "correctness": "2: Several of the paper\u2019s claims are incorrect or not well-supported.",
          "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
          "flag_for_ethics_review": [
            "NO."
          ],
          "recommendation": "5: marginally below the acceptance threshold",
          "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Reviewer_sU9T"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Reviewer_sU9T"
        ]
      },
      {
        "id": "syACrp4kJaS",
        "original": null,
        "number": 1,
        "cdate": 1637137001514,
        "mdate": null,
        "ddate": null,
        "tcdate": 1637137001514,
        "tmdate": 1637138614461,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Official_Comment",
        "content": {
          "title": "Paper updated !",
          "comment": "Dear Reviewers:\n\nThanks for the beneficial reviews. We have tried our best to address all the points you have raised. Please find our detailed replies under your reviews. \n\nAfter revision and supplementation, we have updated our paper, including a *case study* about **traffic flow forecasting** with the proposed STE (presented in **Appendix. A**).\n"
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference",
          "ICLR.cc/2022/Conference/Paper95/Authors"
        ]
      },
      {
        "id": "2AGaOiknJhj",
        "original": null,
        "number": 1,
        "cdate": 1642696836781,
        "mdate": null,
        "ddate": null,
        "tcdate": 1642696836781,
        "tmdate": 1642696836781,
        "tddate": null,
        "forum": "9W2KnHqm_xN",
        "replyto": "9W2KnHqm_xN",
        "invitation": "ICLR.cc/2022/Conference/Paper95/-/Decision",
        "content": {
          "title": "Paper Decision",
          "decision": "Reject",
          "comment": "Despite some positive points, the criticisms (and overall scores) put this paper below the bar. The reviewers raise issues of novelty, as well as problems with the experiments and argue that some claims are unsupported."
        },
        "signatures": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ],
        "readers": [
          "everyone"
        ],
        "nonreaders": [],
        "writers": [
          "ICLR.cc/2022/Conference/Program_Chairs"
        ]
      }
    ],
    "invitation": {
      "reply": {
        "writers": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "signatures": {
          "values": [
            "ICLR.cc/2022/Conference"
          ]
        },
        "content": {
          "title": {
            "value-regex": ".*",
            "order": 1
          },
          "authors": {
            "values": [
              "Anonymous"
            ],
            "order": 2
          },
          "authorids": {
            "value-regex": ".*",
            "order": 3
          },
          "keywords": {
            "value-regex": ".*",
            "order": 6
          },
          "abstract": {
            "value-regex": ".*",
            "order": 8
          },
          "pdf": {
            "value-regex": ".*",
            "order": 9
          },
          "one-sentence_summary": {
            "value-regex": ".*",
            "order": 10
          },
          "supplementary_material": {
            "value-regex": ".*",
            "order": 11
          },
          "code_of_ethics": {
            "value-regex": ".*",
            "order": 12
          },
          "submission_guidelines": {
            "value-regex": ".*",
            "order": 13
          },
          "resubmission": {
            "value-regex": ".*",
            "order": 14
          },
          "student_author": {
            "value-regex": ".*",
            "order": 15
          },
          "serve_as_reviewer": {
            "value-regex": ".*",
            "order": 16
          },
          "community_implementations": {
            "required": false,
            "description": "Optional link to open source implementations",
            "value-regex": ".*",
            "markdown": true,
            "order": 103
          }
        }
      },
      "replyForumViews": [],
      "expdate": 1682960118639,
      "signatures": [
        "ICLR.cc/2022/Conference"
      ],
      "readers": [
        "everyone"
      ],
      "writers": [
        "ICLR.cc/2022/Conference"
      ],
      "invitees": [
        "ICLR.cc/2022/Conference"
      ],
      "tcdate": 1632875419419,
      "tmdate": 1682960118686,
      "id": "ICLR.cc/2022/Conference/-/Blind_Submission",
      "type": "note"
    }
  },
  "tauthor": "OpenReview.net"
}